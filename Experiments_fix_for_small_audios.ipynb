{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from onnx import numpy_helper"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Add a reshape node in the jasper.onnx model\n",
    "model = onnx.load(\"./jasper.onnx\")\n",
    "\n",
    "model.graph.node[0].input[0] = 'input_reshaped'\n",
    "node = onnx.helper.make_node(op_type='Reshape',inputs=['input__0','shape_reshape'], outputs=['input_reshaped'], name='reshape__0')\n",
    "model.graph.node.insert(0,node)\n",
    "tensor = numpy_helper.from_array(np.array([0,64,-1]),name='shape_reshape')\n",
    "model.graph.initializer.insert(0,tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "onnx.checker.check_model(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "onnx.save(model, \"jasper_reshape.onnx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Code same as speech-recognition.py, which is the final version of speech-recognition sample\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "import os\n",
    "import soundfile as sf # Temporary import to load audio files\n",
    "\n",
    "'''\n",
    " You can download the converted onnx model from https://drive.google.com/file/d/1s_zOpwzhFfvx6wg2JsDK28WJ_ifSfWD_/view?usp=sharing\n",
    " or convert the model yourself.\n",
    "\n",
    " You can get the original pre-trained Jasper model from NVIDIA : https://ngc.nvidia.com/catalog/models/nvidia:jasper_pyt_onnx_fp16_amp/files\n",
    "    Download and unzip : `$ wget --content-disposition https://api.ngc.nvidia.com/v2/models/nvidia/jasper_pyt_onnx_fp16_amp/versions/20.10.0/zip -O jasper_pyt_onnx_fp16_amp_20.10.0.zip && unzip -o ./jasper_pyt_onnx_fp16_amp_20.10.0.zip && unzip -o ./jasper_pyt_onnx_fp16_amp.zip`\n",
    "\n",
    " you can get the script to convert the model here : https://gist.github.com/spazewalker/507f1529e19aea7e8417f6e935851a01\n",
    "\n",
    " You can convert the model using the following steps:\n",
    "     1. Import onnx and load the original model\n",
    "        ```\n",
    "        import onnx\n",
    "        model = onnx.load(\"./jasper-onnx/1/model.onnx\")\n",
    "        ```\n",
    "\n",
    "     3. Change data type of input layer\n",
    "        ```\n",
    "        inp = model.graph.input[0]\n",
    "        model.graph.input.remove(inp)\n",
    "        inp.type.tensor_type.elem_type = 1\n",
    "        model.graph.input.insert(0,inp)\n",
    "        ```\n",
    "\n",
    "     4. Change the data type of output layer\n",
    "        ```\n",
    "        out = model.graph.output[0]\n",
    "        model.graph.output.remove(out)\n",
    "        out.type.tensor_type.elem_type = 1\n",
    "        model.graph.output.insert(0,out)\n",
    "        ```\n",
    "\n",
    "     5. Change the data type of every initializer and cast it's values from FP16 to FP32\n",
    "        ```\n",
    "        for i,init in enumerate(model.graph.initializer):\n",
    "            model.graph.initializer.remove(init)\n",
    "            init.data_type = 1\n",
    "            init.raw_data = np.frombuffer(init.raw_data, count=np.product(init.dims), dtype=np.float16).astype(np.float32).tobytes()\n",
    "            model.graph.initializer.insert(i,init)\n",
    "        ```\n",
    "\n",
    "     6. Finally save the model\n",
    "        ```\n",
    "        with open('jasper_dynamic_input_float.onnx','wb') as f:\n",
    "            onnx.save_model(model,f)\n",
    "        ```\n",
    "\n",
    "    Original Repo : https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechRecognition/Jasper\n",
    " '''\n",
    "\n",
    "class FilterbankFeatures:\n",
    "    def __init__(self,\n",
    "                 sample_rate=16000, window_size=0.02, window_stride=0.01,\n",
    "                 n_fft=512, preemph=0.97, n_filt=64, lowfreq=0,\n",
    "                 highfreq=None, log=True, dither=1e-5):\n",
    "        '''\n",
    "            Initializes pre-processing class. Default values are the values used by the Jasper\n",
    "            architecture for pre-processing. For more details, refer to the paper here:\n",
    "            https://arxiv.org/abs/1904.03288\n",
    "        '''\n",
    "        self.win_length = int(sample_rate * window_size) # frame size\n",
    "        self.hop_length = int(sample_rate * window_stride) # stride\n",
    "        self.n_fft = n_fft or 2 ** np.ceil(np.log2(self.win_length))\n",
    "        self.log = log\n",
    "        self.dither = dither\n",
    "        self.n_filt = n_filt\n",
    "        self.preemph = preemph\n",
    "        highfreq = highfreq or sample_rate / 2\n",
    "        self.window_tensor = np.hanning(self.win_length)\n",
    "\n",
    "        self.filterbanks = self.mel(sample_rate, self.n_fft, n_mels=n_filt, fmin=lowfreq, fmax=highfreq)\n",
    "        self.filterbanks.dtype=np.float32\n",
    "        self.filterbanks = np.expand_dims(self.filterbanks,0)\n",
    "\n",
    "    def normalize_batch(self, x, seq_len):\n",
    "        '''\n",
    "            Normalizes the features.\n",
    "        '''\n",
    "        x_mean = np.zeros((seq_len.shape[0], x.shape[1]), dtype=x.dtype)\n",
    "        x_std = np.zeros((seq_len.shape[0], x.shape[1]), dtype=x.dtype)\n",
    "        for i in range(x.shape[0]):\n",
    "            x_mean[i, :] = np.mean(x[i, :, :seq_len[i]],axis=1)\n",
    "            x_std[i, :] = np.std(x[i, :, :seq_len[i]],axis=1)\n",
    "        # make sure x_std is not zero\n",
    "        x_std += 1e-10\n",
    "        return (x - np.expand_dims(x_mean,2)) / np.expand_dims(x_std,2)\n",
    "\n",
    "    def calculate_features(self, x, seq_len):\n",
    "        '''\n",
    "            Calculates filterbank features.\n",
    "            args:\n",
    "                x : mono channel audio\n",
    "                seq_len : length of the audio sample\n",
    "            returns:\n",
    "                x : filterbank features\n",
    "        '''\n",
    "        dtype = x.dtype\n",
    "\n",
    "        seq_len = np.ceil(seq_len / self.hop_length)\n",
    "        seq_len = np.array(seq_len,dtype=np.int32)\n",
    "\n",
    "        # dither\n",
    "        if self.dither > 0:\n",
    "            x += self.dither * np.random.randn(*x.shape)\n",
    "\n",
    "        # do preemphasis\n",
    "        if self.preemph is not None:\n",
    "            x = np.concatenate(\n",
    "                (np.expand_dims(x[0],-1), x[1:] - self.preemph * x[:-1]), axis=0)\n",
    "\n",
    "        # Short Time Fourier Transform\n",
    "        x  = self.stft(x, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                  win_length=self.win_length,\n",
    "                  fft_window=self.window_tensor)\n",
    "\n",
    "        # get power spectrum\n",
    "        x = (x**2).sum(-1)\n",
    "\n",
    "        # dot with filterbank energies\n",
    "        x = np.matmul(np.array(self.filterbanks,dtype=x.dtype), x)\n",
    "\n",
    "        # log features if required\n",
    "        if self.log:\n",
    "            x = np.log(x + 1e-20)\n",
    "\n",
    "        # normalize if required\n",
    "        x = self.normalize_batch(x, seq_len).astype(dtype)\n",
    "        return x\n",
    "\n",
    "    # Mel Frequency calculation\n",
    "    def hz_to_mel(self, frequencies):\n",
    "        '''\n",
    "            Converts frequencies from hz to mel scale. Input can be a number or a vector.\n",
    "        '''\n",
    "        frequencies = np.asanyarray(frequencies)\n",
    "\n",
    "        f_min = 0.0\n",
    "        f_sp = 200.0 / 3\n",
    "\n",
    "        mels = (frequencies - f_min) / f_sp\n",
    "\n",
    "        # Fill in the log-scale part\n",
    "        min_log_hz = 1000.0  # beginning of log region (Hz)\n",
    "        min_log_mel = (min_log_hz - f_min) / f_sp  # same (Mels)\n",
    "        logstep = np.log(6.4) / 27.0  # step size for log region\n",
    "\n",
    "        if frequencies.ndim:\n",
    "            # If we have array data, vectorize\n",
    "            log_t = frequencies >= min_log_hz\n",
    "            mels[log_t] = min_log_mel + np.log(frequencies[log_t] / min_log_hz) / logstep\n",
    "        elif frequencies >= min_log_hz:\n",
    "            # If we have scalar data, directly\n",
    "            mels = min_log_mel + np.log(frequencies / min_log_hz) / logstep\n",
    "        return mels\n",
    "\n",
    "    def mel_to_hz(self, mels):\n",
    "        '''\n",
    "            Converts frequencies from mel to hz scale. Input can be a number or a vector.\n",
    "        '''\n",
    "        mels = np.asanyarray(mels)\n",
    "\n",
    "        # Fill in the linear scale\n",
    "        f_min = 0.0\n",
    "        f_sp = 200.0 / 3\n",
    "        freqs = f_min + f_sp * mels\n",
    "\n",
    "        # And now the nonlinear scale\n",
    "        min_log_hz = 1000.0  # beginning of log region (Hz)\n",
    "        min_log_mel = (min_log_hz - f_min) / f_sp  # same (Mels)\n",
    "        logstep = np.log(6.4) / 27.0  # step size for log region\n",
    "\n",
    "        if mels.ndim:\n",
    "            # If we have vector data, vectorize\n",
    "            log_t = mels >= min_log_mel\n",
    "            freqs[log_t] = min_log_hz * np.exp(logstep * (mels[log_t] - min_log_mel))\n",
    "        elif mels >= min_log_mel:\n",
    "            # If we have scalar data, check directly\n",
    "            freqs = min_log_hz * np.exp(logstep * (mels - min_log_mel))\n",
    "\n",
    "        return freqs\n",
    "\n",
    "    def mel_frequencies(self, n_mels=128, fmin=0.0, fmax=11025.0):\n",
    "        '''\n",
    "            Calculates n mel frequencies between 2 frequencies\n",
    "            args:\n",
    "                n_mels : number of bands\n",
    "                fmin : min frequency\n",
    "                fmax : max frequency\n",
    "            returns:\n",
    "                mels : vector of mel frequencies\n",
    "        '''\n",
    "        # 'Center freqs' of mel bands - uniformly spaced between limits\n",
    "        min_mel = self.hz_to_mel(fmin)\n",
    "        max_mel = self.hz_to_mel(fmax)\n",
    "\n",
    "        mels = np.linspace(min_mel, max_mel, n_mels)\n",
    "\n",
    "        return self.mel_to_hz(mels)\n",
    "\n",
    "    def mel(self, sr, n_fft, n_mels=128, fmin=0.0, fmax=None, dtype=np.float32):\n",
    "        '''\n",
    "            Generates mel filterbank\n",
    "            args:\n",
    "                sr : Sampling rate\n",
    "                n_fft : number of FFT components\n",
    "                n_mels : number of Mel bands to generate\n",
    "                fmin : lowest frequency (in Hz)\n",
    "                fmax : highest frequency (in Hz). sr/2.0 if None\n",
    "                dtype : the data type of the output basis.\n",
    "            returns:\n",
    "                mels : Mel transform matrix\n",
    "        '''\n",
    "        # default Max freq = half of sampling rate\n",
    "        if fmax is None:\n",
    "            fmax = float(sr) / 2\n",
    "\n",
    "        # Initialize the weights\n",
    "        n_mels = int(n_mels)\n",
    "        weights = np.zeros((n_mels, int(1 + n_fft // 2)), dtype=dtype)\n",
    "\n",
    "        # Center freqs of each FFT bin\n",
    "        fftfreqs = np.linspace(0, float(sr) / 2, int(1 + n_fft // 2), endpoint=True)\n",
    "\n",
    "        # 'Center freqs' of mel bands - uniformly spaced between limits\n",
    "        mel_f = self.mel_frequencies(n_mels + 2, fmin=fmin, fmax=fmax)\n",
    "\n",
    "        fdiff = np.diff(mel_f)\n",
    "        ramps = np.subtract.outer(mel_f, fftfreqs)\n",
    "\n",
    "        for i in range(n_mels):\n",
    "            # lower and upper slopes for all bins\n",
    "            lower = -ramps[i] / fdiff[i]\n",
    "            upper = ramps[i + 2] / fdiff[i + 1]\n",
    "\n",
    "            # .. then intersect them with each other and zero\n",
    "            weights[i] = np.maximum(0, np.minimum(lower, upper))\n",
    "\n",
    "        # Using Slaney-style mel which is scaled to be approx constant energy per channel\n",
    "        enorm = 2.0 / (mel_f[2 : n_mels + 2] - mel_f[:n_mels])\n",
    "        weights *= enorm[:, np.newaxis]\n",
    "        return weights\n",
    "\n",
    "    # STFT preperation\n",
    "    def pad_window_center(self, data, size, axis=-1, **kwargs):\n",
    "        '''\n",
    "            Centers the data and pads.\n",
    "            args:\n",
    "                data : Vector to be padded and centered\n",
    "                size : Length to pad data\n",
    "                axis : Axis along which to pad and center the data\n",
    "                kwargs : arguments passed to np.pad\n",
    "            return : centered and padded data\n",
    "        '''\n",
    "        kwargs.setdefault(\"mode\", \"constant\")\n",
    "        n = data.shape[axis]\n",
    "        lpad = int((size - n) // 2)\n",
    "        lengths = [(0, 0)] * data.ndim\n",
    "        lengths[axis] = (lpad, int(size - n - lpad))\n",
    "        if lpad < 0:\n",
    "            raise Exception(\n",
    "                (\"Target size ({:d}) must be at least input size ({:d})\").format(size, n)\n",
    "            )\n",
    "        return np.pad(data, lengths, **kwargs)\n",
    "\n",
    "    def frame(self, x, frame_length, hop_length):\n",
    "        '''\n",
    "            Slices a data array into (overlapping) frames.\n",
    "            args:\n",
    "                x : array to frame\n",
    "                frame_length : length of frame\n",
    "                hop_length : Number of steps to advance between frames\n",
    "            return : A framed view of `x`\n",
    "        '''\n",
    "        if x.shape[-1] < frame_length:\n",
    "            raise Exception(\n",
    "                \"Input is too short (n={:d})\"\n",
    "                \" for frame_length={:d}\".format(x.shape[-1], frame_length)\n",
    "            )\n",
    "        x = np.asfortranarray(x)\n",
    "        n_frames = 1 + (x.shape[-1] - frame_length) // hop_length\n",
    "        strides = np.asarray(x.strides)\n",
    "        new_stride = np.prod(strides[strides > 0] // x.itemsize) * x.itemsize\n",
    "        shape = list(x.shape)[:-1] + [frame_length, n_frames]\n",
    "        strides = list(strides) + [hop_length * new_stride]\n",
    "        return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n",
    "\n",
    "    def dtype_r2c(self, d, default=np.complex64):\n",
    "        '''\n",
    "            Find the complex numpy dtype corresponding to a real dtype.\n",
    "            args:\n",
    "                d : The real-valued dtype to convert to complex.\n",
    "                default : The default complex target type, if `d` does not match a known dtype\n",
    "            return : The complex dtype\n",
    "        '''\n",
    "        mapping = {\n",
    "            np.dtype(np.float32): np.complex64,\n",
    "            np.dtype(np.float64): np.complex128,\n",
    "        }\n",
    "        dt = np.dtype(d)\n",
    "        if dt.kind == \"c\":\n",
    "            return dt\n",
    "        return np.dtype(mapping.get(dt, default))\n",
    "\n",
    "    def stft(self, y, n_fft, hop_length=None, win_length=None, fft_window=None, pad_mode='reflect', return_complex=False):\n",
    "        '''\n",
    "            Short Time Fourier Transform. The STFT represents a signal in the time-frequency\n",
    "            domain by computing discrete Fourier transforms (DFT) over short overlapping windows.\n",
    "            args:\n",
    "                y : input signal\n",
    "                n_fft : length of the windowed signal after padding with zeros.\n",
    "                hop_length : number of audio samples between adjacent STFT columns.\n",
    "                win_length : Each frame of audio is windowed by window of length win_length and\n",
    "                    then padded with zeros to match n_fft\n",
    "                fft_window : a vector or array of length `n_fft` having values computed by a\n",
    "                    window function\n",
    "                pad_mode : mode while padding the singnal\n",
    "                return_complex : returns array with complex data type if `True`\n",
    "            return : Matrix of short-term Fourier transform coefficients.\n",
    "        '''\n",
    "        if win_length is None:\n",
    "            win_length = n_fft\n",
    "        if hop_length is None:\n",
    "            hop_length = int(win_length // 4)\n",
    "        if y.ndim!=1:\n",
    "            raise Exception(f'Invalid input shape. Only Mono Channeled audio supported. Input must have shape (Audio,). Got {y.shape}')\n",
    "\n",
    "        # Pad the window out to n_fft size\n",
    "        fft_window = self.pad_window_center(fft_window, n_fft)\n",
    "\n",
    "        # Reshape so that the window can be broadcast\n",
    "        fft_window = fft_window.reshape((-1, 1))\n",
    "\n",
    "        # Pad the time series so that frames are centered\n",
    "        y = np.pad(y, int(n_fft // 2), mode=pad_mode)\n",
    "\n",
    "        # Window the time series.\n",
    "        y_frames = self.frame(y, frame_length=n_fft, hop_length=hop_length)\n",
    "\n",
    "        # Convert data type to complex\n",
    "        dtype = self.dtype_r2c(y.dtype)\n",
    "\n",
    "        # Pre-allocate the STFT matrix\n",
    "        stft_matrix = np.empty( (int(1 + n_fft // 2), y_frames.shape[-1]), dtype=dtype, order=\"F\")\n",
    "\n",
    "        stft_matrix = np.fft.rfft( fft_window * y_frames, axis=0)\n",
    "        return stft_matrix if return_complex==True else np.stack((stft_matrix.real,stft_matrix.imag),axis=-1)\n",
    "\n",
    "class Decoder:\n",
    "    '''\n",
    "        Used for decoding the output of jasper model.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        labels=[' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\"'\"]\n",
    "        self.labels_map = {i: label for i,label in enumerate(labels)}\n",
    "        self.blank_id = 28\n",
    "\n",
    "    def decode(self,x):\n",
    "        \"\"\"\n",
    "            Takes output of Jasper model and performs ctc decoding algorithm to\n",
    "            remove duplicates and special symbol. Returns prediction\n",
    "        \"\"\"\n",
    "        x = np.argmax(x,axis=-1)\n",
    "        hypotheses = []\n",
    "        prediction = x.tolist()\n",
    "        # CTC decoding procedure\n",
    "        decoded_prediction = []\n",
    "        previous = self.blank_id\n",
    "        for p in prediction:\n",
    "            if (p != previous or previous == self.blank_id) and p != self.blank_id:\n",
    "                decoded_prediction.append(p)\n",
    "            previous = p\n",
    "        hypothesis = ''.join([self.labels_map[c] for c in decoded_prediction])\n",
    "        hypotheses.append(hypothesis)\n",
    "        return hypotheses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def predict(features,net,decoder):\n",
    "    '''\n",
    "        Main function for prediction.\n",
    "        args:\n",
    "            features : input features, calculated using FilterbankFeatures class\n",
    "            net : Jasper model dnn.net object\n",
    "            decoder : Decoder object\n",
    "        return : Predicted text\n",
    "    '''\n",
    "    # This is a workaround https://github.com/opencv/opencv/issues/19091\n",
    "    # expanding 1 dimentions allows us to pass it to the network\n",
    "    # from python. This should be resolved in the future.\n",
    "    features = np.expand_dims(features,axis=3)\n",
    "    # make prediction\n",
    "    net.setInput(features)\n",
    "    output = net.forward()\n",
    "\n",
    "    # decode output to transcript\n",
    "    prediction = decoder.decode(output[0])\n",
    "    return prediction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "audio = sf.read('./audio3.flac')\n",
    "X=audio[0]\n",
    "seq_len=np.array([X.shape[0]], dtype=np.int32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "net = cv.dnn.readNetFromONNX('./jasper_reshape.onnx')\n",
    "net.setPreferableTarget(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_OPENCL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "feature_extractor = FilterbankFeatures()\n",
    "decoder = Decoder()\n",
    "features = feature_extractor.calculate_features(x=X, seq_len=seq_len)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# features = np.pad(features, ( (0,0), (0,0), (0, max(0,513-features.shape[2]) ) ), 'constant', constant_values=0)\n",
    "features = np.expand_dims(features,axis=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# features = features[:,:,:128,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "features.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 64, 788, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# features = np.pad(features, ( (0,0), (0,0), (0, max(0,513-features.shape[2]) ) ), 'constant', constant_values=0)\n",
    "# make prediction\n",
    "net.setInput(features)\n",
    "output = net.forward()\n",
    "# time taken on CPU ~100s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# decode output to transcript\n",
    "prediction = decoder.decode(output[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "prediction"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['throughout this century the power of the church was constantly on increase and is visible in many important changes']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}