{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jasper2FP32.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/spazewalker/SpeechRecog-Opencv/blob/master/Jasper2FP32.ipynb",
      "authorship_tag": "ABX9TyN7AYbPLDf3zk5y3PCvDJcJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spazewalker/SpeechRecog-Opencv/blob/master/Jasper2FP32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTYpwcx1EUB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061439aa-e5c9-41e3-a766-df7d8c15c76e"
      },
      "source": [
        "!wget --content-disposition --quiet https://api.ngc.nvidia.com/v2/models/nvidia/jasper_pyt_onnx_fp16_amp/versions/20.10.0/zip -O jasper_pyt_onnx_fp16_amp_20.10.0.zip\n",
        "!unzip -o ./jasper_pyt_onnx_fp16_amp_20.10.0.zip\n",
        "!unzip -o ./jasper_pyt_onnx_fp16_amp.zip\n",
        "!pip install onnx"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./jasper_pyt_onnx_fp16_amp_20.10.0.zip\n",
            "  inflating: jasper_pyt_onnx_fp16_amp.zip  \n",
            "Archive:  ./jasper_pyt_onnx_fp16_amp.zip\n",
            "  inflating: decoder-ts-script/1/model.pt  \n",
            "  inflating: feature-extractor-ts-trace/1/model.pt  \n",
            "  inflating: jasper-onnx/1/model.onnx  \n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx) (56.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGqo4C10VJEr",
        "outputId": "eecdd5c8-be88-4f6a-9c55-6821f63ca900"
      },
      "source": [
        "import onnx\n",
        "model = onnx.load(\"./jasper-onnx/1/model.onnx\")\n",
        "print(onnx.helper.printable_graph(model.graph))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph torch-jit-export (\n",
            "  %input__0[FLOAT16, input__0_dynamic_axes_1x64xinput__0_dynamic_axes_2]\n",
            ") initializers (\n",
            "  %decoder.layers.0.bias[FLOAT16, 29]\n",
            "  %decoder.layers.0.weight[FLOAT16, 29x1024x1]\n",
            "  %encoder.layers.0.conv.0.weight[FLOAT16, 256x64x11]\n",
            "  %encoder.layers.0.conv.1.bias[FLOAT16, 256]\n",
            "  %encoder.layers.0.conv.1.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.0.conv.1.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.0.conv.1.weight[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.0.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.1.conv.1.bias[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.1.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.1.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.1.weight[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.12.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.1.conv.13.bias[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.13.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.13.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.13.weight[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.16.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.1.conv.17.bias[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.17.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.17.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.17.weight[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.4.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.1.conv.5.bias[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.5.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.5.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.5.weight[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.8.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.1.conv.9.bias[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.9.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.9.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.1.conv.9.weight[FLOAT16, 256]\n",
            "  %encoder.layers.1.res.0.0.weight[FLOAT16, 256x256x1]\n",
            "  %encoder.layers.1.res.0.1.bias[FLOAT16, 256]\n",
            "  %encoder.layers.1.res.0.1.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.1.res.0.1.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.1.res.0.1.weight[FLOAT16, 256]\n",
            "  %encoder.layers.10.conv.0.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.10.conv.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.12.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.10.conv.13.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.13.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.13.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.13.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.16.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.10.conv.17.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.17.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.17.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.17.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.4.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.10.conv.5.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.5.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.5.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.5.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.8.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.10.conv.9.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.9.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.9.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.conv.9.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.0.0.weight[FLOAT16, 768x256x1]\n",
            "  %encoder.layers.10.res.0.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.0.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.0.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.0.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.1.0.weight[FLOAT16, 768x256x1]\n",
            "  %encoder.layers.10.res.1.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.1.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.1.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.1.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.2.0.weight[FLOAT16, 768x256x1]\n",
            "  %encoder.layers.10.res.2.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.2.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.2.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.2.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.3.0.weight[FLOAT16, 768x384x1]\n",
            "  %encoder.layers.10.res.3.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.3.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.3.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.3.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.4.0.weight[FLOAT16, 768x384x1]\n",
            "  %encoder.layers.10.res.4.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.4.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.4.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.4.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.5.0.weight[FLOAT16, 768x512x1]\n",
            "  %encoder.layers.10.res.5.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.5.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.5.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.5.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.6.0.weight[FLOAT16, 768x512x1]\n",
            "  %encoder.layers.10.res.6.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.6.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.6.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.6.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.7.0.weight[FLOAT16, 768x640x1]\n",
            "  %encoder.layers.10.res.7.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.7.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.7.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.7.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.8.0.weight[FLOAT16, 768x640x1]\n",
            "  %encoder.layers.10.res.8.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.8.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.8.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.8.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.9.0.weight[FLOAT16, 768x768x1]\n",
            "  %encoder.layers.10.res.9.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.9.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.9.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.10.res.9.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.11.conv.0.weight[FLOAT16, 896x768x29]\n",
            "  %encoder.layers.11.conv.1.bias[FLOAT16, 896]\n",
            "  %encoder.layers.11.conv.1.running_mean[FLOAT16, 896]\n",
            "  %encoder.layers.11.conv.1.running_var[FLOAT16, 896]\n",
            "  %encoder.layers.11.conv.1.weight[FLOAT16, 896]\n",
            "  %encoder.layers.12.conv.0.weight[FLOAT16, 1024x896x1]\n",
            "  %encoder.layers.12.conv.1.bias[FLOAT16, 1024]\n",
            "  %encoder.layers.12.conv.1.running_mean[FLOAT16, 1024]\n",
            "  %encoder.layers.12.conv.1.running_var[FLOAT16, 1024]\n",
            "  %encoder.layers.12.conv.1.weight[FLOAT16, 1024]\n",
            "  %encoder.layers.2.conv.0.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.2.conv.1.bias[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.1.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.1.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.1.weight[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.12.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.2.conv.13.bias[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.13.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.13.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.13.weight[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.16.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.2.conv.17.bias[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.17.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.17.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.17.weight[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.4.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.2.conv.5.bias[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.5.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.5.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.5.weight[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.8.weight[FLOAT16, 256x256x11]\n",
            "  %encoder.layers.2.conv.9.bias[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.9.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.9.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.2.conv.9.weight[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.0.0.weight[FLOAT16, 256x256x1]\n",
            "  %encoder.layers.2.res.0.1.bias[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.0.1.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.0.1.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.0.1.weight[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.1.0.weight[FLOAT16, 256x256x1]\n",
            "  %encoder.layers.2.res.1.1.bias[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.1.1.running_mean[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.1.1.running_var[FLOAT16, 256]\n",
            "  %encoder.layers.2.res.1.1.weight[FLOAT16, 256]\n",
            "  %encoder.layers.3.conv.0.weight[FLOAT16, 384x256x13]\n",
            "  %encoder.layers.3.conv.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.12.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.3.conv.13.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.13.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.13.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.13.weight[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.16.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.3.conv.17.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.17.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.17.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.17.weight[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.4.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.3.conv.5.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.5.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.5.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.5.weight[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.8.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.3.conv.9.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.9.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.9.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.conv.9.weight[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.0.0.weight[FLOAT16, 384x256x1]\n",
            "  %encoder.layers.3.res.0.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.0.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.0.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.0.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.1.0.weight[FLOAT16, 384x256x1]\n",
            "  %encoder.layers.3.res.1.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.1.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.1.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.1.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.2.0.weight[FLOAT16, 384x256x1]\n",
            "  %encoder.layers.3.res.2.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.2.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.2.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.3.res.2.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.0.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.4.conv.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.12.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.4.conv.13.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.13.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.13.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.13.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.16.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.4.conv.17.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.17.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.17.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.17.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.4.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.4.conv.5.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.5.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.5.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.5.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.8.weight[FLOAT16, 384x384x13]\n",
            "  %encoder.layers.4.conv.9.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.9.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.9.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.conv.9.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.0.0.weight[FLOAT16, 384x256x1]\n",
            "  %encoder.layers.4.res.0.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.0.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.0.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.0.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.1.0.weight[FLOAT16, 384x256x1]\n",
            "  %encoder.layers.4.res.1.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.1.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.1.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.1.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.2.0.weight[FLOAT16, 384x256x1]\n",
            "  %encoder.layers.4.res.2.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.2.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.2.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.2.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.3.0.weight[FLOAT16, 384x384x1]\n",
            "  %encoder.layers.4.res.3.1.bias[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.3.1.running_mean[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.3.1.running_var[FLOAT16, 384]\n",
            "  %encoder.layers.4.res.3.1.weight[FLOAT16, 384]\n",
            "  %encoder.layers.5.conv.0.weight[FLOAT16, 512x384x17]\n",
            "  %encoder.layers.5.conv.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.12.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.5.conv.13.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.13.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.13.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.13.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.16.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.5.conv.17.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.17.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.17.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.17.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.4.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.5.conv.5.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.5.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.5.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.5.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.8.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.5.conv.9.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.9.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.9.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.conv.9.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.0.0.weight[FLOAT16, 512x256x1]\n",
            "  %encoder.layers.5.res.0.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.0.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.0.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.0.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.1.0.weight[FLOAT16, 512x256x1]\n",
            "  %encoder.layers.5.res.1.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.1.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.1.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.1.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.2.0.weight[FLOAT16, 512x256x1]\n",
            "  %encoder.layers.5.res.2.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.2.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.2.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.2.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.3.0.weight[FLOAT16, 512x384x1]\n",
            "  %encoder.layers.5.res.3.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.3.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.3.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.3.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.4.0.weight[FLOAT16, 512x384x1]\n",
            "  %encoder.layers.5.res.4.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.4.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.4.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.5.res.4.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.0.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.6.conv.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.12.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.6.conv.13.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.13.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.13.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.13.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.16.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.6.conv.17.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.17.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.17.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.17.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.4.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.6.conv.5.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.5.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.5.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.5.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.8.weight[FLOAT16, 512x512x17]\n",
            "  %encoder.layers.6.conv.9.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.9.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.9.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.conv.9.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.0.0.weight[FLOAT16, 512x256x1]\n",
            "  %encoder.layers.6.res.0.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.0.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.0.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.0.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.1.0.weight[FLOAT16, 512x256x1]\n",
            "  %encoder.layers.6.res.1.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.1.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.1.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.1.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.2.0.weight[FLOAT16, 512x256x1]\n",
            "  %encoder.layers.6.res.2.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.2.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.2.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.2.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.3.0.weight[FLOAT16, 512x384x1]\n",
            "  %encoder.layers.6.res.3.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.3.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.3.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.3.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.4.0.weight[FLOAT16, 512x384x1]\n",
            "  %encoder.layers.6.res.4.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.4.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.4.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.4.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.5.0.weight[FLOAT16, 512x512x1]\n",
            "  %encoder.layers.6.res.5.1.bias[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.5.1.running_mean[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.5.1.running_var[FLOAT16, 512]\n",
            "  %encoder.layers.6.res.5.1.weight[FLOAT16, 512]\n",
            "  %encoder.layers.7.conv.0.weight[FLOAT16, 640x512x21]\n",
            "  %encoder.layers.7.conv.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.12.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.7.conv.13.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.13.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.13.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.13.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.16.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.7.conv.17.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.17.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.17.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.17.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.4.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.7.conv.5.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.5.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.5.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.5.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.8.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.7.conv.9.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.9.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.9.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.conv.9.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.0.0.weight[FLOAT16, 640x256x1]\n",
            "  %encoder.layers.7.res.0.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.0.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.0.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.0.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.1.0.weight[FLOAT16, 640x256x1]\n",
            "  %encoder.layers.7.res.1.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.1.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.1.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.1.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.2.0.weight[FLOAT16, 640x256x1]\n",
            "  %encoder.layers.7.res.2.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.2.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.2.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.2.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.3.0.weight[FLOAT16, 640x384x1]\n",
            "  %encoder.layers.7.res.3.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.3.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.3.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.3.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.4.0.weight[FLOAT16, 640x384x1]\n",
            "  %encoder.layers.7.res.4.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.4.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.4.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.4.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.5.0.weight[FLOAT16, 640x512x1]\n",
            "  %encoder.layers.7.res.5.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.5.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.5.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.5.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.6.0.weight[FLOAT16, 640x512x1]\n",
            "  %encoder.layers.7.res.6.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.6.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.6.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.7.res.6.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.0.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.8.conv.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.12.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.8.conv.13.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.13.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.13.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.13.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.16.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.8.conv.17.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.17.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.17.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.17.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.4.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.8.conv.5.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.5.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.5.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.5.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.8.weight[FLOAT16, 640x640x21]\n",
            "  %encoder.layers.8.conv.9.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.9.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.9.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.conv.9.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.0.0.weight[FLOAT16, 640x256x1]\n",
            "  %encoder.layers.8.res.0.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.0.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.0.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.0.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.1.0.weight[FLOAT16, 640x256x1]\n",
            "  %encoder.layers.8.res.1.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.1.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.1.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.1.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.2.0.weight[FLOAT16, 640x256x1]\n",
            "  %encoder.layers.8.res.2.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.2.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.2.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.2.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.3.0.weight[FLOAT16, 640x384x1]\n",
            "  %encoder.layers.8.res.3.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.3.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.3.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.3.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.4.0.weight[FLOAT16, 640x384x1]\n",
            "  %encoder.layers.8.res.4.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.4.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.4.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.4.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.5.0.weight[FLOAT16, 640x512x1]\n",
            "  %encoder.layers.8.res.5.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.5.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.5.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.5.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.6.0.weight[FLOAT16, 640x512x1]\n",
            "  %encoder.layers.8.res.6.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.6.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.6.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.6.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.7.0.weight[FLOAT16, 640x640x1]\n",
            "  %encoder.layers.8.res.7.1.bias[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.7.1.running_mean[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.7.1.running_var[FLOAT16, 640]\n",
            "  %encoder.layers.8.res.7.1.weight[FLOAT16, 640]\n",
            "  %encoder.layers.9.conv.0.weight[FLOAT16, 768x640x25]\n",
            "  %encoder.layers.9.conv.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.12.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.9.conv.13.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.13.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.13.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.13.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.16.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.9.conv.17.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.17.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.17.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.17.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.4.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.9.conv.5.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.5.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.5.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.5.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.8.weight[FLOAT16, 768x768x25]\n",
            "  %encoder.layers.9.conv.9.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.9.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.9.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.conv.9.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.0.0.weight[FLOAT16, 768x256x1]\n",
            "  %encoder.layers.9.res.0.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.0.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.0.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.0.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.1.0.weight[FLOAT16, 768x256x1]\n",
            "  %encoder.layers.9.res.1.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.1.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.1.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.1.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.2.0.weight[FLOAT16, 768x256x1]\n",
            "  %encoder.layers.9.res.2.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.2.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.2.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.2.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.3.0.weight[FLOAT16, 768x384x1]\n",
            "  %encoder.layers.9.res.3.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.3.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.3.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.3.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.4.0.weight[FLOAT16, 768x384x1]\n",
            "  %encoder.layers.9.res.4.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.4.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.4.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.4.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.5.0.weight[FLOAT16, 768x512x1]\n",
            "  %encoder.layers.9.res.5.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.5.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.5.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.5.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.6.0.weight[FLOAT16, 768x512x1]\n",
            "  %encoder.layers.9.res.6.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.6.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.6.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.6.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.7.0.weight[FLOAT16, 768x640x1]\n",
            "  %encoder.layers.9.res.7.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.7.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.7.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.7.1.weight[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.8.0.weight[FLOAT16, 768x640x1]\n",
            "  %encoder.layers.9.res.8.1.bias[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.8.1.running_mean[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.8.1.running_var[FLOAT16, 768]\n",
            "  %encoder.layers.9.res.8.1.weight[FLOAT16, 768]\n",
            ") {\n",
            "  %651 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [2]](%input__0, %encoder.layers.0.conv.0.weight)\n",
            "  %652 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%651, %encoder.layers.0.conv.1.weight, %encoder.layers.0.conv.1.bias, %encoder.layers.0.conv.1.running_mean, %encoder.layers.0.conv.1.running_var)\n",
            "  %653 = Relu(%652)\n",
            "  %654 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%653, %encoder.layers.1.conv.0.weight)\n",
            "  %655 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%654, %encoder.layers.1.conv.1.weight, %encoder.layers.1.conv.1.bias, %encoder.layers.1.conv.1.running_mean, %encoder.layers.1.conv.1.running_var)\n",
            "  %656 = Relu(%655)\n",
            "  %657 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%656, %encoder.layers.1.conv.4.weight)\n",
            "  %658 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%657, %encoder.layers.1.conv.5.weight, %encoder.layers.1.conv.5.bias, %encoder.layers.1.conv.5.running_mean, %encoder.layers.1.conv.5.running_var)\n",
            "  %659 = Relu(%658)\n",
            "  %660 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%659, %encoder.layers.1.conv.8.weight)\n",
            "  %661 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%660, %encoder.layers.1.conv.9.weight, %encoder.layers.1.conv.9.bias, %encoder.layers.1.conv.9.running_mean, %encoder.layers.1.conv.9.running_var)\n",
            "  %662 = Relu(%661)\n",
            "  %663 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%662, %encoder.layers.1.conv.12.weight)\n",
            "  %664 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%663, %encoder.layers.1.conv.13.weight, %encoder.layers.1.conv.13.bias, %encoder.layers.1.conv.13.running_mean, %encoder.layers.1.conv.13.running_var)\n",
            "  %665 = Relu(%664)\n",
            "  %666 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%665, %encoder.layers.1.conv.16.weight)\n",
            "  %667 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%666, %encoder.layers.1.conv.17.weight, %encoder.layers.1.conv.17.bias, %encoder.layers.1.conv.17.running_mean, %encoder.layers.1.conv.17.running_var)\n",
            "  %668 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.1.res.0.0.weight)\n",
            "  %669 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%668, %encoder.layers.1.res.0.1.weight, %encoder.layers.1.res.0.1.bias, %encoder.layers.1.res.0.1.running_mean, %encoder.layers.1.res.0.1.running_var)\n",
            "  %670 = Add(%667, %669)\n",
            "  %671 = Relu(%670)\n",
            "  %672 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%671, %encoder.layers.2.conv.0.weight)\n",
            "  %673 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%672, %encoder.layers.2.conv.1.weight, %encoder.layers.2.conv.1.bias, %encoder.layers.2.conv.1.running_mean, %encoder.layers.2.conv.1.running_var)\n",
            "  %674 = Relu(%673)\n",
            "  %675 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%674, %encoder.layers.2.conv.4.weight)\n",
            "  %676 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%675, %encoder.layers.2.conv.5.weight, %encoder.layers.2.conv.5.bias, %encoder.layers.2.conv.5.running_mean, %encoder.layers.2.conv.5.running_var)\n",
            "  %677 = Relu(%676)\n",
            "  %678 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%677, %encoder.layers.2.conv.8.weight)\n",
            "  %679 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%678, %encoder.layers.2.conv.9.weight, %encoder.layers.2.conv.9.bias, %encoder.layers.2.conv.9.running_mean, %encoder.layers.2.conv.9.running_var)\n",
            "  %680 = Relu(%679)\n",
            "  %681 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%680, %encoder.layers.2.conv.12.weight)\n",
            "  %682 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%681, %encoder.layers.2.conv.13.weight, %encoder.layers.2.conv.13.bias, %encoder.layers.2.conv.13.running_mean, %encoder.layers.2.conv.13.running_var)\n",
            "  %683 = Relu(%682)\n",
            "  %684 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%683, %encoder.layers.2.conv.16.weight)\n",
            "  %685 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%684, %encoder.layers.2.conv.17.weight, %encoder.layers.2.conv.17.bias, %encoder.layers.2.conv.17.running_mean, %encoder.layers.2.conv.17.running_var)\n",
            "  %686 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.2.res.0.0.weight)\n",
            "  %687 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%686, %encoder.layers.2.res.0.1.weight, %encoder.layers.2.res.0.1.bias, %encoder.layers.2.res.0.1.running_mean, %encoder.layers.2.res.0.1.running_var)\n",
            "  %688 = Add(%685, %687)\n",
            "  %689 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.2.res.1.0.weight)\n",
            "  %690 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%689, %encoder.layers.2.res.1.1.weight, %encoder.layers.2.res.1.1.bias, %encoder.layers.2.res.1.1.running_mean, %encoder.layers.2.res.1.1.running_var)\n",
            "  %691 = Add(%688, %690)\n",
            "  %692 = Relu(%691)\n",
            "  %693 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%692, %encoder.layers.3.conv.0.weight)\n",
            "  %694 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%693, %encoder.layers.3.conv.1.weight, %encoder.layers.3.conv.1.bias, %encoder.layers.3.conv.1.running_mean, %encoder.layers.3.conv.1.running_var)\n",
            "  %695 = Relu(%694)\n",
            "  %696 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%695, %encoder.layers.3.conv.4.weight)\n",
            "  %697 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%696, %encoder.layers.3.conv.5.weight, %encoder.layers.3.conv.5.bias, %encoder.layers.3.conv.5.running_mean, %encoder.layers.3.conv.5.running_var)\n",
            "  %698 = Relu(%697)\n",
            "  %699 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%698, %encoder.layers.3.conv.8.weight)\n",
            "  %700 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%699, %encoder.layers.3.conv.9.weight, %encoder.layers.3.conv.9.bias, %encoder.layers.3.conv.9.running_mean, %encoder.layers.3.conv.9.running_var)\n",
            "  %701 = Relu(%700)\n",
            "  %702 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%701, %encoder.layers.3.conv.12.weight)\n",
            "  %703 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%702, %encoder.layers.3.conv.13.weight, %encoder.layers.3.conv.13.bias, %encoder.layers.3.conv.13.running_mean, %encoder.layers.3.conv.13.running_var)\n",
            "  %704 = Relu(%703)\n",
            "  %705 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%704, %encoder.layers.3.conv.16.weight)\n",
            "  %706 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%705, %encoder.layers.3.conv.17.weight, %encoder.layers.3.conv.17.bias, %encoder.layers.3.conv.17.running_mean, %encoder.layers.3.conv.17.running_var)\n",
            "  %707 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.3.res.0.0.weight)\n",
            "  %708 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%707, %encoder.layers.3.res.0.1.weight, %encoder.layers.3.res.0.1.bias, %encoder.layers.3.res.0.1.running_mean, %encoder.layers.3.res.0.1.running_var)\n",
            "  %709 = Add(%706, %708)\n",
            "  %710 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.3.res.1.0.weight)\n",
            "  %711 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%710, %encoder.layers.3.res.1.1.weight, %encoder.layers.3.res.1.1.bias, %encoder.layers.3.res.1.1.running_mean, %encoder.layers.3.res.1.1.running_var)\n",
            "  %712 = Add(%709, %711)\n",
            "  %713 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.3.res.2.0.weight)\n",
            "  %714 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%713, %encoder.layers.3.res.2.1.weight, %encoder.layers.3.res.2.1.bias, %encoder.layers.3.res.2.1.running_mean, %encoder.layers.3.res.2.1.running_var)\n",
            "  %715 = Add(%712, %714)\n",
            "  %716 = Relu(%715)\n",
            "  %717 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%716, %encoder.layers.4.conv.0.weight)\n",
            "  %718 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%717, %encoder.layers.4.conv.1.weight, %encoder.layers.4.conv.1.bias, %encoder.layers.4.conv.1.running_mean, %encoder.layers.4.conv.1.running_var)\n",
            "  %719 = Relu(%718)\n",
            "  %720 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%719, %encoder.layers.4.conv.4.weight)\n",
            "  %721 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%720, %encoder.layers.4.conv.5.weight, %encoder.layers.4.conv.5.bias, %encoder.layers.4.conv.5.running_mean, %encoder.layers.4.conv.5.running_var)\n",
            "  %722 = Relu(%721)\n",
            "  %723 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%722, %encoder.layers.4.conv.8.weight)\n",
            "  %724 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%723, %encoder.layers.4.conv.9.weight, %encoder.layers.4.conv.9.bias, %encoder.layers.4.conv.9.running_mean, %encoder.layers.4.conv.9.running_var)\n",
            "  %725 = Relu(%724)\n",
            "  %726 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%725, %encoder.layers.4.conv.12.weight)\n",
            "  %727 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%726, %encoder.layers.4.conv.13.weight, %encoder.layers.4.conv.13.bias, %encoder.layers.4.conv.13.running_mean, %encoder.layers.4.conv.13.running_var)\n",
            "  %728 = Relu(%727)\n",
            "  %729 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%728, %encoder.layers.4.conv.16.weight)\n",
            "  %730 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%729, %encoder.layers.4.conv.17.weight, %encoder.layers.4.conv.17.bias, %encoder.layers.4.conv.17.running_mean, %encoder.layers.4.conv.17.running_var)\n",
            "  %731 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.4.res.0.0.weight)\n",
            "  %732 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%731, %encoder.layers.4.res.0.1.weight, %encoder.layers.4.res.0.1.bias, %encoder.layers.4.res.0.1.running_mean, %encoder.layers.4.res.0.1.running_var)\n",
            "  %733 = Add(%730, %732)\n",
            "  %734 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.4.res.1.0.weight)\n",
            "  %735 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%734, %encoder.layers.4.res.1.1.weight, %encoder.layers.4.res.1.1.bias, %encoder.layers.4.res.1.1.running_mean, %encoder.layers.4.res.1.1.running_var)\n",
            "  %736 = Add(%733, %735)\n",
            "  %737 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.4.res.2.0.weight)\n",
            "  %738 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%737, %encoder.layers.4.res.2.1.weight, %encoder.layers.4.res.2.1.bias, %encoder.layers.4.res.2.1.running_mean, %encoder.layers.4.res.2.1.running_var)\n",
            "  %739 = Add(%736, %738)\n",
            "  %740 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.4.res.3.0.weight)\n",
            "  %741 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%740, %encoder.layers.4.res.3.1.weight, %encoder.layers.4.res.3.1.bias, %encoder.layers.4.res.3.1.running_mean, %encoder.layers.4.res.3.1.running_var)\n",
            "  %742 = Add(%739, %741)\n",
            "  %743 = Relu(%742)\n",
            "  %744 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%743, %encoder.layers.5.conv.0.weight)\n",
            "  %745 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%744, %encoder.layers.5.conv.1.weight, %encoder.layers.5.conv.1.bias, %encoder.layers.5.conv.1.running_mean, %encoder.layers.5.conv.1.running_var)\n",
            "  %746 = Relu(%745)\n",
            "  %747 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%746, %encoder.layers.5.conv.4.weight)\n",
            "  %748 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%747, %encoder.layers.5.conv.5.weight, %encoder.layers.5.conv.5.bias, %encoder.layers.5.conv.5.running_mean, %encoder.layers.5.conv.5.running_var)\n",
            "  %749 = Relu(%748)\n",
            "  %750 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%749, %encoder.layers.5.conv.8.weight)\n",
            "  %751 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%750, %encoder.layers.5.conv.9.weight, %encoder.layers.5.conv.9.bias, %encoder.layers.5.conv.9.running_mean, %encoder.layers.5.conv.9.running_var)\n",
            "  %752 = Relu(%751)\n",
            "  %753 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%752, %encoder.layers.5.conv.12.weight)\n",
            "  %754 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%753, %encoder.layers.5.conv.13.weight, %encoder.layers.5.conv.13.bias, %encoder.layers.5.conv.13.running_mean, %encoder.layers.5.conv.13.running_var)\n",
            "  %755 = Relu(%754)\n",
            "  %756 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%755, %encoder.layers.5.conv.16.weight)\n",
            "  %757 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%756, %encoder.layers.5.conv.17.weight, %encoder.layers.5.conv.17.bias, %encoder.layers.5.conv.17.running_mean, %encoder.layers.5.conv.17.running_var)\n",
            "  %758 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.5.res.0.0.weight)\n",
            "  %759 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%758, %encoder.layers.5.res.0.1.weight, %encoder.layers.5.res.0.1.bias, %encoder.layers.5.res.0.1.running_mean, %encoder.layers.5.res.0.1.running_var)\n",
            "  %760 = Add(%757, %759)\n",
            "  %761 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.5.res.1.0.weight)\n",
            "  %762 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%761, %encoder.layers.5.res.1.1.weight, %encoder.layers.5.res.1.1.bias, %encoder.layers.5.res.1.1.running_mean, %encoder.layers.5.res.1.1.running_var)\n",
            "  %763 = Add(%760, %762)\n",
            "  %764 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.5.res.2.0.weight)\n",
            "  %765 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%764, %encoder.layers.5.res.2.1.weight, %encoder.layers.5.res.2.1.bias, %encoder.layers.5.res.2.1.running_mean, %encoder.layers.5.res.2.1.running_var)\n",
            "  %766 = Add(%763, %765)\n",
            "  %767 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.5.res.3.0.weight)\n",
            "  %768 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%767, %encoder.layers.5.res.3.1.weight, %encoder.layers.5.res.3.1.bias, %encoder.layers.5.res.3.1.running_mean, %encoder.layers.5.res.3.1.running_var)\n",
            "  %769 = Add(%766, %768)\n",
            "  %770 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.5.res.4.0.weight)\n",
            "  %771 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%770, %encoder.layers.5.res.4.1.weight, %encoder.layers.5.res.4.1.bias, %encoder.layers.5.res.4.1.running_mean, %encoder.layers.5.res.4.1.running_var)\n",
            "  %772 = Add(%769, %771)\n",
            "  %773 = Relu(%772)\n",
            "  %774 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%773, %encoder.layers.6.conv.0.weight)\n",
            "  %775 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%774, %encoder.layers.6.conv.1.weight, %encoder.layers.6.conv.1.bias, %encoder.layers.6.conv.1.running_mean, %encoder.layers.6.conv.1.running_var)\n",
            "  %776 = Relu(%775)\n",
            "  %777 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%776, %encoder.layers.6.conv.4.weight)\n",
            "  %778 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%777, %encoder.layers.6.conv.5.weight, %encoder.layers.6.conv.5.bias, %encoder.layers.6.conv.5.running_mean, %encoder.layers.6.conv.5.running_var)\n",
            "  %779 = Relu(%778)\n",
            "  %780 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%779, %encoder.layers.6.conv.8.weight)\n",
            "  %781 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%780, %encoder.layers.6.conv.9.weight, %encoder.layers.6.conv.9.bias, %encoder.layers.6.conv.9.running_mean, %encoder.layers.6.conv.9.running_var)\n",
            "  %782 = Relu(%781)\n",
            "  %783 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%782, %encoder.layers.6.conv.12.weight)\n",
            "  %784 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%783, %encoder.layers.6.conv.13.weight, %encoder.layers.6.conv.13.bias, %encoder.layers.6.conv.13.running_mean, %encoder.layers.6.conv.13.running_var)\n",
            "  %785 = Relu(%784)\n",
            "  %786 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%785, %encoder.layers.6.conv.16.weight)\n",
            "  %787 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%786, %encoder.layers.6.conv.17.weight, %encoder.layers.6.conv.17.bias, %encoder.layers.6.conv.17.running_mean, %encoder.layers.6.conv.17.running_var)\n",
            "  %788 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.6.res.0.0.weight)\n",
            "  %789 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%788, %encoder.layers.6.res.0.1.weight, %encoder.layers.6.res.0.1.bias, %encoder.layers.6.res.0.1.running_mean, %encoder.layers.6.res.0.1.running_var)\n",
            "  %790 = Add(%787, %789)\n",
            "  %791 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.6.res.1.0.weight)\n",
            "  %792 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%791, %encoder.layers.6.res.1.1.weight, %encoder.layers.6.res.1.1.bias, %encoder.layers.6.res.1.1.running_mean, %encoder.layers.6.res.1.1.running_var)\n",
            "  %793 = Add(%790, %792)\n",
            "  %794 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.6.res.2.0.weight)\n",
            "  %795 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%794, %encoder.layers.6.res.2.1.weight, %encoder.layers.6.res.2.1.bias, %encoder.layers.6.res.2.1.running_mean, %encoder.layers.6.res.2.1.running_var)\n",
            "  %796 = Add(%793, %795)\n",
            "  %797 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.6.res.3.0.weight)\n",
            "  %798 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%797, %encoder.layers.6.res.3.1.weight, %encoder.layers.6.res.3.1.bias, %encoder.layers.6.res.3.1.running_mean, %encoder.layers.6.res.3.1.running_var)\n",
            "  %799 = Add(%796, %798)\n",
            "  %800 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.6.res.4.0.weight)\n",
            "  %801 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%800, %encoder.layers.6.res.4.1.weight, %encoder.layers.6.res.4.1.bias, %encoder.layers.6.res.4.1.running_mean, %encoder.layers.6.res.4.1.running_var)\n",
            "  %802 = Add(%799, %801)\n",
            "  %803 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.6.res.5.0.weight)\n",
            "  %804 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%803, %encoder.layers.6.res.5.1.weight, %encoder.layers.6.res.5.1.bias, %encoder.layers.6.res.5.1.running_mean, %encoder.layers.6.res.5.1.running_var)\n",
            "  %805 = Add(%802, %804)\n",
            "  %806 = Relu(%805)\n",
            "  %807 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%806, %encoder.layers.7.conv.0.weight)\n",
            "  %808 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%807, %encoder.layers.7.conv.1.weight, %encoder.layers.7.conv.1.bias, %encoder.layers.7.conv.1.running_mean, %encoder.layers.7.conv.1.running_var)\n",
            "  %809 = Relu(%808)\n",
            "  %810 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%809, %encoder.layers.7.conv.4.weight)\n",
            "  %811 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%810, %encoder.layers.7.conv.5.weight, %encoder.layers.7.conv.5.bias, %encoder.layers.7.conv.5.running_mean, %encoder.layers.7.conv.5.running_var)\n",
            "  %812 = Relu(%811)\n",
            "  %813 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%812, %encoder.layers.7.conv.8.weight)\n",
            "  %814 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%813, %encoder.layers.7.conv.9.weight, %encoder.layers.7.conv.9.bias, %encoder.layers.7.conv.9.running_mean, %encoder.layers.7.conv.9.running_var)\n",
            "  %815 = Relu(%814)\n",
            "  %816 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%815, %encoder.layers.7.conv.12.weight)\n",
            "  %817 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%816, %encoder.layers.7.conv.13.weight, %encoder.layers.7.conv.13.bias, %encoder.layers.7.conv.13.running_mean, %encoder.layers.7.conv.13.running_var)\n",
            "  %818 = Relu(%817)\n",
            "  %819 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%818, %encoder.layers.7.conv.16.weight)\n",
            "  %820 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%819, %encoder.layers.7.conv.17.weight, %encoder.layers.7.conv.17.bias, %encoder.layers.7.conv.17.running_mean, %encoder.layers.7.conv.17.running_var)\n",
            "  %821 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.7.res.0.0.weight)\n",
            "  %822 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%821, %encoder.layers.7.res.0.1.weight, %encoder.layers.7.res.0.1.bias, %encoder.layers.7.res.0.1.running_mean, %encoder.layers.7.res.0.1.running_var)\n",
            "  %823 = Add(%820, %822)\n",
            "  %824 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.7.res.1.0.weight)\n",
            "  %825 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%824, %encoder.layers.7.res.1.1.weight, %encoder.layers.7.res.1.1.bias, %encoder.layers.7.res.1.1.running_mean, %encoder.layers.7.res.1.1.running_var)\n",
            "  %826 = Add(%823, %825)\n",
            "  %827 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.7.res.2.0.weight)\n",
            "  %828 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%827, %encoder.layers.7.res.2.1.weight, %encoder.layers.7.res.2.1.bias, %encoder.layers.7.res.2.1.running_mean, %encoder.layers.7.res.2.1.running_var)\n",
            "  %829 = Add(%826, %828)\n",
            "  %830 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.7.res.3.0.weight)\n",
            "  %831 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%830, %encoder.layers.7.res.3.1.weight, %encoder.layers.7.res.3.1.bias, %encoder.layers.7.res.3.1.running_mean, %encoder.layers.7.res.3.1.running_var)\n",
            "  %832 = Add(%829, %831)\n",
            "  %833 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.7.res.4.0.weight)\n",
            "  %834 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%833, %encoder.layers.7.res.4.1.weight, %encoder.layers.7.res.4.1.bias, %encoder.layers.7.res.4.1.running_mean, %encoder.layers.7.res.4.1.running_var)\n",
            "  %835 = Add(%832, %834)\n",
            "  %836 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.7.res.5.0.weight)\n",
            "  %837 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%836, %encoder.layers.7.res.5.1.weight, %encoder.layers.7.res.5.1.bias, %encoder.layers.7.res.5.1.running_mean, %encoder.layers.7.res.5.1.running_var)\n",
            "  %838 = Add(%835, %837)\n",
            "  %839 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.7.res.6.0.weight)\n",
            "  %840 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%839, %encoder.layers.7.res.6.1.weight, %encoder.layers.7.res.6.1.bias, %encoder.layers.7.res.6.1.running_mean, %encoder.layers.7.res.6.1.running_var)\n",
            "  %841 = Add(%838, %840)\n",
            "  %842 = Relu(%841)\n",
            "  %843 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%842, %encoder.layers.8.conv.0.weight)\n",
            "  %844 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%843, %encoder.layers.8.conv.1.weight, %encoder.layers.8.conv.1.bias, %encoder.layers.8.conv.1.running_mean, %encoder.layers.8.conv.1.running_var)\n",
            "  %845 = Relu(%844)\n",
            "  %846 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%845, %encoder.layers.8.conv.4.weight)\n",
            "  %847 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%846, %encoder.layers.8.conv.5.weight, %encoder.layers.8.conv.5.bias, %encoder.layers.8.conv.5.running_mean, %encoder.layers.8.conv.5.running_var)\n",
            "  %848 = Relu(%847)\n",
            "  %849 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%848, %encoder.layers.8.conv.8.weight)\n",
            "  %850 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%849, %encoder.layers.8.conv.9.weight, %encoder.layers.8.conv.9.bias, %encoder.layers.8.conv.9.running_mean, %encoder.layers.8.conv.9.running_var)\n",
            "  %851 = Relu(%850)\n",
            "  %852 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%851, %encoder.layers.8.conv.12.weight)\n",
            "  %853 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%852, %encoder.layers.8.conv.13.weight, %encoder.layers.8.conv.13.bias, %encoder.layers.8.conv.13.running_mean, %encoder.layers.8.conv.13.running_var)\n",
            "  %854 = Relu(%853)\n",
            "  %855 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%854, %encoder.layers.8.conv.16.weight)\n",
            "  %856 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%855, %encoder.layers.8.conv.17.weight, %encoder.layers.8.conv.17.bias, %encoder.layers.8.conv.17.running_mean, %encoder.layers.8.conv.17.running_var)\n",
            "  %857 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.8.res.0.0.weight)\n",
            "  %858 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%857, %encoder.layers.8.res.0.1.weight, %encoder.layers.8.res.0.1.bias, %encoder.layers.8.res.0.1.running_mean, %encoder.layers.8.res.0.1.running_var)\n",
            "  %859 = Add(%856, %858)\n",
            "  %860 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.8.res.1.0.weight)\n",
            "  %861 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%860, %encoder.layers.8.res.1.1.weight, %encoder.layers.8.res.1.1.bias, %encoder.layers.8.res.1.1.running_mean, %encoder.layers.8.res.1.1.running_var)\n",
            "  %862 = Add(%859, %861)\n",
            "  %863 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.8.res.2.0.weight)\n",
            "  %864 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%863, %encoder.layers.8.res.2.1.weight, %encoder.layers.8.res.2.1.bias, %encoder.layers.8.res.2.1.running_mean, %encoder.layers.8.res.2.1.running_var)\n",
            "  %865 = Add(%862, %864)\n",
            "  %866 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.8.res.3.0.weight)\n",
            "  %867 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%866, %encoder.layers.8.res.3.1.weight, %encoder.layers.8.res.3.1.bias, %encoder.layers.8.res.3.1.running_mean, %encoder.layers.8.res.3.1.running_var)\n",
            "  %868 = Add(%865, %867)\n",
            "  %869 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.8.res.4.0.weight)\n",
            "  %870 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%869, %encoder.layers.8.res.4.1.weight, %encoder.layers.8.res.4.1.bias, %encoder.layers.8.res.4.1.running_mean, %encoder.layers.8.res.4.1.running_var)\n",
            "  %871 = Add(%868, %870)\n",
            "  %872 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.8.res.5.0.weight)\n",
            "  %873 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%872, %encoder.layers.8.res.5.1.weight, %encoder.layers.8.res.5.1.bias, %encoder.layers.8.res.5.1.running_mean, %encoder.layers.8.res.5.1.running_var)\n",
            "  %874 = Add(%871, %873)\n",
            "  %875 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.8.res.6.0.weight)\n",
            "  %876 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%875, %encoder.layers.8.res.6.1.weight, %encoder.layers.8.res.6.1.bias, %encoder.layers.8.res.6.1.running_mean, %encoder.layers.8.res.6.1.running_var)\n",
            "  %877 = Add(%874, %876)\n",
            "  %878 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.8.res.7.0.weight)\n",
            "  %879 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%878, %encoder.layers.8.res.7.1.weight, %encoder.layers.8.res.7.1.bias, %encoder.layers.8.res.7.1.running_mean, %encoder.layers.8.res.7.1.running_var)\n",
            "  %880 = Add(%877, %879)\n",
            "  %881 = Relu(%880)\n",
            "  %882 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%881, %encoder.layers.9.conv.0.weight)\n",
            "  %883 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%882, %encoder.layers.9.conv.1.weight, %encoder.layers.9.conv.1.bias, %encoder.layers.9.conv.1.running_mean, %encoder.layers.9.conv.1.running_var)\n",
            "  %884 = Relu(%883)\n",
            "  %885 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%884, %encoder.layers.9.conv.4.weight)\n",
            "  %886 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%885, %encoder.layers.9.conv.5.weight, %encoder.layers.9.conv.5.bias, %encoder.layers.9.conv.5.running_mean, %encoder.layers.9.conv.5.running_var)\n",
            "  %887 = Relu(%886)\n",
            "  %888 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%887, %encoder.layers.9.conv.8.weight)\n",
            "  %889 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%888, %encoder.layers.9.conv.9.weight, %encoder.layers.9.conv.9.bias, %encoder.layers.9.conv.9.running_mean, %encoder.layers.9.conv.9.running_var)\n",
            "  %890 = Relu(%889)\n",
            "  %891 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%890, %encoder.layers.9.conv.12.weight)\n",
            "  %892 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%891, %encoder.layers.9.conv.13.weight, %encoder.layers.9.conv.13.bias, %encoder.layers.9.conv.13.running_mean, %encoder.layers.9.conv.13.running_var)\n",
            "  %893 = Relu(%892)\n",
            "  %894 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%893, %encoder.layers.9.conv.16.weight)\n",
            "  %895 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%894, %encoder.layers.9.conv.17.weight, %encoder.layers.9.conv.17.bias, %encoder.layers.9.conv.17.running_mean, %encoder.layers.9.conv.17.running_var)\n",
            "  %896 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.9.res.0.0.weight)\n",
            "  %897 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%896, %encoder.layers.9.res.0.1.weight, %encoder.layers.9.res.0.1.bias, %encoder.layers.9.res.0.1.running_mean, %encoder.layers.9.res.0.1.running_var)\n",
            "  %898 = Add(%895, %897)\n",
            "  %899 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.9.res.1.0.weight)\n",
            "  %900 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%899, %encoder.layers.9.res.1.1.weight, %encoder.layers.9.res.1.1.bias, %encoder.layers.9.res.1.1.running_mean, %encoder.layers.9.res.1.1.running_var)\n",
            "  %901 = Add(%898, %900)\n",
            "  %902 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.9.res.2.0.weight)\n",
            "  %903 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%902, %encoder.layers.9.res.2.1.weight, %encoder.layers.9.res.2.1.bias, %encoder.layers.9.res.2.1.running_mean, %encoder.layers.9.res.2.1.running_var)\n",
            "  %904 = Add(%901, %903)\n",
            "  %905 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.9.res.3.0.weight)\n",
            "  %906 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%905, %encoder.layers.9.res.3.1.weight, %encoder.layers.9.res.3.1.bias, %encoder.layers.9.res.3.1.running_mean, %encoder.layers.9.res.3.1.running_var)\n",
            "  %907 = Add(%904, %906)\n",
            "  %908 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.9.res.4.0.weight)\n",
            "  %909 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%908, %encoder.layers.9.res.4.1.weight, %encoder.layers.9.res.4.1.bias, %encoder.layers.9.res.4.1.running_mean, %encoder.layers.9.res.4.1.running_var)\n",
            "  %910 = Add(%907, %909)\n",
            "  %911 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.9.res.5.0.weight)\n",
            "  %912 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%911, %encoder.layers.9.res.5.1.weight, %encoder.layers.9.res.5.1.bias, %encoder.layers.9.res.5.1.running_mean, %encoder.layers.9.res.5.1.running_var)\n",
            "  %913 = Add(%910, %912)\n",
            "  %914 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.9.res.6.0.weight)\n",
            "  %915 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%914, %encoder.layers.9.res.6.1.weight, %encoder.layers.9.res.6.1.bias, %encoder.layers.9.res.6.1.running_mean, %encoder.layers.9.res.6.1.running_var)\n",
            "  %916 = Add(%913, %915)\n",
            "  %917 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.9.res.7.0.weight)\n",
            "  %918 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%917, %encoder.layers.9.res.7.1.weight, %encoder.layers.9.res.7.1.bias, %encoder.layers.9.res.7.1.running_mean, %encoder.layers.9.res.7.1.running_var)\n",
            "  %919 = Add(%916, %918)\n",
            "  %920 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%881, %encoder.layers.9.res.8.0.weight)\n",
            "  %921 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%920, %encoder.layers.9.res.8.1.weight, %encoder.layers.9.res.8.1.bias, %encoder.layers.9.res.8.1.running_mean, %encoder.layers.9.res.8.1.running_var)\n",
            "  %922 = Add(%919, %921)\n",
            "  %923 = Relu(%922)\n",
            "  %924 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%923, %encoder.layers.10.conv.0.weight)\n",
            "  %925 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%924, %encoder.layers.10.conv.1.weight, %encoder.layers.10.conv.1.bias, %encoder.layers.10.conv.1.running_mean, %encoder.layers.10.conv.1.running_var)\n",
            "  %926 = Relu(%925)\n",
            "  %927 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%926, %encoder.layers.10.conv.4.weight)\n",
            "  %928 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%927, %encoder.layers.10.conv.5.weight, %encoder.layers.10.conv.5.bias, %encoder.layers.10.conv.5.running_mean, %encoder.layers.10.conv.5.running_var)\n",
            "  %929 = Relu(%928)\n",
            "  %930 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%929, %encoder.layers.10.conv.8.weight)\n",
            "  %931 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%930, %encoder.layers.10.conv.9.weight, %encoder.layers.10.conv.9.bias, %encoder.layers.10.conv.9.running_mean, %encoder.layers.10.conv.9.running_var)\n",
            "  %932 = Relu(%931)\n",
            "  %933 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%932, %encoder.layers.10.conv.12.weight)\n",
            "  %934 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%933, %encoder.layers.10.conv.13.weight, %encoder.layers.10.conv.13.bias, %encoder.layers.10.conv.13.running_mean, %encoder.layers.10.conv.13.running_var)\n",
            "  %935 = Relu(%934)\n",
            "  %936 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%935, %encoder.layers.10.conv.16.weight)\n",
            "  %937 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%936, %encoder.layers.10.conv.17.weight, %encoder.layers.10.conv.17.bias, %encoder.layers.10.conv.17.running_mean, %encoder.layers.10.conv.17.running_var)\n",
            "  %938 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.10.res.0.0.weight)\n",
            "  %939 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%938, %encoder.layers.10.res.0.1.weight, %encoder.layers.10.res.0.1.bias, %encoder.layers.10.res.0.1.running_mean, %encoder.layers.10.res.0.1.running_var)\n",
            "  %940 = Add(%937, %939)\n",
            "  %941 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.10.res.1.0.weight)\n",
            "  %942 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%941, %encoder.layers.10.res.1.1.weight, %encoder.layers.10.res.1.1.bias, %encoder.layers.10.res.1.1.running_mean, %encoder.layers.10.res.1.1.running_var)\n",
            "  %943 = Add(%940, %942)\n",
            "  %944 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.10.res.2.0.weight)\n",
            "  %945 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%944, %encoder.layers.10.res.2.1.weight, %encoder.layers.10.res.2.1.bias, %encoder.layers.10.res.2.1.running_mean, %encoder.layers.10.res.2.1.running_var)\n",
            "  %946 = Add(%943, %945)\n",
            "  %947 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.10.res.3.0.weight)\n",
            "  %948 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%947, %encoder.layers.10.res.3.1.weight, %encoder.layers.10.res.3.1.bias, %encoder.layers.10.res.3.1.running_mean, %encoder.layers.10.res.3.1.running_var)\n",
            "  %949 = Add(%946, %948)\n",
            "  %950 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.10.res.4.0.weight)\n",
            "  %951 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%950, %encoder.layers.10.res.4.1.weight, %encoder.layers.10.res.4.1.bias, %encoder.layers.10.res.4.1.running_mean, %encoder.layers.10.res.4.1.running_var)\n",
            "  %952 = Add(%949, %951)\n",
            "  %953 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.10.res.5.0.weight)\n",
            "  %954 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%953, %encoder.layers.10.res.5.1.weight, %encoder.layers.10.res.5.1.bias, %encoder.layers.10.res.5.1.running_mean, %encoder.layers.10.res.5.1.running_var)\n",
            "  %955 = Add(%952, %954)\n",
            "  %956 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.10.res.6.0.weight)\n",
            "  %957 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%956, %encoder.layers.10.res.6.1.weight, %encoder.layers.10.res.6.1.bias, %encoder.layers.10.res.6.1.running_mean, %encoder.layers.10.res.6.1.running_var)\n",
            "  %958 = Add(%955, %957)\n",
            "  %959 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.10.res.7.0.weight)\n",
            "  %960 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%959, %encoder.layers.10.res.7.1.weight, %encoder.layers.10.res.7.1.bias, %encoder.layers.10.res.7.1.running_mean, %encoder.layers.10.res.7.1.running_var)\n",
            "  %961 = Add(%958, %960)\n",
            "  %962 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%881, %encoder.layers.10.res.8.0.weight)\n",
            "  %963 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%962, %encoder.layers.10.res.8.1.weight, %encoder.layers.10.res.8.1.bias, %encoder.layers.10.res.8.1.running_mean, %encoder.layers.10.res.8.1.running_var)\n",
            "  %964 = Add(%961, %963)\n",
            "  %965 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%923, %encoder.layers.10.res.9.0.weight)\n",
            "  %966 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%965, %encoder.layers.10.res.9.1.weight, %encoder.layers.10.res.9.1.bias, %encoder.layers.10.res.9.1.running_mean, %encoder.layers.10.res.9.1.running_var)\n",
            "  %967 = Add(%964, %966)\n",
            "  %968 = Relu(%967)\n",
            "  %969 = Conv[dilations = [2], group = 1, kernel_shape = [29], pads = [28, 28], strides = [1]](%968, %encoder.layers.11.conv.0.weight)\n",
            "  %970 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%969, %encoder.layers.11.conv.1.weight, %encoder.layers.11.conv.1.bias, %encoder.layers.11.conv.1.running_mean, %encoder.layers.11.conv.1.running_var)\n",
            "  %971 = Relu(%970)\n",
            "  %972 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%971, %encoder.layers.12.conv.0.weight)\n",
            "  %973 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%972, %encoder.layers.12.conv.1.weight, %encoder.layers.12.conv.1.bias, %encoder.layers.12.conv.1.running_mean, %encoder.layers.12.conv.1.running_var)\n",
            "  %974 = Relu(%973)\n",
            "  %975 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%974, %decoder.layers.0.weight, %decoder.layers.0.bias)\n",
            "  %976 = Transpose[perm = [0, 2, 1]](%975)\n",
            "  %output__0 = LogSoftmax[axis = 2](%976)\n",
            "  return %output__0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzv3vtW2jeaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3264cce8-10a2-4380-8190-bdb65e509e1f"
      },
      "source": [
        "for node_tmp in model.graph.node:\n",
        "    print(node_tmp)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: \"input__0\"\n",
            "input: \"encoder.layers.0.conv.0.weight\"\n",
            "output: \"651\"\n",
            "name: \"Conv_0\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 2\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"651\"\n",
            "input: \"encoder.layers.0.conv.1.weight\"\n",
            "input: \"encoder.layers.0.conv.1.bias\"\n",
            "input: \"encoder.layers.0.conv.1.running_mean\"\n",
            "input: \"encoder.layers.0.conv.1.running_var\"\n",
            "output: \"652\"\n",
            "name: \"BatchNormalization_1\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"652\"\n",
            "output: \"653\"\n",
            "name: \"Relu_2\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.1.conv.0.weight\"\n",
            "output: \"654\"\n",
            "name: \"Conv_3\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"654\"\n",
            "input: \"encoder.layers.1.conv.1.weight\"\n",
            "input: \"encoder.layers.1.conv.1.bias\"\n",
            "input: \"encoder.layers.1.conv.1.running_mean\"\n",
            "input: \"encoder.layers.1.conv.1.running_var\"\n",
            "output: \"655\"\n",
            "name: \"BatchNormalization_4\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"655\"\n",
            "output: \"656\"\n",
            "name: \"Relu_5\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"656\"\n",
            "input: \"encoder.layers.1.conv.4.weight\"\n",
            "output: \"657\"\n",
            "name: \"Conv_6\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"657\"\n",
            "input: \"encoder.layers.1.conv.5.weight\"\n",
            "input: \"encoder.layers.1.conv.5.bias\"\n",
            "input: \"encoder.layers.1.conv.5.running_mean\"\n",
            "input: \"encoder.layers.1.conv.5.running_var\"\n",
            "output: \"658\"\n",
            "name: \"BatchNormalization_7\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"658\"\n",
            "output: \"659\"\n",
            "name: \"Relu_8\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"659\"\n",
            "input: \"encoder.layers.1.conv.8.weight\"\n",
            "output: \"660\"\n",
            "name: \"Conv_9\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"660\"\n",
            "input: \"encoder.layers.1.conv.9.weight\"\n",
            "input: \"encoder.layers.1.conv.9.bias\"\n",
            "input: \"encoder.layers.1.conv.9.running_mean\"\n",
            "input: \"encoder.layers.1.conv.9.running_var\"\n",
            "output: \"661\"\n",
            "name: \"BatchNormalization_10\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"661\"\n",
            "output: \"662\"\n",
            "name: \"Relu_11\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"662\"\n",
            "input: \"encoder.layers.1.conv.12.weight\"\n",
            "output: \"663\"\n",
            "name: \"Conv_12\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"663\"\n",
            "input: \"encoder.layers.1.conv.13.weight\"\n",
            "input: \"encoder.layers.1.conv.13.bias\"\n",
            "input: \"encoder.layers.1.conv.13.running_mean\"\n",
            "input: \"encoder.layers.1.conv.13.running_var\"\n",
            "output: \"664\"\n",
            "name: \"BatchNormalization_13\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"664\"\n",
            "output: \"665\"\n",
            "name: \"Relu_14\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"665\"\n",
            "input: \"encoder.layers.1.conv.16.weight\"\n",
            "output: \"666\"\n",
            "name: \"Conv_15\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"666\"\n",
            "input: \"encoder.layers.1.conv.17.weight\"\n",
            "input: \"encoder.layers.1.conv.17.bias\"\n",
            "input: \"encoder.layers.1.conv.17.running_mean\"\n",
            "input: \"encoder.layers.1.conv.17.running_var\"\n",
            "output: \"667\"\n",
            "name: \"BatchNormalization_16\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.1.res.0.0.weight\"\n",
            "output: \"668\"\n",
            "name: \"Conv_17\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"668\"\n",
            "input: \"encoder.layers.1.res.0.1.weight\"\n",
            "input: \"encoder.layers.1.res.0.1.bias\"\n",
            "input: \"encoder.layers.1.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.1.res.0.1.running_var\"\n",
            "output: \"669\"\n",
            "name: \"BatchNormalization_18\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"667\"\n",
            "input: \"669\"\n",
            "output: \"670\"\n",
            "name: \"Add_19\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"670\"\n",
            "output: \"671\"\n",
            "name: \"Relu_20\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.2.conv.0.weight\"\n",
            "output: \"672\"\n",
            "name: \"Conv_21\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"672\"\n",
            "input: \"encoder.layers.2.conv.1.weight\"\n",
            "input: \"encoder.layers.2.conv.1.bias\"\n",
            "input: \"encoder.layers.2.conv.1.running_mean\"\n",
            "input: \"encoder.layers.2.conv.1.running_var\"\n",
            "output: \"673\"\n",
            "name: \"BatchNormalization_22\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"673\"\n",
            "output: \"674\"\n",
            "name: \"Relu_23\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"674\"\n",
            "input: \"encoder.layers.2.conv.4.weight\"\n",
            "output: \"675\"\n",
            "name: \"Conv_24\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"675\"\n",
            "input: \"encoder.layers.2.conv.5.weight\"\n",
            "input: \"encoder.layers.2.conv.5.bias\"\n",
            "input: \"encoder.layers.2.conv.5.running_mean\"\n",
            "input: \"encoder.layers.2.conv.5.running_var\"\n",
            "output: \"676\"\n",
            "name: \"BatchNormalization_25\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"676\"\n",
            "output: \"677\"\n",
            "name: \"Relu_26\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"677\"\n",
            "input: \"encoder.layers.2.conv.8.weight\"\n",
            "output: \"678\"\n",
            "name: \"Conv_27\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"678\"\n",
            "input: \"encoder.layers.2.conv.9.weight\"\n",
            "input: \"encoder.layers.2.conv.9.bias\"\n",
            "input: \"encoder.layers.2.conv.9.running_mean\"\n",
            "input: \"encoder.layers.2.conv.9.running_var\"\n",
            "output: \"679\"\n",
            "name: \"BatchNormalization_28\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"679\"\n",
            "output: \"680\"\n",
            "name: \"Relu_29\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"680\"\n",
            "input: \"encoder.layers.2.conv.12.weight\"\n",
            "output: \"681\"\n",
            "name: \"Conv_30\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"681\"\n",
            "input: \"encoder.layers.2.conv.13.weight\"\n",
            "input: \"encoder.layers.2.conv.13.bias\"\n",
            "input: \"encoder.layers.2.conv.13.running_mean\"\n",
            "input: \"encoder.layers.2.conv.13.running_var\"\n",
            "output: \"682\"\n",
            "name: \"BatchNormalization_31\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"682\"\n",
            "output: \"683\"\n",
            "name: \"Relu_32\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"683\"\n",
            "input: \"encoder.layers.2.conv.16.weight\"\n",
            "output: \"684\"\n",
            "name: \"Conv_33\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 11\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 5\n",
            "  ints: 5\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"684\"\n",
            "input: \"encoder.layers.2.conv.17.weight\"\n",
            "input: \"encoder.layers.2.conv.17.bias\"\n",
            "input: \"encoder.layers.2.conv.17.running_mean\"\n",
            "input: \"encoder.layers.2.conv.17.running_var\"\n",
            "output: \"685\"\n",
            "name: \"BatchNormalization_34\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.2.res.0.0.weight\"\n",
            "output: \"686\"\n",
            "name: \"Conv_35\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"686\"\n",
            "input: \"encoder.layers.2.res.0.1.weight\"\n",
            "input: \"encoder.layers.2.res.0.1.bias\"\n",
            "input: \"encoder.layers.2.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.2.res.0.1.running_var\"\n",
            "output: \"687\"\n",
            "name: \"BatchNormalization_36\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"685\"\n",
            "input: \"687\"\n",
            "output: \"688\"\n",
            "name: \"Add_37\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.2.res.1.0.weight\"\n",
            "output: \"689\"\n",
            "name: \"Conv_38\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"689\"\n",
            "input: \"encoder.layers.2.res.1.1.weight\"\n",
            "input: \"encoder.layers.2.res.1.1.bias\"\n",
            "input: \"encoder.layers.2.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.2.res.1.1.running_var\"\n",
            "output: \"690\"\n",
            "name: \"BatchNormalization_39\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"688\"\n",
            "input: \"690\"\n",
            "output: \"691\"\n",
            "name: \"Add_40\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"691\"\n",
            "output: \"692\"\n",
            "name: \"Relu_41\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.3.conv.0.weight\"\n",
            "output: \"693\"\n",
            "name: \"Conv_42\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"693\"\n",
            "input: \"encoder.layers.3.conv.1.weight\"\n",
            "input: \"encoder.layers.3.conv.1.bias\"\n",
            "input: \"encoder.layers.3.conv.1.running_mean\"\n",
            "input: \"encoder.layers.3.conv.1.running_var\"\n",
            "output: \"694\"\n",
            "name: \"BatchNormalization_43\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"694\"\n",
            "output: \"695\"\n",
            "name: \"Relu_44\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"695\"\n",
            "input: \"encoder.layers.3.conv.4.weight\"\n",
            "output: \"696\"\n",
            "name: \"Conv_45\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"696\"\n",
            "input: \"encoder.layers.3.conv.5.weight\"\n",
            "input: \"encoder.layers.3.conv.5.bias\"\n",
            "input: \"encoder.layers.3.conv.5.running_mean\"\n",
            "input: \"encoder.layers.3.conv.5.running_var\"\n",
            "output: \"697\"\n",
            "name: \"BatchNormalization_46\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"697\"\n",
            "output: \"698\"\n",
            "name: \"Relu_47\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"698\"\n",
            "input: \"encoder.layers.3.conv.8.weight\"\n",
            "output: \"699\"\n",
            "name: \"Conv_48\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"699\"\n",
            "input: \"encoder.layers.3.conv.9.weight\"\n",
            "input: \"encoder.layers.3.conv.9.bias\"\n",
            "input: \"encoder.layers.3.conv.9.running_mean\"\n",
            "input: \"encoder.layers.3.conv.9.running_var\"\n",
            "output: \"700\"\n",
            "name: \"BatchNormalization_49\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"700\"\n",
            "output: \"701\"\n",
            "name: \"Relu_50\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"701\"\n",
            "input: \"encoder.layers.3.conv.12.weight\"\n",
            "output: \"702\"\n",
            "name: \"Conv_51\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"702\"\n",
            "input: \"encoder.layers.3.conv.13.weight\"\n",
            "input: \"encoder.layers.3.conv.13.bias\"\n",
            "input: \"encoder.layers.3.conv.13.running_mean\"\n",
            "input: \"encoder.layers.3.conv.13.running_var\"\n",
            "output: \"703\"\n",
            "name: \"BatchNormalization_52\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"703\"\n",
            "output: \"704\"\n",
            "name: \"Relu_53\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"704\"\n",
            "input: \"encoder.layers.3.conv.16.weight\"\n",
            "output: \"705\"\n",
            "name: \"Conv_54\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"705\"\n",
            "input: \"encoder.layers.3.conv.17.weight\"\n",
            "input: \"encoder.layers.3.conv.17.bias\"\n",
            "input: \"encoder.layers.3.conv.17.running_mean\"\n",
            "input: \"encoder.layers.3.conv.17.running_var\"\n",
            "output: \"706\"\n",
            "name: \"BatchNormalization_55\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.3.res.0.0.weight\"\n",
            "output: \"707\"\n",
            "name: \"Conv_56\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"707\"\n",
            "input: \"encoder.layers.3.res.0.1.weight\"\n",
            "input: \"encoder.layers.3.res.0.1.bias\"\n",
            "input: \"encoder.layers.3.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.3.res.0.1.running_var\"\n",
            "output: \"708\"\n",
            "name: \"BatchNormalization_57\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"706\"\n",
            "input: \"708\"\n",
            "output: \"709\"\n",
            "name: \"Add_58\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.3.res.1.0.weight\"\n",
            "output: \"710\"\n",
            "name: \"Conv_59\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"710\"\n",
            "input: \"encoder.layers.3.res.1.1.weight\"\n",
            "input: \"encoder.layers.3.res.1.1.bias\"\n",
            "input: \"encoder.layers.3.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.3.res.1.1.running_var\"\n",
            "output: \"711\"\n",
            "name: \"BatchNormalization_60\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"709\"\n",
            "input: \"711\"\n",
            "output: \"712\"\n",
            "name: \"Add_61\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.3.res.2.0.weight\"\n",
            "output: \"713\"\n",
            "name: \"Conv_62\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"713\"\n",
            "input: \"encoder.layers.3.res.2.1.weight\"\n",
            "input: \"encoder.layers.3.res.2.1.bias\"\n",
            "input: \"encoder.layers.3.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.3.res.2.1.running_var\"\n",
            "output: \"714\"\n",
            "name: \"BatchNormalization_63\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"712\"\n",
            "input: \"714\"\n",
            "output: \"715\"\n",
            "name: \"Add_64\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"715\"\n",
            "output: \"716\"\n",
            "name: \"Relu_65\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.4.conv.0.weight\"\n",
            "output: \"717\"\n",
            "name: \"Conv_66\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"717\"\n",
            "input: \"encoder.layers.4.conv.1.weight\"\n",
            "input: \"encoder.layers.4.conv.1.bias\"\n",
            "input: \"encoder.layers.4.conv.1.running_mean\"\n",
            "input: \"encoder.layers.4.conv.1.running_var\"\n",
            "output: \"718\"\n",
            "name: \"BatchNormalization_67\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"718\"\n",
            "output: \"719\"\n",
            "name: \"Relu_68\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"719\"\n",
            "input: \"encoder.layers.4.conv.4.weight\"\n",
            "output: \"720\"\n",
            "name: \"Conv_69\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"720\"\n",
            "input: \"encoder.layers.4.conv.5.weight\"\n",
            "input: \"encoder.layers.4.conv.5.bias\"\n",
            "input: \"encoder.layers.4.conv.5.running_mean\"\n",
            "input: \"encoder.layers.4.conv.5.running_var\"\n",
            "output: \"721\"\n",
            "name: \"BatchNormalization_70\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"721\"\n",
            "output: \"722\"\n",
            "name: \"Relu_71\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"722\"\n",
            "input: \"encoder.layers.4.conv.8.weight\"\n",
            "output: \"723\"\n",
            "name: \"Conv_72\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"723\"\n",
            "input: \"encoder.layers.4.conv.9.weight\"\n",
            "input: \"encoder.layers.4.conv.9.bias\"\n",
            "input: \"encoder.layers.4.conv.9.running_mean\"\n",
            "input: \"encoder.layers.4.conv.9.running_var\"\n",
            "output: \"724\"\n",
            "name: \"BatchNormalization_73\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"724\"\n",
            "output: \"725\"\n",
            "name: \"Relu_74\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"725\"\n",
            "input: \"encoder.layers.4.conv.12.weight\"\n",
            "output: \"726\"\n",
            "name: \"Conv_75\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"726\"\n",
            "input: \"encoder.layers.4.conv.13.weight\"\n",
            "input: \"encoder.layers.4.conv.13.bias\"\n",
            "input: \"encoder.layers.4.conv.13.running_mean\"\n",
            "input: \"encoder.layers.4.conv.13.running_var\"\n",
            "output: \"727\"\n",
            "name: \"BatchNormalization_76\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"727\"\n",
            "output: \"728\"\n",
            "name: \"Relu_77\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"728\"\n",
            "input: \"encoder.layers.4.conv.16.weight\"\n",
            "output: \"729\"\n",
            "name: \"Conv_78\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 13\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 6\n",
            "  ints: 6\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"729\"\n",
            "input: \"encoder.layers.4.conv.17.weight\"\n",
            "input: \"encoder.layers.4.conv.17.bias\"\n",
            "input: \"encoder.layers.4.conv.17.running_mean\"\n",
            "input: \"encoder.layers.4.conv.17.running_var\"\n",
            "output: \"730\"\n",
            "name: \"BatchNormalization_79\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.4.res.0.0.weight\"\n",
            "output: \"731\"\n",
            "name: \"Conv_80\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"731\"\n",
            "input: \"encoder.layers.4.res.0.1.weight\"\n",
            "input: \"encoder.layers.4.res.0.1.bias\"\n",
            "input: \"encoder.layers.4.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.4.res.0.1.running_var\"\n",
            "output: \"732\"\n",
            "name: \"BatchNormalization_81\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"730\"\n",
            "input: \"732\"\n",
            "output: \"733\"\n",
            "name: \"Add_82\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.4.res.1.0.weight\"\n",
            "output: \"734\"\n",
            "name: \"Conv_83\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"734\"\n",
            "input: \"encoder.layers.4.res.1.1.weight\"\n",
            "input: \"encoder.layers.4.res.1.1.bias\"\n",
            "input: \"encoder.layers.4.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.4.res.1.1.running_var\"\n",
            "output: \"735\"\n",
            "name: \"BatchNormalization_84\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"733\"\n",
            "input: \"735\"\n",
            "output: \"736\"\n",
            "name: \"Add_85\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.4.res.2.0.weight\"\n",
            "output: \"737\"\n",
            "name: \"Conv_86\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"737\"\n",
            "input: \"encoder.layers.4.res.2.1.weight\"\n",
            "input: \"encoder.layers.4.res.2.1.bias\"\n",
            "input: \"encoder.layers.4.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.4.res.2.1.running_var\"\n",
            "output: \"738\"\n",
            "name: \"BatchNormalization_87\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"736\"\n",
            "input: \"738\"\n",
            "output: \"739\"\n",
            "name: \"Add_88\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.4.res.3.0.weight\"\n",
            "output: \"740\"\n",
            "name: \"Conv_89\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"740\"\n",
            "input: \"encoder.layers.4.res.3.1.weight\"\n",
            "input: \"encoder.layers.4.res.3.1.bias\"\n",
            "input: \"encoder.layers.4.res.3.1.running_mean\"\n",
            "input: \"encoder.layers.4.res.3.1.running_var\"\n",
            "output: \"741\"\n",
            "name: \"BatchNormalization_90\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"739\"\n",
            "input: \"741\"\n",
            "output: \"742\"\n",
            "name: \"Add_91\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"742\"\n",
            "output: \"743\"\n",
            "name: \"Relu_92\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"743\"\n",
            "input: \"encoder.layers.5.conv.0.weight\"\n",
            "output: \"744\"\n",
            "name: \"Conv_93\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"744\"\n",
            "input: \"encoder.layers.5.conv.1.weight\"\n",
            "input: \"encoder.layers.5.conv.1.bias\"\n",
            "input: \"encoder.layers.5.conv.1.running_mean\"\n",
            "input: \"encoder.layers.5.conv.1.running_var\"\n",
            "output: \"745\"\n",
            "name: \"BatchNormalization_94\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"745\"\n",
            "output: \"746\"\n",
            "name: \"Relu_95\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"746\"\n",
            "input: \"encoder.layers.5.conv.4.weight\"\n",
            "output: \"747\"\n",
            "name: \"Conv_96\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"747\"\n",
            "input: \"encoder.layers.5.conv.5.weight\"\n",
            "input: \"encoder.layers.5.conv.5.bias\"\n",
            "input: \"encoder.layers.5.conv.5.running_mean\"\n",
            "input: \"encoder.layers.5.conv.5.running_var\"\n",
            "output: \"748\"\n",
            "name: \"BatchNormalization_97\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"748\"\n",
            "output: \"749\"\n",
            "name: \"Relu_98\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"749\"\n",
            "input: \"encoder.layers.5.conv.8.weight\"\n",
            "output: \"750\"\n",
            "name: \"Conv_99\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"750\"\n",
            "input: \"encoder.layers.5.conv.9.weight\"\n",
            "input: \"encoder.layers.5.conv.9.bias\"\n",
            "input: \"encoder.layers.5.conv.9.running_mean\"\n",
            "input: \"encoder.layers.5.conv.9.running_var\"\n",
            "output: \"751\"\n",
            "name: \"BatchNormalization_100\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"751\"\n",
            "output: \"752\"\n",
            "name: \"Relu_101\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"752\"\n",
            "input: \"encoder.layers.5.conv.12.weight\"\n",
            "output: \"753\"\n",
            "name: \"Conv_102\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"753\"\n",
            "input: \"encoder.layers.5.conv.13.weight\"\n",
            "input: \"encoder.layers.5.conv.13.bias\"\n",
            "input: \"encoder.layers.5.conv.13.running_mean\"\n",
            "input: \"encoder.layers.5.conv.13.running_var\"\n",
            "output: \"754\"\n",
            "name: \"BatchNormalization_103\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"754\"\n",
            "output: \"755\"\n",
            "name: \"Relu_104\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"755\"\n",
            "input: \"encoder.layers.5.conv.16.weight\"\n",
            "output: \"756\"\n",
            "name: \"Conv_105\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"756\"\n",
            "input: \"encoder.layers.5.conv.17.weight\"\n",
            "input: \"encoder.layers.5.conv.17.bias\"\n",
            "input: \"encoder.layers.5.conv.17.running_mean\"\n",
            "input: \"encoder.layers.5.conv.17.running_var\"\n",
            "output: \"757\"\n",
            "name: \"BatchNormalization_106\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.5.res.0.0.weight\"\n",
            "output: \"758\"\n",
            "name: \"Conv_107\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"758\"\n",
            "input: \"encoder.layers.5.res.0.1.weight\"\n",
            "input: \"encoder.layers.5.res.0.1.bias\"\n",
            "input: \"encoder.layers.5.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.5.res.0.1.running_var\"\n",
            "output: \"759\"\n",
            "name: \"BatchNormalization_108\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"757\"\n",
            "input: \"759\"\n",
            "output: \"760\"\n",
            "name: \"Add_109\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.5.res.1.0.weight\"\n",
            "output: \"761\"\n",
            "name: \"Conv_110\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"761\"\n",
            "input: \"encoder.layers.5.res.1.1.weight\"\n",
            "input: \"encoder.layers.5.res.1.1.bias\"\n",
            "input: \"encoder.layers.5.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.5.res.1.1.running_var\"\n",
            "output: \"762\"\n",
            "name: \"BatchNormalization_111\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"760\"\n",
            "input: \"762\"\n",
            "output: \"763\"\n",
            "name: \"Add_112\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.5.res.2.0.weight\"\n",
            "output: \"764\"\n",
            "name: \"Conv_113\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"764\"\n",
            "input: \"encoder.layers.5.res.2.1.weight\"\n",
            "input: \"encoder.layers.5.res.2.1.bias\"\n",
            "input: \"encoder.layers.5.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.5.res.2.1.running_var\"\n",
            "output: \"765\"\n",
            "name: \"BatchNormalization_114\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"763\"\n",
            "input: \"765\"\n",
            "output: \"766\"\n",
            "name: \"Add_115\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.5.res.3.0.weight\"\n",
            "output: \"767\"\n",
            "name: \"Conv_116\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"767\"\n",
            "input: \"encoder.layers.5.res.3.1.weight\"\n",
            "input: \"encoder.layers.5.res.3.1.bias\"\n",
            "input: \"encoder.layers.5.res.3.1.running_mean\"\n",
            "input: \"encoder.layers.5.res.3.1.running_var\"\n",
            "output: \"768\"\n",
            "name: \"BatchNormalization_117\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"766\"\n",
            "input: \"768\"\n",
            "output: \"769\"\n",
            "name: \"Add_118\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"743\"\n",
            "input: \"encoder.layers.5.res.4.0.weight\"\n",
            "output: \"770\"\n",
            "name: \"Conv_119\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"770\"\n",
            "input: \"encoder.layers.5.res.4.1.weight\"\n",
            "input: \"encoder.layers.5.res.4.1.bias\"\n",
            "input: \"encoder.layers.5.res.4.1.running_mean\"\n",
            "input: \"encoder.layers.5.res.4.1.running_var\"\n",
            "output: \"771\"\n",
            "name: \"BatchNormalization_120\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"769\"\n",
            "input: \"771\"\n",
            "output: \"772\"\n",
            "name: \"Add_121\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"772\"\n",
            "output: \"773\"\n",
            "name: \"Relu_122\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"773\"\n",
            "input: \"encoder.layers.6.conv.0.weight\"\n",
            "output: \"774\"\n",
            "name: \"Conv_123\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"774\"\n",
            "input: \"encoder.layers.6.conv.1.weight\"\n",
            "input: \"encoder.layers.6.conv.1.bias\"\n",
            "input: \"encoder.layers.6.conv.1.running_mean\"\n",
            "input: \"encoder.layers.6.conv.1.running_var\"\n",
            "output: \"775\"\n",
            "name: \"BatchNormalization_124\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"775\"\n",
            "output: \"776\"\n",
            "name: \"Relu_125\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"776\"\n",
            "input: \"encoder.layers.6.conv.4.weight\"\n",
            "output: \"777\"\n",
            "name: \"Conv_126\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"777\"\n",
            "input: \"encoder.layers.6.conv.5.weight\"\n",
            "input: \"encoder.layers.6.conv.5.bias\"\n",
            "input: \"encoder.layers.6.conv.5.running_mean\"\n",
            "input: \"encoder.layers.6.conv.5.running_var\"\n",
            "output: \"778\"\n",
            "name: \"BatchNormalization_127\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"778\"\n",
            "output: \"779\"\n",
            "name: \"Relu_128\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"779\"\n",
            "input: \"encoder.layers.6.conv.8.weight\"\n",
            "output: \"780\"\n",
            "name: \"Conv_129\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"780\"\n",
            "input: \"encoder.layers.6.conv.9.weight\"\n",
            "input: \"encoder.layers.6.conv.9.bias\"\n",
            "input: \"encoder.layers.6.conv.9.running_mean\"\n",
            "input: \"encoder.layers.6.conv.9.running_var\"\n",
            "output: \"781\"\n",
            "name: \"BatchNormalization_130\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"781\"\n",
            "output: \"782\"\n",
            "name: \"Relu_131\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"782\"\n",
            "input: \"encoder.layers.6.conv.12.weight\"\n",
            "output: \"783\"\n",
            "name: \"Conv_132\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"783\"\n",
            "input: \"encoder.layers.6.conv.13.weight\"\n",
            "input: \"encoder.layers.6.conv.13.bias\"\n",
            "input: \"encoder.layers.6.conv.13.running_mean\"\n",
            "input: \"encoder.layers.6.conv.13.running_var\"\n",
            "output: \"784\"\n",
            "name: \"BatchNormalization_133\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"784\"\n",
            "output: \"785\"\n",
            "name: \"Relu_134\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"785\"\n",
            "input: \"encoder.layers.6.conv.16.weight\"\n",
            "output: \"786\"\n",
            "name: \"Conv_135\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 17\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 8\n",
            "  ints: 8\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"786\"\n",
            "input: \"encoder.layers.6.conv.17.weight\"\n",
            "input: \"encoder.layers.6.conv.17.bias\"\n",
            "input: \"encoder.layers.6.conv.17.running_mean\"\n",
            "input: \"encoder.layers.6.conv.17.running_var\"\n",
            "output: \"787\"\n",
            "name: \"BatchNormalization_136\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.6.res.0.0.weight\"\n",
            "output: \"788\"\n",
            "name: \"Conv_137\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"788\"\n",
            "input: \"encoder.layers.6.res.0.1.weight\"\n",
            "input: \"encoder.layers.6.res.0.1.bias\"\n",
            "input: \"encoder.layers.6.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.6.res.0.1.running_var\"\n",
            "output: \"789\"\n",
            "name: \"BatchNormalization_138\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"787\"\n",
            "input: \"789\"\n",
            "output: \"790\"\n",
            "name: \"Add_139\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.6.res.1.0.weight\"\n",
            "output: \"791\"\n",
            "name: \"Conv_140\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"791\"\n",
            "input: \"encoder.layers.6.res.1.1.weight\"\n",
            "input: \"encoder.layers.6.res.1.1.bias\"\n",
            "input: \"encoder.layers.6.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.6.res.1.1.running_var\"\n",
            "output: \"792\"\n",
            "name: \"BatchNormalization_141\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"790\"\n",
            "input: \"792\"\n",
            "output: \"793\"\n",
            "name: \"Add_142\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.6.res.2.0.weight\"\n",
            "output: \"794\"\n",
            "name: \"Conv_143\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"794\"\n",
            "input: \"encoder.layers.6.res.2.1.weight\"\n",
            "input: \"encoder.layers.6.res.2.1.bias\"\n",
            "input: \"encoder.layers.6.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.6.res.2.1.running_var\"\n",
            "output: \"795\"\n",
            "name: \"BatchNormalization_144\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"793\"\n",
            "input: \"795\"\n",
            "output: \"796\"\n",
            "name: \"Add_145\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.6.res.3.0.weight\"\n",
            "output: \"797\"\n",
            "name: \"Conv_146\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"797\"\n",
            "input: \"encoder.layers.6.res.3.1.weight\"\n",
            "input: \"encoder.layers.6.res.3.1.bias\"\n",
            "input: \"encoder.layers.6.res.3.1.running_mean\"\n",
            "input: \"encoder.layers.6.res.3.1.running_var\"\n",
            "output: \"798\"\n",
            "name: \"BatchNormalization_147\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"796\"\n",
            "input: \"798\"\n",
            "output: \"799\"\n",
            "name: \"Add_148\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"743\"\n",
            "input: \"encoder.layers.6.res.4.0.weight\"\n",
            "output: \"800\"\n",
            "name: \"Conv_149\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"800\"\n",
            "input: \"encoder.layers.6.res.4.1.weight\"\n",
            "input: \"encoder.layers.6.res.4.1.bias\"\n",
            "input: \"encoder.layers.6.res.4.1.running_mean\"\n",
            "input: \"encoder.layers.6.res.4.1.running_var\"\n",
            "output: \"801\"\n",
            "name: \"BatchNormalization_150\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"799\"\n",
            "input: \"801\"\n",
            "output: \"802\"\n",
            "name: \"Add_151\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"773\"\n",
            "input: \"encoder.layers.6.res.5.0.weight\"\n",
            "output: \"803\"\n",
            "name: \"Conv_152\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"803\"\n",
            "input: \"encoder.layers.6.res.5.1.weight\"\n",
            "input: \"encoder.layers.6.res.5.1.bias\"\n",
            "input: \"encoder.layers.6.res.5.1.running_mean\"\n",
            "input: \"encoder.layers.6.res.5.1.running_var\"\n",
            "output: \"804\"\n",
            "name: \"BatchNormalization_153\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"802\"\n",
            "input: \"804\"\n",
            "output: \"805\"\n",
            "name: \"Add_154\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"805\"\n",
            "output: \"806\"\n",
            "name: \"Relu_155\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"806\"\n",
            "input: \"encoder.layers.7.conv.0.weight\"\n",
            "output: \"807\"\n",
            "name: \"Conv_156\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"807\"\n",
            "input: \"encoder.layers.7.conv.1.weight\"\n",
            "input: \"encoder.layers.7.conv.1.bias\"\n",
            "input: \"encoder.layers.7.conv.1.running_mean\"\n",
            "input: \"encoder.layers.7.conv.1.running_var\"\n",
            "output: \"808\"\n",
            "name: \"BatchNormalization_157\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"808\"\n",
            "output: \"809\"\n",
            "name: \"Relu_158\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"809\"\n",
            "input: \"encoder.layers.7.conv.4.weight\"\n",
            "output: \"810\"\n",
            "name: \"Conv_159\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"810\"\n",
            "input: \"encoder.layers.7.conv.5.weight\"\n",
            "input: \"encoder.layers.7.conv.5.bias\"\n",
            "input: \"encoder.layers.7.conv.5.running_mean\"\n",
            "input: \"encoder.layers.7.conv.5.running_var\"\n",
            "output: \"811\"\n",
            "name: \"BatchNormalization_160\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"811\"\n",
            "output: \"812\"\n",
            "name: \"Relu_161\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"812\"\n",
            "input: \"encoder.layers.7.conv.8.weight\"\n",
            "output: \"813\"\n",
            "name: \"Conv_162\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"813\"\n",
            "input: \"encoder.layers.7.conv.9.weight\"\n",
            "input: \"encoder.layers.7.conv.9.bias\"\n",
            "input: \"encoder.layers.7.conv.9.running_mean\"\n",
            "input: \"encoder.layers.7.conv.9.running_var\"\n",
            "output: \"814\"\n",
            "name: \"BatchNormalization_163\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"814\"\n",
            "output: \"815\"\n",
            "name: \"Relu_164\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"815\"\n",
            "input: \"encoder.layers.7.conv.12.weight\"\n",
            "output: \"816\"\n",
            "name: \"Conv_165\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"816\"\n",
            "input: \"encoder.layers.7.conv.13.weight\"\n",
            "input: \"encoder.layers.7.conv.13.bias\"\n",
            "input: \"encoder.layers.7.conv.13.running_mean\"\n",
            "input: \"encoder.layers.7.conv.13.running_var\"\n",
            "output: \"817\"\n",
            "name: \"BatchNormalization_166\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"817\"\n",
            "output: \"818\"\n",
            "name: \"Relu_167\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"818\"\n",
            "input: \"encoder.layers.7.conv.16.weight\"\n",
            "output: \"819\"\n",
            "name: \"Conv_168\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"819\"\n",
            "input: \"encoder.layers.7.conv.17.weight\"\n",
            "input: \"encoder.layers.7.conv.17.bias\"\n",
            "input: \"encoder.layers.7.conv.17.running_mean\"\n",
            "input: \"encoder.layers.7.conv.17.running_var\"\n",
            "output: \"820\"\n",
            "name: \"BatchNormalization_169\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.7.res.0.0.weight\"\n",
            "output: \"821\"\n",
            "name: \"Conv_170\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"821\"\n",
            "input: \"encoder.layers.7.res.0.1.weight\"\n",
            "input: \"encoder.layers.7.res.0.1.bias\"\n",
            "input: \"encoder.layers.7.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.7.res.0.1.running_var\"\n",
            "output: \"822\"\n",
            "name: \"BatchNormalization_171\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"820\"\n",
            "input: \"822\"\n",
            "output: \"823\"\n",
            "name: \"Add_172\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.7.res.1.0.weight\"\n",
            "output: \"824\"\n",
            "name: \"Conv_173\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"824\"\n",
            "input: \"encoder.layers.7.res.1.1.weight\"\n",
            "input: \"encoder.layers.7.res.1.1.bias\"\n",
            "input: \"encoder.layers.7.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.7.res.1.1.running_var\"\n",
            "output: \"825\"\n",
            "name: \"BatchNormalization_174\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"823\"\n",
            "input: \"825\"\n",
            "output: \"826\"\n",
            "name: \"Add_175\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.7.res.2.0.weight\"\n",
            "output: \"827\"\n",
            "name: \"Conv_176\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"827\"\n",
            "input: \"encoder.layers.7.res.2.1.weight\"\n",
            "input: \"encoder.layers.7.res.2.1.bias\"\n",
            "input: \"encoder.layers.7.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.7.res.2.1.running_var\"\n",
            "output: \"828\"\n",
            "name: \"BatchNormalization_177\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"826\"\n",
            "input: \"828\"\n",
            "output: \"829\"\n",
            "name: \"Add_178\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.7.res.3.0.weight\"\n",
            "output: \"830\"\n",
            "name: \"Conv_179\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"830\"\n",
            "input: \"encoder.layers.7.res.3.1.weight\"\n",
            "input: \"encoder.layers.7.res.3.1.bias\"\n",
            "input: \"encoder.layers.7.res.3.1.running_mean\"\n",
            "input: \"encoder.layers.7.res.3.1.running_var\"\n",
            "output: \"831\"\n",
            "name: \"BatchNormalization_180\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"829\"\n",
            "input: \"831\"\n",
            "output: \"832\"\n",
            "name: \"Add_181\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"743\"\n",
            "input: \"encoder.layers.7.res.4.0.weight\"\n",
            "output: \"833\"\n",
            "name: \"Conv_182\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"833\"\n",
            "input: \"encoder.layers.7.res.4.1.weight\"\n",
            "input: \"encoder.layers.7.res.4.1.bias\"\n",
            "input: \"encoder.layers.7.res.4.1.running_mean\"\n",
            "input: \"encoder.layers.7.res.4.1.running_var\"\n",
            "output: \"834\"\n",
            "name: \"BatchNormalization_183\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"832\"\n",
            "input: \"834\"\n",
            "output: \"835\"\n",
            "name: \"Add_184\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"773\"\n",
            "input: \"encoder.layers.7.res.5.0.weight\"\n",
            "output: \"836\"\n",
            "name: \"Conv_185\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"836\"\n",
            "input: \"encoder.layers.7.res.5.1.weight\"\n",
            "input: \"encoder.layers.7.res.5.1.bias\"\n",
            "input: \"encoder.layers.7.res.5.1.running_mean\"\n",
            "input: \"encoder.layers.7.res.5.1.running_var\"\n",
            "output: \"837\"\n",
            "name: \"BatchNormalization_186\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"835\"\n",
            "input: \"837\"\n",
            "output: \"838\"\n",
            "name: \"Add_187\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"806\"\n",
            "input: \"encoder.layers.7.res.6.0.weight\"\n",
            "output: \"839\"\n",
            "name: \"Conv_188\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"839\"\n",
            "input: \"encoder.layers.7.res.6.1.weight\"\n",
            "input: \"encoder.layers.7.res.6.1.bias\"\n",
            "input: \"encoder.layers.7.res.6.1.running_mean\"\n",
            "input: \"encoder.layers.7.res.6.1.running_var\"\n",
            "output: \"840\"\n",
            "name: \"BatchNormalization_189\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"838\"\n",
            "input: \"840\"\n",
            "output: \"841\"\n",
            "name: \"Add_190\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"841\"\n",
            "output: \"842\"\n",
            "name: \"Relu_191\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"842\"\n",
            "input: \"encoder.layers.8.conv.0.weight\"\n",
            "output: \"843\"\n",
            "name: \"Conv_192\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"843\"\n",
            "input: \"encoder.layers.8.conv.1.weight\"\n",
            "input: \"encoder.layers.8.conv.1.bias\"\n",
            "input: \"encoder.layers.8.conv.1.running_mean\"\n",
            "input: \"encoder.layers.8.conv.1.running_var\"\n",
            "output: \"844\"\n",
            "name: \"BatchNormalization_193\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"844\"\n",
            "output: \"845\"\n",
            "name: \"Relu_194\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"845\"\n",
            "input: \"encoder.layers.8.conv.4.weight\"\n",
            "output: \"846\"\n",
            "name: \"Conv_195\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"846\"\n",
            "input: \"encoder.layers.8.conv.5.weight\"\n",
            "input: \"encoder.layers.8.conv.5.bias\"\n",
            "input: \"encoder.layers.8.conv.5.running_mean\"\n",
            "input: \"encoder.layers.8.conv.5.running_var\"\n",
            "output: \"847\"\n",
            "name: \"BatchNormalization_196\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"847\"\n",
            "output: \"848\"\n",
            "name: \"Relu_197\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"848\"\n",
            "input: \"encoder.layers.8.conv.8.weight\"\n",
            "output: \"849\"\n",
            "name: \"Conv_198\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"849\"\n",
            "input: \"encoder.layers.8.conv.9.weight\"\n",
            "input: \"encoder.layers.8.conv.9.bias\"\n",
            "input: \"encoder.layers.8.conv.9.running_mean\"\n",
            "input: \"encoder.layers.8.conv.9.running_var\"\n",
            "output: \"850\"\n",
            "name: \"BatchNormalization_199\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"850\"\n",
            "output: \"851\"\n",
            "name: \"Relu_200\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"851\"\n",
            "input: \"encoder.layers.8.conv.12.weight\"\n",
            "output: \"852\"\n",
            "name: \"Conv_201\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"852\"\n",
            "input: \"encoder.layers.8.conv.13.weight\"\n",
            "input: \"encoder.layers.8.conv.13.bias\"\n",
            "input: \"encoder.layers.8.conv.13.running_mean\"\n",
            "input: \"encoder.layers.8.conv.13.running_var\"\n",
            "output: \"853\"\n",
            "name: \"BatchNormalization_202\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"853\"\n",
            "output: \"854\"\n",
            "name: \"Relu_203\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"854\"\n",
            "input: \"encoder.layers.8.conv.16.weight\"\n",
            "output: \"855\"\n",
            "name: \"Conv_204\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 21\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 10\n",
            "  ints: 10\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"855\"\n",
            "input: \"encoder.layers.8.conv.17.weight\"\n",
            "input: \"encoder.layers.8.conv.17.bias\"\n",
            "input: \"encoder.layers.8.conv.17.running_mean\"\n",
            "input: \"encoder.layers.8.conv.17.running_var\"\n",
            "output: \"856\"\n",
            "name: \"BatchNormalization_205\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.8.res.0.0.weight\"\n",
            "output: \"857\"\n",
            "name: \"Conv_206\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"857\"\n",
            "input: \"encoder.layers.8.res.0.1.weight\"\n",
            "input: \"encoder.layers.8.res.0.1.bias\"\n",
            "input: \"encoder.layers.8.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.0.1.running_var\"\n",
            "output: \"858\"\n",
            "name: \"BatchNormalization_207\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"856\"\n",
            "input: \"858\"\n",
            "output: \"859\"\n",
            "name: \"Add_208\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.8.res.1.0.weight\"\n",
            "output: \"860\"\n",
            "name: \"Conv_209\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"860\"\n",
            "input: \"encoder.layers.8.res.1.1.weight\"\n",
            "input: \"encoder.layers.8.res.1.1.bias\"\n",
            "input: \"encoder.layers.8.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.1.1.running_var\"\n",
            "output: \"861\"\n",
            "name: \"BatchNormalization_210\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"859\"\n",
            "input: \"861\"\n",
            "output: \"862\"\n",
            "name: \"Add_211\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.8.res.2.0.weight\"\n",
            "output: \"863\"\n",
            "name: \"Conv_212\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"863\"\n",
            "input: \"encoder.layers.8.res.2.1.weight\"\n",
            "input: \"encoder.layers.8.res.2.1.bias\"\n",
            "input: \"encoder.layers.8.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.2.1.running_var\"\n",
            "output: \"864\"\n",
            "name: \"BatchNormalization_213\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"862\"\n",
            "input: \"864\"\n",
            "output: \"865\"\n",
            "name: \"Add_214\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.8.res.3.0.weight\"\n",
            "output: \"866\"\n",
            "name: \"Conv_215\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"866\"\n",
            "input: \"encoder.layers.8.res.3.1.weight\"\n",
            "input: \"encoder.layers.8.res.3.1.bias\"\n",
            "input: \"encoder.layers.8.res.3.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.3.1.running_var\"\n",
            "output: \"867\"\n",
            "name: \"BatchNormalization_216\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"865\"\n",
            "input: \"867\"\n",
            "output: \"868\"\n",
            "name: \"Add_217\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"743\"\n",
            "input: \"encoder.layers.8.res.4.0.weight\"\n",
            "output: \"869\"\n",
            "name: \"Conv_218\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"869\"\n",
            "input: \"encoder.layers.8.res.4.1.weight\"\n",
            "input: \"encoder.layers.8.res.4.1.bias\"\n",
            "input: \"encoder.layers.8.res.4.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.4.1.running_var\"\n",
            "output: \"870\"\n",
            "name: \"BatchNormalization_219\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"868\"\n",
            "input: \"870\"\n",
            "output: \"871\"\n",
            "name: \"Add_220\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"773\"\n",
            "input: \"encoder.layers.8.res.5.0.weight\"\n",
            "output: \"872\"\n",
            "name: \"Conv_221\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"872\"\n",
            "input: \"encoder.layers.8.res.5.1.weight\"\n",
            "input: \"encoder.layers.8.res.5.1.bias\"\n",
            "input: \"encoder.layers.8.res.5.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.5.1.running_var\"\n",
            "output: \"873\"\n",
            "name: \"BatchNormalization_222\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"871\"\n",
            "input: \"873\"\n",
            "output: \"874\"\n",
            "name: \"Add_223\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"806\"\n",
            "input: \"encoder.layers.8.res.6.0.weight\"\n",
            "output: \"875\"\n",
            "name: \"Conv_224\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"875\"\n",
            "input: \"encoder.layers.8.res.6.1.weight\"\n",
            "input: \"encoder.layers.8.res.6.1.bias\"\n",
            "input: \"encoder.layers.8.res.6.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.6.1.running_var\"\n",
            "output: \"876\"\n",
            "name: \"BatchNormalization_225\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"874\"\n",
            "input: \"876\"\n",
            "output: \"877\"\n",
            "name: \"Add_226\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"842\"\n",
            "input: \"encoder.layers.8.res.7.0.weight\"\n",
            "output: \"878\"\n",
            "name: \"Conv_227\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"878\"\n",
            "input: \"encoder.layers.8.res.7.1.weight\"\n",
            "input: \"encoder.layers.8.res.7.1.bias\"\n",
            "input: \"encoder.layers.8.res.7.1.running_mean\"\n",
            "input: \"encoder.layers.8.res.7.1.running_var\"\n",
            "output: \"879\"\n",
            "name: \"BatchNormalization_228\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"877\"\n",
            "input: \"879\"\n",
            "output: \"880\"\n",
            "name: \"Add_229\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"880\"\n",
            "output: \"881\"\n",
            "name: \"Relu_230\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"881\"\n",
            "input: \"encoder.layers.9.conv.0.weight\"\n",
            "output: \"882\"\n",
            "name: \"Conv_231\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"882\"\n",
            "input: \"encoder.layers.9.conv.1.weight\"\n",
            "input: \"encoder.layers.9.conv.1.bias\"\n",
            "input: \"encoder.layers.9.conv.1.running_mean\"\n",
            "input: \"encoder.layers.9.conv.1.running_var\"\n",
            "output: \"883\"\n",
            "name: \"BatchNormalization_232\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"883\"\n",
            "output: \"884\"\n",
            "name: \"Relu_233\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"884\"\n",
            "input: \"encoder.layers.9.conv.4.weight\"\n",
            "output: \"885\"\n",
            "name: \"Conv_234\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"885\"\n",
            "input: \"encoder.layers.9.conv.5.weight\"\n",
            "input: \"encoder.layers.9.conv.5.bias\"\n",
            "input: \"encoder.layers.9.conv.5.running_mean\"\n",
            "input: \"encoder.layers.9.conv.5.running_var\"\n",
            "output: \"886\"\n",
            "name: \"BatchNormalization_235\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"886\"\n",
            "output: \"887\"\n",
            "name: \"Relu_236\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"887\"\n",
            "input: \"encoder.layers.9.conv.8.weight\"\n",
            "output: \"888\"\n",
            "name: \"Conv_237\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"888\"\n",
            "input: \"encoder.layers.9.conv.9.weight\"\n",
            "input: \"encoder.layers.9.conv.9.bias\"\n",
            "input: \"encoder.layers.9.conv.9.running_mean\"\n",
            "input: \"encoder.layers.9.conv.9.running_var\"\n",
            "output: \"889\"\n",
            "name: \"BatchNormalization_238\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"889\"\n",
            "output: \"890\"\n",
            "name: \"Relu_239\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"890\"\n",
            "input: \"encoder.layers.9.conv.12.weight\"\n",
            "output: \"891\"\n",
            "name: \"Conv_240\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"891\"\n",
            "input: \"encoder.layers.9.conv.13.weight\"\n",
            "input: \"encoder.layers.9.conv.13.bias\"\n",
            "input: \"encoder.layers.9.conv.13.running_mean\"\n",
            "input: \"encoder.layers.9.conv.13.running_var\"\n",
            "output: \"892\"\n",
            "name: \"BatchNormalization_241\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"892\"\n",
            "output: \"893\"\n",
            "name: \"Relu_242\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"893\"\n",
            "input: \"encoder.layers.9.conv.16.weight\"\n",
            "output: \"894\"\n",
            "name: \"Conv_243\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"894\"\n",
            "input: \"encoder.layers.9.conv.17.weight\"\n",
            "input: \"encoder.layers.9.conv.17.bias\"\n",
            "input: \"encoder.layers.9.conv.17.running_mean\"\n",
            "input: \"encoder.layers.9.conv.17.running_var\"\n",
            "output: \"895\"\n",
            "name: \"BatchNormalization_244\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.9.res.0.0.weight\"\n",
            "output: \"896\"\n",
            "name: \"Conv_245\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"896\"\n",
            "input: \"encoder.layers.9.res.0.1.weight\"\n",
            "input: \"encoder.layers.9.res.0.1.bias\"\n",
            "input: \"encoder.layers.9.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.0.1.running_var\"\n",
            "output: \"897\"\n",
            "name: \"BatchNormalization_246\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"895\"\n",
            "input: \"897\"\n",
            "output: \"898\"\n",
            "name: \"Add_247\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.9.res.1.0.weight\"\n",
            "output: \"899\"\n",
            "name: \"Conv_248\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"899\"\n",
            "input: \"encoder.layers.9.res.1.1.weight\"\n",
            "input: \"encoder.layers.9.res.1.1.bias\"\n",
            "input: \"encoder.layers.9.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.1.1.running_var\"\n",
            "output: \"900\"\n",
            "name: \"BatchNormalization_249\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"898\"\n",
            "input: \"900\"\n",
            "output: \"901\"\n",
            "name: \"Add_250\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.9.res.2.0.weight\"\n",
            "output: \"902\"\n",
            "name: \"Conv_251\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"902\"\n",
            "input: \"encoder.layers.9.res.2.1.weight\"\n",
            "input: \"encoder.layers.9.res.2.1.bias\"\n",
            "input: \"encoder.layers.9.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.2.1.running_var\"\n",
            "output: \"903\"\n",
            "name: \"BatchNormalization_252\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"901\"\n",
            "input: \"903\"\n",
            "output: \"904\"\n",
            "name: \"Add_253\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.9.res.3.0.weight\"\n",
            "output: \"905\"\n",
            "name: \"Conv_254\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"905\"\n",
            "input: \"encoder.layers.9.res.3.1.weight\"\n",
            "input: \"encoder.layers.9.res.3.1.bias\"\n",
            "input: \"encoder.layers.9.res.3.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.3.1.running_var\"\n",
            "output: \"906\"\n",
            "name: \"BatchNormalization_255\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"904\"\n",
            "input: \"906\"\n",
            "output: \"907\"\n",
            "name: \"Add_256\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"743\"\n",
            "input: \"encoder.layers.9.res.4.0.weight\"\n",
            "output: \"908\"\n",
            "name: \"Conv_257\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"908\"\n",
            "input: \"encoder.layers.9.res.4.1.weight\"\n",
            "input: \"encoder.layers.9.res.4.1.bias\"\n",
            "input: \"encoder.layers.9.res.4.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.4.1.running_var\"\n",
            "output: \"909\"\n",
            "name: \"BatchNormalization_258\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"907\"\n",
            "input: \"909\"\n",
            "output: \"910\"\n",
            "name: \"Add_259\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"773\"\n",
            "input: \"encoder.layers.9.res.5.0.weight\"\n",
            "output: \"911\"\n",
            "name: \"Conv_260\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"911\"\n",
            "input: \"encoder.layers.9.res.5.1.weight\"\n",
            "input: \"encoder.layers.9.res.5.1.bias\"\n",
            "input: \"encoder.layers.9.res.5.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.5.1.running_var\"\n",
            "output: \"912\"\n",
            "name: \"BatchNormalization_261\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"910\"\n",
            "input: \"912\"\n",
            "output: \"913\"\n",
            "name: \"Add_262\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"806\"\n",
            "input: \"encoder.layers.9.res.6.0.weight\"\n",
            "output: \"914\"\n",
            "name: \"Conv_263\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"914\"\n",
            "input: \"encoder.layers.9.res.6.1.weight\"\n",
            "input: \"encoder.layers.9.res.6.1.bias\"\n",
            "input: \"encoder.layers.9.res.6.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.6.1.running_var\"\n",
            "output: \"915\"\n",
            "name: \"BatchNormalization_264\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"913\"\n",
            "input: \"915\"\n",
            "output: \"916\"\n",
            "name: \"Add_265\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"842\"\n",
            "input: \"encoder.layers.9.res.7.0.weight\"\n",
            "output: \"917\"\n",
            "name: \"Conv_266\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"917\"\n",
            "input: \"encoder.layers.9.res.7.1.weight\"\n",
            "input: \"encoder.layers.9.res.7.1.bias\"\n",
            "input: \"encoder.layers.9.res.7.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.7.1.running_var\"\n",
            "output: \"918\"\n",
            "name: \"BatchNormalization_267\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"916\"\n",
            "input: \"918\"\n",
            "output: \"919\"\n",
            "name: \"Add_268\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"881\"\n",
            "input: \"encoder.layers.9.res.8.0.weight\"\n",
            "output: \"920\"\n",
            "name: \"Conv_269\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"920\"\n",
            "input: \"encoder.layers.9.res.8.1.weight\"\n",
            "input: \"encoder.layers.9.res.8.1.bias\"\n",
            "input: \"encoder.layers.9.res.8.1.running_mean\"\n",
            "input: \"encoder.layers.9.res.8.1.running_var\"\n",
            "output: \"921\"\n",
            "name: \"BatchNormalization_270\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"919\"\n",
            "input: \"921\"\n",
            "output: \"922\"\n",
            "name: \"Add_271\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"922\"\n",
            "output: \"923\"\n",
            "name: \"Relu_272\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"923\"\n",
            "input: \"encoder.layers.10.conv.0.weight\"\n",
            "output: \"924\"\n",
            "name: \"Conv_273\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"924\"\n",
            "input: \"encoder.layers.10.conv.1.weight\"\n",
            "input: \"encoder.layers.10.conv.1.bias\"\n",
            "input: \"encoder.layers.10.conv.1.running_mean\"\n",
            "input: \"encoder.layers.10.conv.1.running_var\"\n",
            "output: \"925\"\n",
            "name: \"BatchNormalization_274\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"925\"\n",
            "output: \"926\"\n",
            "name: \"Relu_275\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"926\"\n",
            "input: \"encoder.layers.10.conv.4.weight\"\n",
            "output: \"927\"\n",
            "name: \"Conv_276\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"927\"\n",
            "input: \"encoder.layers.10.conv.5.weight\"\n",
            "input: \"encoder.layers.10.conv.5.bias\"\n",
            "input: \"encoder.layers.10.conv.5.running_mean\"\n",
            "input: \"encoder.layers.10.conv.5.running_var\"\n",
            "output: \"928\"\n",
            "name: \"BatchNormalization_277\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"928\"\n",
            "output: \"929\"\n",
            "name: \"Relu_278\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"929\"\n",
            "input: \"encoder.layers.10.conv.8.weight\"\n",
            "output: \"930\"\n",
            "name: \"Conv_279\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"930\"\n",
            "input: \"encoder.layers.10.conv.9.weight\"\n",
            "input: \"encoder.layers.10.conv.9.bias\"\n",
            "input: \"encoder.layers.10.conv.9.running_mean\"\n",
            "input: \"encoder.layers.10.conv.9.running_var\"\n",
            "output: \"931\"\n",
            "name: \"BatchNormalization_280\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"931\"\n",
            "output: \"932\"\n",
            "name: \"Relu_281\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"932\"\n",
            "input: \"encoder.layers.10.conv.12.weight\"\n",
            "output: \"933\"\n",
            "name: \"Conv_282\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"933\"\n",
            "input: \"encoder.layers.10.conv.13.weight\"\n",
            "input: \"encoder.layers.10.conv.13.bias\"\n",
            "input: \"encoder.layers.10.conv.13.running_mean\"\n",
            "input: \"encoder.layers.10.conv.13.running_var\"\n",
            "output: \"934\"\n",
            "name: \"BatchNormalization_283\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"934\"\n",
            "output: \"935\"\n",
            "name: \"Relu_284\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"935\"\n",
            "input: \"encoder.layers.10.conv.16.weight\"\n",
            "output: \"936\"\n",
            "name: \"Conv_285\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 25\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 12\n",
            "  ints: 12\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"936\"\n",
            "input: \"encoder.layers.10.conv.17.weight\"\n",
            "input: \"encoder.layers.10.conv.17.bias\"\n",
            "input: \"encoder.layers.10.conv.17.running_mean\"\n",
            "input: \"encoder.layers.10.conv.17.running_var\"\n",
            "output: \"937\"\n",
            "name: \"BatchNormalization_286\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"653\"\n",
            "input: \"encoder.layers.10.res.0.0.weight\"\n",
            "output: \"938\"\n",
            "name: \"Conv_287\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"938\"\n",
            "input: \"encoder.layers.10.res.0.1.weight\"\n",
            "input: \"encoder.layers.10.res.0.1.bias\"\n",
            "input: \"encoder.layers.10.res.0.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.0.1.running_var\"\n",
            "output: \"939\"\n",
            "name: \"BatchNormalization_288\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"937\"\n",
            "input: \"939\"\n",
            "output: \"940\"\n",
            "name: \"Add_289\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"671\"\n",
            "input: \"encoder.layers.10.res.1.0.weight\"\n",
            "output: \"941\"\n",
            "name: \"Conv_290\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"941\"\n",
            "input: \"encoder.layers.10.res.1.1.weight\"\n",
            "input: \"encoder.layers.10.res.1.1.bias\"\n",
            "input: \"encoder.layers.10.res.1.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.1.1.running_var\"\n",
            "output: \"942\"\n",
            "name: \"BatchNormalization_291\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"940\"\n",
            "input: \"942\"\n",
            "output: \"943\"\n",
            "name: \"Add_292\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"692\"\n",
            "input: \"encoder.layers.10.res.2.0.weight\"\n",
            "output: \"944\"\n",
            "name: \"Conv_293\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"944\"\n",
            "input: \"encoder.layers.10.res.2.1.weight\"\n",
            "input: \"encoder.layers.10.res.2.1.bias\"\n",
            "input: \"encoder.layers.10.res.2.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.2.1.running_var\"\n",
            "output: \"945\"\n",
            "name: \"BatchNormalization_294\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"943\"\n",
            "input: \"945\"\n",
            "output: \"946\"\n",
            "name: \"Add_295\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"716\"\n",
            "input: \"encoder.layers.10.res.3.0.weight\"\n",
            "output: \"947\"\n",
            "name: \"Conv_296\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"947\"\n",
            "input: \"encoder.layers.10.res.3.1.weight\"\n",
            "input: \"encoder.layers.10.res.3.1.bias\"\n",
            "input: \"encoder.layers.10.res.3.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.3.1.running_var\"\n",
            "output: \"948\"\n",
            "name: \"BatchNormalization_297\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"946\"\n",
            "input: \"948\"\n",
            "output: \"949\"\n",
            "name: \"Add_298\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"743\"\n",
            "input: \"encoder.layers.10.res.4.0.weight\"\n",
            "output: \"950\"\n",
            "name: \"Conv_299\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"950\"\n",
            "input: \"encoder.layers.10.res.4.1.weight\"\n",
            "input: \"encoder.layers.10.res.4.1.bias\"\n",
            "input: \"encoder.layers.10.res.4.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.4.1.running_var\"\n",
            "output: \"951\"\n",
            "name: \"BatchNormalization_300\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"949\"\n",
            "input: \"951\"\n",
            "output: \"952\"\n",
            "name: \"Add_301\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"773\"\n",
            "input: \"encoder.layers.10.res.5.0.weight\"\n",
            "output: \"953\"\n",
            "name: \"Conv_302\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"953\"\n",
            "input: \"encoder.layers.10.res.5.1.weight\"\n",
            "input: \"encoder.layers.10.res.5.1.bias\"\n",
            "input: \"encoder.layers.10.res.5.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.5.1.running_var\"\n",
            "output: \"954\"\n",
            "name: \"BatchNormalization_303\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"952\"\n",
            "input: \"954\"\n",
            "output: \"955\"\n",
            "name: \"Add_304\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"806\"\n",
            "input: \"encoder.layers.10.res.6.0.weight\"\n",
            "output: \"956\"\n",
            "name: \"Conv_305\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"956\"\n",
            "input: \"encoder.layers.10.res.6.1.weight\"\n",
            "input: \"encoder.layers.10.res.6.1.bias\"\n",
            "input: \"encoder.layers.10.res.6.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.6.1.running_var\"\n",
            "output: \"957\"\n",
            "name: \"BatchNormalization_306\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"955\"\n",
            "input: \"957\"\n",
            "output: \"958\"\n",
            "name: \"Add_307\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"842\"\n",
            "input: \"encoder.layers.10.res.7.0.weight\"\n",
            "output: \"959\"\n",
            "name: \"Conv_308\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"959\"\n",
            "input: \"encoder.layers.10.res.7.1.weight\"\n",
            "input: \"encoder.layers.10.res.7.1.bias\"\n",
            "input: \"encoder.layers.10.res.7.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.7.1.running_var\"\n",
            "output: \"960\"\n",
            "name: \"BatchNormalization_309\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"958\"\n",
            "input: \"960\"\n",
            "output: \"961\"\n",
            "name: \"Add_310\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"881\"\n",
            "input: \"encoder.layers.10.res.8.0.weight\"\n",
            "output: \"962\"\n",
            "name: \"Conv_311\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"962\"\n",
            "input: \"encoder.layers.10.res.8.1.weight\"\n",
            "input: \"encoder.layers.10.res.8.1.bias\"\n",
            "input: \"encoder.layers.10.res.8.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.8.1.running_var\"\n",
            "output: \"963\"\n",
            "name: \"BatchNormalization_312\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"961\"\n",
            "input: \"963\"\n",
            "output: \"964\"\n",
            "name: \"Add_313\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"923\"\n",
            "input: \"encoder.layers.10.res.9.0.weight\"\n",
            "output: \"965\"\n",
            "name: \"Conv_314\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"965\"\n",
            "input: \"encoder.layers.10.res.9.1.weight\"\n",
            "input: \"encoder.layers.10.res.9.1.bias\"\n",
            "input: \"encoder.layers.10.res.9.1.running_mean\"\n",
            "input: \"encoder.layers.10.res.9.1.running_var\"\n",
            "output: \"966\"\n",
            "name: \"BatchNormalization_315\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"964\"\n",
            "input: \"966\"\n",
            "output: \"967\"\n",
            "name: \"Add_316\"\n",
            "op_type: \"Add\"\n",
            "\n",
            "input: \"967\"\n",
            "output: \"968\"\n",
            "name: \"Relu_317\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"968\"\n",
            "input: \"encoder.layers.11.conv.0.weight\"\n",
            "output: \"969\"\n",
            "name: \"Conv_318\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 2\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 29\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 28\n",
            "  ints: 28\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"969\"\n",
            "input: \"encoder.layers.11.conv.1.weight\"\n",
            "input: \"encoder.layers.11.conv.1.bias\"\n",
            "input: \"encoder.layers.11.conv.1.running_mean\"\n",
            "input: \"encoder.layers.11.conv.1.running_var\"\n",
            "output: \"970\"\n",
            "name: \"BatchNormalization_319\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"970\"\n",
            "output: \"971\"\n",
            "name: \"Relu_320\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"971\"\n",
            "input: \"encoder.layers.12.conv.0.weight\"\n",
            "output: \"972\"\n",
            "name: \"Conv_321\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"972\"\n",
            "input: \"encoder.layers.12.conv.1.weight\"\n",
            "input: \"encoder.layers.12.conv.1.bias\"\n",
            "input: \"encoder.layers.12.conv.1.running_mean\"\n",
            "input: \"encoder.layers.12.conv.1.running_var\"\n",
            "output: \"973\"\n",
            "name: \"BatchNormalization_322\"\n",
            "op_type: \"BatchNormalization\"\n",
            "attribute {\n",
            "  name: \"epsilon\"\n",
            "  f: 0.0010000000474974513\n",
            "  type: FLOAT\n",
            "}\n",
            "attribute {\n",
            "  name: \"momentum\"\n",
            "  f: 0.8999999761581421\n",
            "  type: FLOAT\n",
            "}\n",
            "\n",
            "input: \"973\"\n",
            "output: \"974\"\n",
            "name: \"Relu_323\"\n",
            "op_type: \"Relu\"\n",
            "\n",
            "input: \"974\"\n",
            "input: \"decoder.layers.0.weight\"\n",
            "input: \"decoder.layers.0.bias\"\n",
            "output: \"975\"\n",
            "name: \"Conv_324\"\n",
            "op_type: \"Conv\"\n",
            "attribute {\n",
            "  name: \"dilations\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"group\"\n",
            "  i: 1\n",
            "  type: INT\n",
            "}\n",
            "attribute {\n",
            "  name: \"kernel_shape\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"pads\"\n",
            "  ints: 0\n",
            "  ints: 0\n",
            "  type: INTS\n",
            "}\n",
            "attribute {\n",
            "  name: \"strides\"\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"975\"\n",
            "output: \"976\"\n",
            "name: \"Transpose_325\"\n",
            "op_type: \"Transpose\"\n",
            "attribute {\n",
            "  name: \"perm\"\n",
            "  ints: 0\n",
            "  ints: 2\n",
            "  ints: 1\n",
            "  type: INTS\n",
            "}\n",
            "\n",
            "input: \"976\"\n",
            "output: \"output__0\"\n",
            "name: \"LogSoftmax_326\"\n",
            "op_type: \"LogSoftmax\"\n",
            "attribute {\n",
            "  name: \"axis\"\n",
            "  i: 2\n",
            "  type: INT\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsuw3n3TpIn8",
        "outputId": "fcfcf4f0-3a82-49f1-c7b9-a7d3c405321f"
      },
      "source": [
        "for i in range(16):\n",
        "    print(i,onnx.TensorProto.DataType.Name(i))\n",
        "# 17 data types. Input is of type Float16. should change it to Float i.e. 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 UNDEFINED\n",
            "1 FLOAT\n",
            "2 UINT8\n",
            "3 INT8\n",
            "4 UINT16\n",
            "5 INT16\n",
            "6 INT32\n",
            "7 INT64\n",
            "8 STRING\n",
            "9 BOOL\n",
            "10 FLOAT16\n",
            "11 DOUBLE\n",
            "12 UINT32\n",
            "13 UINT64\n",
            "14 COMPLEX64\n",
            "15 COMPLEX128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjuMTcK1tWkm"
      },
      "source": [
        "# Change input data type FLOAT16 ==> FLOAT\n",
        "inp = model.graph.input[0]\n",
        "model.graph.input.remove(inp)\n",
        "inp.type.tensor_type.elem_type = 1\n",
        "model.graph.input.insert(0,inp)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gipxj17pplbB"
      },
      "source": [
        "# Change output data type FLOAT16 ==> FLOAT\n",
        "out = model.graph.output[0]\n",
        "model.graph.output.remove(out)\n",
        "out.type.tensor_type.elem_type = 1\n",
        "model.graph.output.insert(0,out)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A-lghvVrJnC",
        "outputId": "6f6dfe05-7c81-4f65-e04a-322c8798ba24"
      },
      "source": [
        "model.graph.input"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"input__0\"\n",
              "type {\n",
              "  tensor_type {\n",
              "    elem_type: 1\n",
              "    shape {\n",
              "      dim {\n",
              "        dim_param: \"input__0_dynamic_axes_1\"\n",
              "      }\n",
              "      dim {\n",
              "        dim_value: 64\n",
              "      }\n",
              "      dim {\n",
              "        dim_param: \"input__0_dynamic_axes_2\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}\n",
              "]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGf2iduHvucA"
      },
      "source": [
        "# Change data type FLOAT16 ==> FLOAT of every initilizer\n",
        "for i,init in enumerate(model.graph.initializer):\n",
        "    model.graph.initializer.remove(init)\n",
        "    init.data_type = 1\n",
        "    model.graph.initializer.insert(i,init)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bG8Ha-k5K3d",
        "outputId": "7a39f80b-2bf1-4340-dfa7-cbe8aabcbc6b"
      },
      "source": [
        "print(onnx.helper.printable_graph(model.graph))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph torch-jit-export (\n",
            "  %input__0[FLOAT, input__0_dynamic_axes_1x64xinput__0_dynamic_axes_2]\n",
            ") initializers (\n",
            "  %decoder.layers.0.bias[FLOAT, 29]\n",
            "  %decoder.layers.0.weight[FLOAT, 29x1024x1]\n",
            "  %encoder.layers.0.conv.0.weight[FLOAT, 256x64x11]\n",
            "  %encoder.layers.0.conv.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.0.conv.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.0.conv.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.0.conv.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.0.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.12.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.13.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.13.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.13.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.13.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.16.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.17.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.17.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.17.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.17.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.4.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.5.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.5.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.5.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.5.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.8.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.9.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.9.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.9.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.9.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.0.weight[FLOAT, 256x256x1]\n",
            "  %encoder.layers.1.res.0.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.10.conv.0.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.12.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.13.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.13.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.13.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.13.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.16.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.17.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.17.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.17.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.17.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.4.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.5.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.5.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.5.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.5.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.8.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.9.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.9.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.9.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.9.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.10.res.0.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.10.res.1.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.10.res.2.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.10.res.3.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.10.res.4.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.10.res.5.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.10.res.6.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.10.res.7.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.10.res.8.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.0.weight[FLOAT, 768x768x1]\n",
            "  %encoder.layers.10.res.9.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.11.conv.0.weight[FLOAT, 896x768x29]\n",
            "  %encoder.layers.11.conv.1.bias[FLOAT, 896]\n",
            "  %encoder.layers.11.conv.1.running_mean[FLOAT, 896]\n",
            "  %encoder.layers.11.conv.1.running_var[FLOAT, 896]\n",
            "  %encoder.layers.11.conv.1.weight[FLOAT, 896]\n",
            "  %encoder.layers.12.conv.0.weight[FLOAT, 1024x896x1]\n",
            "  %encoder.layers.12.conv.1.bias[FLOAT, 1024]\n",
            "  %encoder.layers.12.conv.1.running_mean[FLOAT, 1024]\n",
            "  %encoder.layers.12.conv.1.running_var[FLOAT, 1024]\n",
            "  %encoder.layers.12.conv.1.weight[FLOAT, 1024]\n",
            "  %encoder.layers.2.conv.0.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.12.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.13.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.13.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.13.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.13.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.16.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.17.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.17.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.17.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.17.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.4.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.5.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.5.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.5.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.5.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.8.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.9.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.9.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.9.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.9.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.0.weight[FLOAT, 256x256x1]\n",
            "  %encoder.layers.2.res.0.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.0.weight[FLOAT, 256x256x1]\n",
            "  %encoder.layers.2.res.1.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.3.conv.0.weight[FLOAT, 384x256x13]\n",
            "  %encoder.layers.3.conv.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.12.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.13.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.13.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.13.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.13.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.16.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.17.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.17.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.17.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.17.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.4.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.5.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.5.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.5.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.5.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.8.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.9.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.9.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.9.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.9.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.3.res.0.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.3.res.1.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.3.res.2.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.0.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.12.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.13.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.13.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.13.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.13.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.16.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.17.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.17.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.17.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.17.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.4.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.5.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.5.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.5.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.5.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.8.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.9.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.9.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.9.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.9.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.4.res.0.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.4.res.1.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.4.res.2.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.0.weight[FLOAT, 384x384x1]\n",
            "  %encoder.layers.4.res.3.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.5.conv.0.weight[FLOAT, 512x384x17]\n",
            "  %encoder.layers.5.conv.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.12.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.13.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.13.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.13.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.13.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.16.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.17.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.17.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.17.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.17.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.4.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.5.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.5.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.5.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.5.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.8.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.9.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.9.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.9.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.9.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.5.res.0.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.5.res.1.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.5.res.2.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.5.res.3.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.5.res.4.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.0.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.12.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.13.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.13.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.13.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.13.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.16.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.17.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.17.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.17.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.17.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.4.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.5.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.5.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.5.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.5.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.8.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.9.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.9.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.9.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.9.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.6.res.0.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.6.res.1.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.6.res.2.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.6.res.3.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.6.res.4.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.0.weight[FLOAT, 512x512x1]\n",
            "  %encoder.layers.6.res.5.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.7.conv.0.weight[FLOAT, 640x512x21]\n",
            "  %encoder.layers.7.conv.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.12.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.13.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.13.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.13.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.13.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.16.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.17.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.17.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.17.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.17.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.4.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.5.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.5.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.5.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.5.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.8.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.9.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.9.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.9.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.9.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.7.res.0.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.7.res.1.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.7.res.2.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.7.res.3.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.7.res.4.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.7.res.5.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.7.res.6.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.0.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.12.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.13.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.13.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.13.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.13.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.16.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.17.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.17.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.17.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.17.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.4.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.5.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.5.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.5.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.5.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.8.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.9.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.9.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.9.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.9.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.8.res.0.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.8.res.1.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.8.res.2.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.8.res.3.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.8.res.4.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.8.res.5.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.8.res.6.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.0.weight[FLOAT, 640x640x1]\n",
            "  %encoder.layers.8.res.7.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.9.conv.0.weight[FLOAT, 768x640x25]\n",
            "  %encoder.layers.9.conv.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.12.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.13.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.13.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.13.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.13.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.16.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.17.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.17.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.17.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.17.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.4.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.5.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.5.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.5.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.5.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.8.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.9.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.9.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.9.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.9.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.9.res.0.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.9.res.1.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.9.res.2.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.9.res.3.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.9.res.4.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.9.res.5.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.9.res.6.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.9.res.7.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.9.res.8.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.1.weight[FLOAT, 768]\n",
            ") {\n",
            "  %651 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [2]](%input__0, %encoder.layers.0.conv.0.weight)\n",
            "  %652 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%651, %encoder.layers.0.conv.1.weight, %encoder.layers.0.conv.1.bias, %encoder.layers.0.conv.1.running_mean, %encoder.layers.0.conv.1.running_var)\n",
            "  %653 = Relu(%652)\n",
            "  %654 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%653, %encoder.layers.1.conv.0.weight)\n",
            "  %655 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%654, %encoder.layers.1.conv.1.weight, %encoder.layers.1.conv.1.bias, %encoder.layers.1.conv.1.running_mean, %encoder.layers.1.conv.1.running_var)\n",
            "  %656 = Relu(%655)\n",
            "  %657 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%656, %encoder.layers.1.conv.4.weight)\n",
            "  %658 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%657, %encoder.layers.1.conv.5.weight, %encoder.layers.1.conv.5.bias, %encoder.layers.1.conv.5.running_mean, %encoder.layers.1.conv.5.running_var)\n",
            "  %659 = Relu(%658)\n",
            "  %660 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%659, %encoder.layers.1.conv.8.weight)\n",
            "  %661 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%660, %encoder.layers.1.conv.9.weight, %encoder.layers.1.conv.9.bias, %encoder.layers.1.conv.9.running_mean, %encoder.layers.1.conv.9.running_var)\n",
            "  %662 = Relu(%661)\n",
            "  %663 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%662, %encoder.layers.1.conv.12.weight)\n",
            "  %664 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%663, %encoder.layers.1.conv.13.weight, %encoder.layers.1.conv.13.bias, %encoder.layers.1.conv.13.running_mean, %encoder.layers.1.conv.13.running_var)\n",
            "  %665 = Relu(%664)\n",
            "  %666 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%665, %encoder.layers.1.conv.16.weight)\n",
            "  %667 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%666, %encoder.layers.1.conv.17.weight, %encoder.layers.1.conv.17.bias, %encoder.layers.1.conv.17.running_mean, %encoder.layers.1.conv.17.running_var)\n",
            "  %668 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.1.res.0.0.weight)\n",
            "  %669 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%668, %encoder.layers.1.res.0.1.weight, %encoder.layers.1.res.0.1.bias, %encoder.layers.1.res.0.1.running_mean, %encoder.layers.1.res.0.1.running_var)\n",
            "  %670 = Add(%667, %669)\n",
            "  %671 = Relu(%670)\n",
            "  %672 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%671, %encoder.layers.2.conv.0.weight)\n",
            "  %673 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%672, %encoder.layers.2.conv.1.weight, %encoder.layers.2.conv.1.bias, %encoder.layers.2.conv.1.running_mean, %encoder.layers.2.conv.1.running_var)\n",
            "  %674 = Relu(%673)\n",
            "  %675 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%674, %encoder.layers.2.conv.4.weight)\n",
            "  %676 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%675, %encoder.layers.2.conv.5.weight, %encoder.layers.2.conv.5.bias, %encoder.layers.2.conv.5.running_mean, %encoder.layers.2.conv.5.running_var)\n",
            "  %677 = Relu(%676)\n",
            "  %678 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%677, %encoder.layers.2.conv.8.weight)\n",
            "  %679 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%678, %encoder.layers.2.conv.9.weight, %encoder.layers.2.conv.9.bias, %encoder.layers.2.conv.9.running_mean, %encoder.layers.2.conv.9.running_var)\n",
            "  %680 = Relu(%679)\n",
            "  %681 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%680, %encoder.layers.2.conv.12.weight)\n",
            "  %682 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%681, %encoder.layers.2.conv.13.weight, %encoder.layers.2.conv.13.bias, %encoder.layers.2.conv.13.running_mean, %encoder.layers.2.conv.13.running_var)\n",
            "  %683 = Relu(%682)\n",
            "  %684 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%683, %encoder.layers.2.conv.16.weight)\n",
            "  %685 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%684, %encoder.layers.2.conv.17.weight, %encoder.layers.2.conv.17.bias, %encoder.layers.2.conv.17.running_mean, %encoder.layers.2.conv.17.running_var)\n",
            "  %686 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.2.res.0.0.weight)\n",
            "  %687 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%686, %encoder.layers.2.res.0.1.weight, %encoder.layers.2.res.0.1.bias, %encoder.layers.2.res.0.1.running_mean, %encoder.layers.2.res.0.1.running_var)\n",
            "  %688 = Add(%685, %687)\n",
            "  %689 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.2.res.1.0.weight)\n",
            "  %690 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%689, %encoder.layers.2.res.1.1.weight, %encoder.layers.2.res.1.1.bias, %encoder.layers.2.res.1.1.running_mean, %encoder.layers.2.res.1.1.running_var)\n",
            "  %691 = Add(%688, %690)\n",
            "  %692 = Relu(%691)\n",
            "  %693 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%692, %encoder.layers.3.conv.0.weight)\n",
            "  %694 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%693, %encoder.layers.3.conv.1.weight, %encoder.layers.3.conv.1.bias, %encoder.layers.3.conv.1.running_mean, %encoder.layers.3.conv.1.running_var)\n",
            "  %695 = Relu(%694)\n",
            "  %696 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%695, %encoder.layers.3.conv.4.weight)\n",
            "  %697 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%696, %encoder.layers.3.conv.5.weight, %encoder.layers.3.conv.5.bias, %encoder.layers.3.conv.5.running_mean, %encoder.layers.3.conv.5.running_var)\n",
            "  %698 = Relu(%697)\n",
            "  %699 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%698, %encoder.layers.3.conv.8.weight)\n",
            "  %700 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%699, %encoder.layers.3.conv.9.weight, %encoder.layers.3.conv.9.bias, %encoder.layers.3.conv.9.running_mean, %encoder.layers.3.conv.9.running_var)\n",
            "  %701 = Relu(%700)\n",
            "  %702 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%701, %encoder.layers.3.conv.12.weight)\n",
            "  %703 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%702, %encoder.layers.3.conv.13.weight, %encoder.layers.3.conv.13.bias, %encoder.layers.3.conv.13.running_mean, %encoder.layers.3.conv.13.running_var)\n",
            "  %704 = Relu(%703)\n",
            "  %705 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%704, %encoder.layers.3.conv.16.weight)\n",
            "  %706 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%705, %encoder.layers.3.conv.17.weight, %encoder.layers.3.conv.17.bias, %encoder.layers.3.conv.17.running_mean, %encoder.layers.3.conv.17.running_var)\n",
            "  %707 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.3.res.0.0.weight)\n",
            "  %708 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%707, %encoder.layers.3.res.0.1.weight, %encoder.layers.3.res.0.1.bias, %encoder.layers.3.res.0.1.running_mean, %encoder.layers.3.res.0.1.running_var)\n",
            "  %709 = Add(%706, %708)\n",
            "  %710 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.3.res.1.0.weight)\n",
            "  %711 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%710, %encoder.layers.3.res.1.1.weight, %encoder.layers.3.res.1.1.bias, %encoder.layers.3.res.1.1.running_mean, %encoder.layers.3.res.1.1.running_var)\n",
            "  %712 = Add(%709, %711)\n",
            "  %713 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.3.res.2.0.weight)\n",
            "  %714 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%713, %encoder.layers.3.res.2.1.weight, %encoder.layers.3.res.2.1.bias, %encoder.layers.3.res.2.1.running_mean, %encoder.layers.3.res.2.1.running_var)\n",
            "  %715 = Add(%712, %714)\n",
            "  %716 = Relu(%715)\n",
            "  %717 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%716, %encoder.layers.4.conv.0.weight)\n",
            "  %718 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%717, %encoder.layers.4.conv.1.weight, %encoder.layers.4.conv.1.bias, %encoder.layers.4.conv.1.running_mean, %encoder.layers.4.conv.1.running_var)\n",
            "  %719 = Relu(%718)\n",
            "  %720 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%719, %encoder.layers.4.conv.4.weight)\n",
            "  %721 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%720, %encoder.layers.4.conv.5.weight, %encoder.layers.4.conv.5.bias, %encoder.layers.4.conv.5.running_mean, %encoder.layers.4.conv.5.running_var)\n",
            "  %722 = Relu(%721)\n",
            "  %723 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%722, %encoder.layers.4.conv.8.weight)\n",
            "  %724 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%723, %encoder.layers.4.conv.9.weight, %encoder.layers.4.conv.9.bias, %encoder.layers.4.conv.9.running_mean, %encoder.layers.4.conv.9.running_var)\n",
            "  %725 = Relu(%724)\n",
            "  %726 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%725, %encoder.layers.4.conv.12.weight)\n",
            "  %727 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%726, %encoder.layers.4.conv.13.weight, %encoder.layers.4.conv.13.bias, %encoder.layers.4.conv.13.running_mean, %encoder.layers.4.conv.13.running_var)\n",
            "  %728 = Relu(%727)\n",
            "  %729 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%728, %encoder.layers.4.conv.16.weight)\n",
            "  %730 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%729, %encoder.layers.4.conv.17.weight, %encoder.layers.4.conv.17.bias, %encoder.layers.4.conv.17.running_mean, %encoder.layers.4.conv.17.running_var)\n",
            "  %731 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.4.res.0.0.weight)\n",
            "  %732 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%731, %encoder.layers.4.res.0.1.weight, %encoder.layers.4.res.0.1.bias, %encoder.layers.4.res.0.1.running_mean, %encoder.layers.4.res.0.1.running_var)\n",
            "  %733 = Add(%730, %732)\n",
            "  %734 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.4.res.1.0.weight)\n",
            "  %735 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%734, %encoder.layers.4.res.1.1.weight, %encoder.layers.4.res.1.1.bias, %encoder.layers.4.res.1.1.running_mean, %encoder.layers.4.res.1.1.running_var)\n",
            "  %736 = Add(%733, %735)\n",
            "  %737 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.4.res.2.0.weight)\n",
            "  %738 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%737, %encoder.layers.4.res.2.1.weight, %encoder.layers.4.res.2.1.bias, %encoder.layers.4.res.2.1.running_mean, %encoder.layers.4.res.2.1.running_var)\n",
            "  %739 = Add(%736, %738)\n",
            "  %740 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.4.res.3.0.weight)\n",
            "  %741 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%740, %encoder.layers.4.res.3.1.weight, %encoder.layers.4.res.3.1.bias, %encoder.layers.4.res.3.1.running_mean, %encoder.layers.4.res.3.1.running_var)\n",
            "  %742 = Add(%739, %741)\n",
            "  %743 = Relu(%742)\n",
            "  %744 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%743, %encoder.layers.5.conv.0.weight)\n",
            "  %745 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%744, %encoder.layers.5.conv.1.weight, %encoder.layers.5.conv.1.bias, %encoder.layers.5.conv.1.running_mean, %encoder.layers.5.conv.1.running_var)\n",
            "  %746 = Relu(%745)\n",
            "  %747 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%746, %encoder.layers.5.conv.4.weight)\n",
            "  %748 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%747, %encoder.layers.5.conv.5.weight, %encoder.layers.5.conv.5.bias, %encoder.layers.5.conv.5.running_mean, %encoder.layers.5.conv.5.running_var)\n",
            "  %749 = Relu(%748)\n",
            "  %750 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%749, %encoder.layers.5.conv.8.weight)\n",
            "  %751 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%750, %encoder.layers.5.conv.9.weight, %encoder.layers.5.conv.9.bias, %encoder.layers.5.conv.9.running_mean, %encoder.layers.5.conv.9.running_var)\n",
            "  %752 = Relu(%751)\n",
            "  %753 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%752, %encoder.layers.5.conv.12.weight)\n",
            "  %754 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%753, %encoder.layers.5.conv.13.weight, %encoder.layers.5.conv.13.bias, %encoder.layers.5.conv.13.running_mean, %encoder.layers.5.conv.13.running_var)\n",
            "  %755 = Relu(%754)\n",
            "  %756 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%755, %encoder.layers.5.conv.16.weight)\n",
            "  %757 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%756, %encoder.layers.5.conv.17.weight, %encoder.layers.5.conv.17.bias, %encoder.layers.5.conv.17.running_mean, %encoder.layers.5.conv.17.running_var)\n",
            "  %758 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.5.res.0.0.weight)\n",
            "  %759 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%758, %encoder.layers.5.res.0.1.weight, %encoder.layers.5.res.0.1.bias, %encoder.layers.5.res.0.1.running_mean, %encoder.layers.5.res.0.1.running_var)\n",
            "  %760 = Add(%757, %759)\n",
            "  %761 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.5.res.1.0.weight)\n",
            "  %762 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%761, %encoder.layers.5.res.1.1.weight, %encoder.layers.5.res.1.1.bias, %encoder.layers.5.res.1.1.running_mean, %encoder.layers.5.res.1.1.running_var)\n",
            "  %763 = Add(%760, %762)\n",
            "  %764 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.5.res.2.0.weight)\n",
            "  %765 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%764, %encoder.layers.5.res.2.1.weight, %encoder.layers.5.res.2.1.bias, %encoder.layers.5.res.2.1.running_mean, %encoder.layers.5.res.2.1.running_var)\n",
            "  %766 = Add(%763, %765)\n",
            "  %767 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.5.res.3.0.weight)\n",
            "  %768 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%767, %encoder.layers.5.res.3.1.weight, %encoder.layers.5.res.3.1.bias, %encoder.layers.5.res.3.1.running_mean, %encoder.layers.5.res.3.1.running_var)\n",
            "  %769 = Add(%766, %768)\n",
            "  %770 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.5.res.4.0.weight)\n",
            "  %771 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%770, %encoder.layers.5.res.4.1.weight, %encoder.layers.5.res.4.1.bias, %encoder.layers.5.res.4.1.running_mean, %encoder.layers.5.res.4.1.running_var)\n",
            "  %772 = Add(%769, %771)\n",
            "  %773 = Relu(%772)\n",
            "  %774 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%773, %encoder.layers.6.conv.0.weight)\n",
            "  %775 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%774, %encoder.layers.6.conv.1.weight, %encoder.layers.6.conv.1.bias, %encoder.layers.6.conv.1.running_mean, %encoder.layers.6.conv.1.running_var)\n",
            "  %776 = Relu(%775)\n",
            "  %777 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%776, %encoder.layers.6.conv.4.weight)\n",
            "  %778 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%777, %encoder.layers.6.conv.5.weight, %encoder.layers.6.conv.5.bias, %encoder.layers.6.conv.5.running_mean, %encoder.layers.6.conv.5.running_var)\n",
            "  %779 = Relu(%778)\n",
            "  %780 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%779, %encoder.layers.6.conv.8.weight)\n",
            "  %781 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%780, %encoder.layers.6.conv.9.weight, %encoder.layers.6.conv.9.bias, %encoder.layers.6.conv.9.running_mean, %encoder.layers.6.conv.9.running_var)\n",
            "  %782 = Relu(%781)\n",
            "  %783 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%782, %encoder.layers.6.conv.12.weight)\n",
            "  %784 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%783, %encoder.layers.6.conv.13.weight, %encoder.layers.6.conv.13.bias, %encoder.layers.6.conv.13.running_mean, %encoder.layers.6.conv.13.running_var)\n",
            "  %785 = Relu(%784)\n",
            "  %786 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%785, %encoder.layers.6.conv.16.weight)\n",
            "  %787 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%786, %encoder.layers.6.conv.17.weight, %encoder.layers.6.conv.17.bias, %encoder.layers.6.conv.17.running_mean, %encoder.layers.6.conv.17.running_var)\n",
            "  %788 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.6.res.0.0.weight)\n",
            "  %789 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%788, %encoder.layers.6.res.0.1.weight, %encoder.layers.6.res.0.1.bias, %encoder.layers.6.res.0.1.running_mean, %encoder.layers.6.res.0.1.running_var)\n",
            "  %790 = Add(%787, %789)\n",
            "  %791 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.6.res.1.0.weight)\n",
            "  %792 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%791, %encoder.layers.6.res.1.1.weight, %encoder.layers.6.res.1.1.bias, %encoder.layers.6.res.1.1.running_mean, %encoder.layers.6.res.1.1.running_var)\n",
            "  %793 = Add(%790, %792)\n",
            "  %794 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.6.res.2.0.weight)\n",
            "  %795 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%794, %encoder.layers.6.res.2.1.weight, %encoder.layers.6.res.2.1.bias, %encoder.layers.6.res.2.1.running_mean, %encoder.layers.6.res.2.1.running_var)\n",
            "  %796 = Add(%793, %795)\n",
            "  %797 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.6.res.3.0.weight)\n",
            "  %798 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%797, %encoder.layers.6.res.3.1.weight, %encoder.layers.6.res.3.1.bias, %encoder.layers.6.res.3.1.running_mean, %encoder.layers.6.res.3.1.running_var)\n",
            "  %799 = Add(%796, %798)\n",
            "  %800 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.6.res.4.0.weight)\n",
            "  %801 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%800, %encoder.layers.6.res.4.1.weight, %encoder.layers.6.res.4.1.bias, %encoder.layers.6.res.4.1.running_mean, %encoder.layers.6.res.4.1.running_var)\n",
            "  %802 = Add(%799, %801)\n",
            "  %803 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.6.res.5.0.weight)\n",
            "  %804 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%803, %encoder.layers.6.res.5.1.weight, %encoder.layers.6.res.5.1.bias, %encoder.layers.6.res.5.1.running_mean, %encoder.layers.6.res.5.1.running_var)\n",
            "  %805 = Add(%802, %804)\n",
            "  %806 = Relu(%805)\n",
            "  %807 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%806, %encoder.layers.7.conv.0.weight)\n",
            "  %808 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%807, %encoder.layers.7.conv.1.weight, %encoder.layers.7.conv.1.bias, %encoder.layers.7.conv.1.running_mean, %encoder.layers.7.conv.1.running_var)\n",
            "  %809 = Relu(%808)\n",
            "  %810 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%809, %encoder.layers.7.conv.4.weight)\n",
            "  %811 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%810, %encoder.layers.7.conv.5.weight, %encoder.layers.7.conv.5.bias, %encoder.layers.7.conv.5.running_mean, %encoder.layers.7.conv.5.running_var)\n",
            "  %812 = Relu(%811)\n",
            "  %813 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%812, %encoder.layers.7.conv.8.weight)\n",
            "  %814 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%813, %encoder.layers.7.conv.9.weight, %encoder.layers.7.conv.9.bias, %encoder.layers.7.conv.9.running_mean, %encoder.layers.7.conv.9.running_var)\n",
            "  %815 = Relu(%814)\n",
            "  %816 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%815, %encoder.layers.7.conv.12.weight)\n",
            "  %817 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%816, %encoder.layers.7.conv.13.weight, %encoder.layers.7.conv.13.bias, %encoder.layers.7.conv.13.running_mean, %encoder.layers.7.conv.13.running_var)\n",
            "  %818 = Relu(%817)\n",
            "  %819 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%818, %encoder.layers.7.conv.16.weight)\n",
            "  %820 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%819, %encoder.layers.7.conv.17.weight, %encoder.layers.7.conv.17.bias, %encoder.layers.7.conv.17.running_mean, %encoder.layers.7.conv.17.running_var)\n",
            "  %821 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.7.res.0.0.weight)\n",
            "  %822 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%821, %encoder.layers.7.res.0.1.weight, %encoder.layers.7.res.0.1.bias, %encoder.layers.7.res.0.1.running_mean, %encoder.layers.7.res.0.1.running_var)\n",
            "  %823 = Add(%820, %822)\n",
            "  %824 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.7.res.1.0.weight)\n",
            "  %825 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%824, %encoder.layers.7.res.1.1.weight, %encoder.layers.7.res.1.1.bias, %encoder.layers.7.res.1.1.running_mean, %encoder.layers.7.res.1.1.running_var)\n",
            "  %826 = Add(%823, %825)\n",
            "  %827 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.7.res.2.0.weight)\n",
            "  %828 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%827, %encoder.layers.7.res.2.1.weight, %encoder.layers.7.res.2.1.bias, %encoder.layers.7.res.2.1.running_mean, %encoder.layers.7.res.2.1.running_var)\n",
            "  %829 = Add(%826, %828)\n",
            "  %830 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.7.res.3.0.weight)\n",
            "  %831 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%830, %encoder.layers.7.res.3.1.weight, %encoder.layers.7.res.3.1.bias, %encoder.layers.7.res.3.1.running_mean, %encoder.layers.7.res.3.1.running_var)\n",
            "  %832 = Add(%829, %831)\n",
            "  %833 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.7.res.4.0.weight)\n",
            "  %834 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%833, %encoder.layers.7.res.4.1.weight, %encoder.layers.7.res.4.1.bias, %encoder.layers.7.res.4.1.running_mean, %encoder.layers.7.res.4.1.running_var)\n",
            "  %835 = Add(%832, %834)\n",
            "  %836 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.7.res.5.0.weight)\n",
            "  %837 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%836, %encoder.layers.7.res.5.1.weight, %encoder.layers.7.res.5.1.bias, %encoder.layers.7.res.5.1.running_mean, %encoder.layers.7.res.5.1.running_var)\n",
            "  %838 = Add(%835, %837)\n",
            "  %839 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.7.res.6.0.weight)\n",
            "  %840 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%839, %encoder.layers.7.res.6.1.weight, %encoder.layers.7.res.6.1.bias, %encoder.layers.7.res.6.1.running_mean, %encoder.layers.7.res.6.1.running_var)\n",
            "  %841 = Add(%838, %840)\n",
            "  %842 = Relu(%841)\n",
            "  %843 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%842, %encoder.layers.8.conv.0.weight)\n",
            "  %844 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%843, %encoder.layers.8.conv.1.weight, %encoder.layers.8.conv.1.bias, %encoder.layers.8.conv.1.running_mean, %encoder.layers.8.conv.1.running_var)\n",
            "  %845 = Relu(%844)\n",
            "  %846 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%845, %encoder.layers.8.conv.4.weight)\n",
            "  %847 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%846, %encoder.layers.8.conv.5.weight, %encoder.layers.8.conv.5.bias, %encoder.layers.8.conv.5.running_mean, %encoder.layers.8.conv.5.running_var)\n",
            "  %848 = Relu(%847)\n",
            "  %849 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%848, %encoder.layers.8.conv.8.weight)\n",
            "  %850 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%849, %encoder.layers.8.conv.9.weight, %encoder.layers.8.conv.9.bias, %encoder.layers.8.conv.9.running_mean, %encoder.layers.8.conv.9.running_var)\n",
            "  %851 = Relu(%850)\n",
            "  %852 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%851, %encoder.layers.8.conv.12.weight)\n",
            "  %853 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%852, %encoder.layers.8.conv.13.weight, %encoder.layers.8.conv.13.bias, %encoder.layers.8.conv.13.running_mean, %encoder.layers.8.conv.13.running_var)\n",
            "  %854 = Relu(%853)\n",
            "  %855 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%854, %encoder.layers.8.conv.16.weight)\n",
            "  %856 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%855, %encoder.layers.8.conv.17.weight, %encoder.layers.8.conv.17.bias, %encoder.layers.8.conv.17.running_mean, %encoder.layers.8.conv.17.running_var)\n",
            "  %857 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.8.res.0.0.weight)\n",
            "  %858 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%857, %encoder.layers.8.res.0.1.weight, %encoder.layers.8.res.0.1.bias, %encoder.layers.8.res.0.1.running_mean, %encoder.layers.8.res.0.1.running_var)\n",
            "  %859 = Add(%856, %858)\n",
            "  %860 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.8.res.1.0.weight)\n",
            "  %861 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%860, %encoder.layers.8.res.1.1.weight, %encoder.layers.8.res.1.1.bias, %encoder.layers.8.res.1.1.running_mean, %encoder.layers.8.res.1.1.running_var)\n",
            "  %862 = Add(%859, %861)\n",
            "  %863 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.8.res.2.0.weight)\n",
            "  %864 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%863, %encoder.layers.8.res.2.1.weight, %encoder.layers.8.res.2.1.bias, %encoder.layers.8.res.2.1.running_mean, %encoder.layers.8.res.2.1.running_var)\n",
            "  %865 = Add(%862, %864)\n",
            "  %866 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.8.res.3.0.weight)\n",
            "  %867 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%866, %encoder.layers.8.res.3.1.weight, %encoder.layers.8.res.3.1.bias, %encoder.layers.8.res.3.1.running_mean, %encoder.layers.8.res.3.1.running_var)\n",
            "  %868 = Add(%865, %867)\n",
            "  %869 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.8.res.4.0.weight)\n",
            "  %870 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%869, %encoder.layers.8.res.4.1.weight, %encoder.layers.8.res.4.1.bias, %encoder.layers.8.res.4.1.running_mean, %encoder.layers.8.res.4.1.running_var)\n",
            "  %871 = Add(%868, %870)\n",
            "  %872 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.8.res.5.0.weight)\n",
            "  %873 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%872, %encoder.layers.8.res.5.1.weight, %encoder.layers.8.res.5.1.bias, %encoder.layers.8.res.5.1.running_mean, %encoder.layers.8.res.5.1.running_var)\n",
            "  %874 = Add(%871, %873)\n",
            "  %875 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.8.res.6.0.weight)\n",
            "  %876 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%875, %encoder.layers.8.res.6.1.weight, %encoder.layers.8.res.6.1.bias, %encoder.layers.8.res.6.1.running_mean, %encoder.layers.8.res.6.1.running_var)\n",
            "  %877 = Add(%874, %876)\n",
            "  %878 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.8.res.7.0.weight)\n",
            "  %879 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%878, %encoder.layers.8.res.7.1.weight, %encoder.layers.8.res.7.1.bias, %encoder.layers.8.res.7.1.running_mean, %encoder.layers.8.res.7.1.running_var)\n",
            "  %880 = Add(%877, %879)\n",
            "  %881 = Relu(%880)\n",
            "  %882 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%881, %encoder.layers.9.conv.0.weight)\n",
            "  %883 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%882, %encoder.layers.9.conv.1.weight, %encoder.layers.9.conv.1.bias, %encoder.layers.9.conv.1.running_mean, %encoder.layers.9.conv.1.running_var)\n",
            "  %884 = Relu(%883)\n",
            "  %885 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%884, %encoder.layers.9.conv.4.weight)\n",
            "  %886 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%885, %encoder.layers.9.conv.5.weight, %encoder.layers.9.conv.5.bias, %encoder.layers.9.conv.5.running_mean, %encoder.layers.9.conv.5.running_var)\n",
            "  %887 = Relu(%886)\n",
            "  %888 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%887, %encoder.layers.9.conv.8.weight)\n",
            "  %889 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%888, %encoder.layers.9.conv.9.weight, %encoder.layers.9.conv.9.bias, %encoder.layers.9.conv.9.running_mean, %encoder.layers.9.conv.9.running_var)\n",
            "  %890 = Relu(%889)\n",
            "  %891 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%890, %encoder.layers.9.conv.12.weight)\n",
            "  %892 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%891, %encoder.layers.9.conv.13.weight, %encoder.layers.9.conv.13.bias, %encoder.layers.9.conv.13.running_mean, %encoder.layers.9.conv.13.running_var)\n",
            "  %893 = Relu(%892)\n",
            "  %894 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%893, %encoder.layers.9.conv.16.weight)\n",
            "  %895 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%894, %encoder.layers.9.conv.17.weight, %encoder.layers.9.conv.17.bias, %encoder.layers.9.conv.17.running_mean, %encoder.layers.9.conv.17.running_var)\n",
            "  %896 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.9.res.0.0.weight)\n",
            "  %897 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%896, %encoder.layers.9.res.0.1.weight, %encoder.layers.9.res.0.1.bias, %encoder.layers.9.res.0.1.running_mean, %encoder.layers.9.res.0.1.running_var)\n",
            "  %898 = Add(%895, %897)\n",
            "  %899 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.9.res.1.0.weight)\n",
            "  %900 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%899, %encoder.layers.9.res.1.1.weight, %encoder.layers.9.res.1.1.bias, %encoder.layers.9.res.1.1.running_mean, %encoder.layers.9.res.1.1.running_var)\n",
            "  %901 = Add(%898, %900)\n",
            "  %902 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.9.res.2.0.weight)\n",
            "  %903 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%902, %encoder.layers.9.res.2.1.weight, %encoder.layers.9.res.2.1.bias, %encoder.layers.9.res.2.1.running_mean, %encoder.layers.9.res.2.1.running_var)\n",
            "  %904 = Add(%901, %903)\n",
            "  %905 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.9.res.3.0.weight)\n",
            "  %906 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%905, %encoder.layers.9.res.3.1.weight, %encoder.layers.9.res.3.1.bias, %encoder.layers.9.res.3.1.running_mean, %encoder.layers.9.res.3.1.running_var)\n",
            "  %907 = Add(%904, %906)\n",
            "  %908 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.9.res.4.0.weight)\n",
            "  %909 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%908, %encoder.layers.9.res.4.1.weight, %encoder.layers.9.res.4.1.bias, %encoder.layers.9.res.4.1.running_mean, %encoder.layers.9.res.4.1.running_var)\n",
            "  %910 = Add(%907, %909)\n",
            "  %911 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.9.res.5.0.weight)\n",
            "  %912 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%911, %encoder.layers.9.res.5.1.weight, %encoder.layers.9.res.5.1.bias, %encoder.layers.9.res.5.1.running_mean, %encoder.layers.9.res.5.1.running_var)\n",
            "  %913 = Add(%910, %912)\n",
            "  %914 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.9.res.6.0.weight)\n",
            "  %915 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%914, %encoder.layers.9.res.6.1.weight, %encoder.layers.9.res.6.1.bias, %encoder.layers.9.res.6.1.running_mean, %encoder.layers.9.res.6.1.running_var)\n",
            "  %916 = Add(%913, %915)\n",
            "  %917 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.9.res.7.0.weight)\n",
            "  %918 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%917, %encoder.layers.9.res.7.1.weight, %encoder.layers.9.res.7.1.bias, %encoder.layers.9.res.7.1.running_mean, %encoder.layers.9.res.7.1.running_var)\n",
            "  %919 = Add(%916, %918)\n",
            "  %920 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%881, %encoder.layers.9.res.8.0.weight)\n",
            "  %921 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%920, %encoder.layers.9.res.8.1.weight, %encoder.layers.9.res.8.1.bias, %encoder.layers.9.res.8.1.running_mean, %encoder.layers.9.res.8.1.running_var)\n",
            "  %922 = Add(%919, %921)\n",
            "  %923 = Relu(%922)\n",
            "  %924 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%923, %encoder.layers.10.conv.0.weight)\n",
            "  %925 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%924, %encoder.layers.10.conv.1.weight, %encoder.layers.10.conv.1.bias, %encoder.layers.10.conv.1.running_mean, %encoder.layers.10.conv.1.running_var)\n",
            "  %926 = Relu(%925)\n",
            "  %927 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%926, %encoder.layers.10.conv.4.weight)\n",
            "  %928 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%927, %encoder.layers.10.conv.5.weight, %encoder.layers.10.conv.5.bias, %encoder.layers.10.conv.5.running_mean, %encoder.layers.10.conv.5.running_var)\n",
            "  %929 = Relu(%928)\n",
            "  %930 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%929, %encoder.layers.10.conv.8.weight)\n",
            "  %931 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%930, %encoder.layers.10.conv.9.weight, %encoder.layers.10.conv.9.bias, %encoder.layers.10.conv.9.running_mean, %encoder.layers.10.conv.9.running_var)\n",
            "  %932 = Relu(%931)\n",
            "  %933 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%932, %encoder.layers.10.conv.12.weight)\n",
            "  %934 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%933, %encoder.layers.10.conv.13.weight, %encoder.layers.10.conv.13.bias, %encoder.layers.10.conv.13.running_mean, %encoder.layers.10.conv.13.running_var)\n",
            "  %935 = Relu(%934)\n",
            "  %936 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%935, %encoder.layers.10.conv.16.weight)\n",
            "  %937 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%936, %encoder.layers.10.conv.17.weight, %encoder.layers.10.conv.17.bias, %encoder.layers.10.conv.17.running_mean, %encoder.layers.10.conv.17.running_var)\n",
            "  %938 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.10.res.0.0.weight)\n",
            "  %939 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%938, %encoder.layers.10.res.0.1.weight, %encoder.layers.10.res.0.1.bias, %encoder.layers.10.res.0.1.running_mean, %encoder.layers.10.res.0.1.running_var)\n",
            "  %940 = Add(%937, %939)\n",
            "  %941 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.10.res.1.0.weight)\n",
            "  %942 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%941, %encoder.layers.10.res.1.1.weight, %encoder.layers.10.res.1.1.bias, %encoder.layers.10.res.1.1.running_mean, %encoder.layers.10.res.1.1.running_var)\n",
            "  %943 = Add(%940, %942)\n",
            "  %944 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.10.res.2.0.weight)\n",
            "  %945 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%944, %encoder.layers.10.res.2.1.weight, %encoder.layers.10.res.2.1.bias, %encoder.layers.10.res.2.1.running_mean, %encoder.layers.10.res.2.1.running_var)\n",
            "  %946 = Add(%943, %945)\n",
            "  %947 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.10.res.3.0.weight)\n",
            "  %948 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%947, %encoder.layers.10.res.3.1.weight, %encoder.layers.10.res.3.1.bias, %encoder.layers.10.res.3.1.running_mean, %encoder.layers.10.res.3.1.running_var)\n",
            "  %949 = Add(%946, %948)\n",
            "  %950 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.10.res.4.0.weight)\n",
            "  %951 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%950, %encoder.layers.10.res.4.1.weight, %encoder.layers.10.res.4.1.bias, %encoder.layers.10.res.4.1.running_mean, %encoder.layers.10.res.4.1.running_var)\n",
            "  %952 = Add(%949, %951)\n",
            "  %953 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.10.res.5.0.weight)\n",
            "  %954 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%953, %encoder.layers.10.res.5.1.weight, %encoder.layers.10.res.5.1.bias, %encoder.layers.10.res.5.1.running_mean, %encoder.layers.10.res.5.1.running_var)\n",
            "  %955 = Add(%952, %954)\n",
            "  %956 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.10.res.6.0.weight)\n",
            "  %957 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%956, %encoder.layers.10.res.6.1.weight, %encoder.layers.10.res.6.1.bias, %encoder.layers.10.res.6.1.running_mean, %encoder.layers.10.res.6.1.running_var)\n",
            "  %958 = Add(%955, %957)\n",
            "  %959 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.10.res.7.0.weight)\n",
            "  %960 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%959, %encoder.layers.10.res.7.1.weight, %encoder.layers.10.res.7.1.bias, %encoder.layers.10.res.7.1.running_mean, %encoder.layers.10.res.7.1.running_var)\n",
            "  %961 = Add(%958, %960)\n",
            "  %962 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%881, %encoder.layers.10.res.8.0.weight)\n",
            "  %963 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%962, %encoder.layers.10.res.8.1.weight, %encoder.layers.10.res.8.1.bias, %encoder.layers.10.res.8.1.running_mean, %encoder.layers.10.res.8.1.running_var)\n",
            "  %964 = Add(%961, %963)\n",
            "  %965 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%923, %encoder.layers.10.res.9.0.weight)\n",
            "  %966 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%965, %encoder.layers.10.res.9.1.weight, %encoder.layers.10.res.9.1.bias, %encoder.layers.10.res.9.1.running_mean, %encoder.layers.10.res.9.1.running_var)\n",
            "  %967 = Add(%964, %966)\n",
            "  %968 = Relu(%967)\n",
            "  %969 = Conv[dilations = [2], group = 1, kernel_shape = [29], pads = [28, 28], strides = [1]](%968, %encoder.layers.11.conv.0.weight)\n",
            "  %970 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%969, %encoder.layers.11.conv.1.weight, %encoder.layers.11.conv.1.bias, %encoder.layers.11.conv.1.running_mean, %encoder.layers.11.conv.1.running_var)\n",
            "  %971 = Relu(%970)\n",
            "  %972 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%971, %encoder.layers.12.conv.0.weight)\n",
            "  %973 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%972, %encoder.layers.12.conv.1.weight, %encoder.layers.12.conv.1.bias, %encoder.layers.12.conv.1.running_mean, %encoder.layers.12.conv.1.running_var)\n",
            "  %974 = Relu(%973)\n",
            "  %975 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%974, %decoder.layers.0.weight, %decoder.layers.0.bias)\n",
            "  %976 = Transpose[perm = [0, 2, 1]](%975)\n",
            "  %output__0 = LogSoftmax[axis = 2](%976)\n",
            "  return %output__0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb9k8i429XnX"
      },
      "source": [
        "with open('jasper_dynamic_input_float.onnx','wb') as f:\n",
        "    onnx.save_model(model,f)\n",
        "model = onnx.load('jasper_dynamic_input_float.onnx')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlGe4mJtk8ir"
      },
      "source": [
        "inp = model.graph.input[0]\n",
        "model.graph.input.remove(inp)\n",
        "inp.type.tensor_type.shape.dim[2].dim_value = 256\n",
        "inp.type.tensor_type.shape.dim[0].dim_value = 1\n",
        "model.graph.input.insert(0,inp)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y13aLBLliTr",
        "outputId": "fa2c1804-320b-443e-8ead-3bc489cfe883"
      },
      "source": [
        "model.graph.input"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"input__0\"\n",
              "type {\n",
              "  tensor_type {\n",
              "    elem_type: 1\n",
              "    shape {\n",
              "      dim {\n",
              "        dim_value: 1\n",
              "      }\n",
              "      dim {\n",
              "        dim_value: 64\n",
              "      }\n",
              "      dim {\n",
              "        dim_value: 256\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}\n",
              "]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaLsA8CcnHo5"
      },
      "source": [
        "with open('jasper_input_1x64x256_float.onnx','wb') as f:\n",
        "    onnx.save_model(model,f)\n",
        "model = onnx.load('jasper_input_1x64x256_float.onnx')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ItnoDCv_nrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fb7e5a-c600-46a0-9897-e2a6bcda2e33"
      },
      "source": [
        "print(onnx.helper.printable_graph(model.graph))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph torch-jit-export (\n",
            "  %input__0[FLOAT, 1x64x256]\n",
            ") initializers (\n",
            "  %decoder.layers.0.bias[FLOAT, 29]\n",
            "  %decoder.layers.0.weight[FLOAT, 29x1024x1]\n",
            "  %encoder.layers.0.conv.0.weight[FLOAT, 256x64x11]\n",
            "  %encoder.layers.0.conv.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.0.conv.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.0.conv.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.0.conv.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.0.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.12.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.13.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.13.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.13.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.13.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.16.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.17.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.17.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.17.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.17.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.4.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.5.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.5.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.5.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.5.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.8.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.1.conv.9.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.9.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.9.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.conv.9.weight[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.0.weight[FLOAT, 256x256x1]\n",
            "  %encoder.layers.1.res.0.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.1.res.0.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.10.conv.0.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.12.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.13.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.13.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.13.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.13.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.16.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.17.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.17.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.17.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.17.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.4.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.5.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.5.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.5.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.5.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.8.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.10.conv.9.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.9.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.9.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.conv.9.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.10.res.0.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.0.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.10.res.1.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.1.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.10.res.2.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.2.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.10.res.3.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.3.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.10.res.4.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.4.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.10.res.5.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.5.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.10.res.6.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.6.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.10.res.7.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.7.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.10.res.8.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.8.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.0.weight[FLOAT, 768x768x1]\n",
            "  %encoder.layers.10.res.9.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.10.res.9.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.11.conv.0.weight[FLOAT, 896x768x29]\n",
            "  %encoder.layers.11.conv.1.bias[FLOAT, 896]\n",
            "  %encoder.layers.11.conv.1.running_mean[FLOAT, 896]\n",
            "  %encoder.layers.11.conv.1.running_var[FLOAT, 896]\n",
            "  %encoder.layers.11.conv.1.weight[FLOAT, 896]\n",
            "  %encoder.layers.12.conv.0.weight[FLOAT, 1024x896x1]\n",
            "  %encoder.layers.12.conv.1.bias[FLOAT, 1024]\n",
            "  %encoder.layers.12.conv.1.running_mean[FLOAT, 1024]\n",
            "  %encoder.layers.12.conv.1.running_var[FLOAT, 1024]\n",
            "  %encoder.layers.12.conv.1.weight[FLOAT, 1024]\n",
            "  %encoder.layers.2.conv.0.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.12.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.13.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.13.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.13.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.13.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.16.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.17.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.17.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.17.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.17.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.4.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.5.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.5.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.5.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.5.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.8.weight[FLOAT, 256x256x11]\n",
            "  %encoder.layers.2.conv.9.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.9.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.9.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.conv.9.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.0.weight[FLOAT, 256x256x1]\n",
            "  %encoder.layers.2.res.0.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.res.0.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.0.weight[FLOAT, 256x256x1]\n",
            "  %encoder.layers.2.res.1.1.bias[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.1.running_mean[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.1.running_var[FLOAT, 256]\n",
            "  %encoder.layers.2.res.1.1.weight[FLOAT, 256]\n",
            "  %encoder.layers.3.conv.0.weight[FLOAT, 384x256x13]\n",
            "  %encoder.layers.3.conv.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.12.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.13.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.13.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.13.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.13.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.16.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.17.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.17.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.17.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.17.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.4.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.5.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.5.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.5.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.5.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.8.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.3.conv.9.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.9.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.9.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.conv.9.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.3.res.0.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.res.0.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.3.res.1.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.res.1.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.3.res.2.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.3.res.2.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.0.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.12.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.13.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.13.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.13.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.13.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.16.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.17.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.17.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.17.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.17.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.4.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.5.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.5.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.5.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.5.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.8.weight[FLOAT, 384x384x13]\n",
            "  %encoder.layers.4.conv.9.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.9.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.9.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.conv.9.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.4.res.0.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.0.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.4.res.1.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.1.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.0.weight[FLOAT, 384x256x1]\n",
            "  %encoder.layers.4.res.2.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.2.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.0.weight[FLOAT, 384x384x1]\n",
            "  %encoder.layers.4.res.3.1.bias[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.1.running_mean[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.1.running_var[FLOAT, 384]\n",
            "  %encoder.layers.4.res.3.1.weight[FLOAT, 384]\n",
            "  %encoder.layers.5.conv.0.weight[FLOAT, 512x384x17]\n",
            "  %encoder.layers.5.conv.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.12.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.13.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.13.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.13.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.13.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.16.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.17.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.17.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.17.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.17.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.4.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.5.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.5.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.5.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.5.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.8.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.5.conv.9.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.9.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.9.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.conv.9.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.5.res.0.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.0.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.5.res.1.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.1.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.5.res.2.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.2.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.5.res.3.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.3.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.5.res.4.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.5.res.4.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.0.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.12.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.13.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.13.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.13.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.13.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.16.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.17.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.17.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.17.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.17.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.4.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.5.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.5.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.5.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.5.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.8.weight[FLOAT, 512x512x17]\n",
            "  %encoder.layers.6.conv.9.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.9.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.9.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.conv.9.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.6.res.0.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.0.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.6.res.1.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.1.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.0.weight[FLOAT, 512x256x1]\n",
            "  %encoder.layers.6.res.2.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.2.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.6.res.3.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.3.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.0.weight[FLOAT, 512x384x1]\n",
            "  %encoder.layers.6.res.4.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.4.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.0.weight[FLOAT, 512x512x1]\n",
            "  %encoder.layers.6.res.5.1.bias[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.1.running_mean[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.1.running_var[FLOAT, 512]\n",
            "  %encoder.layers.6.res.5.1.weight[FLOAT, 512]\n",
            "  %encoder.layers.7.conv.0.weight[FLOAT, 640x512x21]\n",
            "  %encoder.layers.7.conv.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.12.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.13.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.13.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.13.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.13.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.16.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.17.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.17.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.17.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.17.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.4.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.5.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.5.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.5.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.5.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.8.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.7.conv.9.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.9.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.9.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.conv.9.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.7.res.0.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.0.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.7.res.1.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.1.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.7.res.2.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.2.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.7.res.3.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.3.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.7.res.4.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.4.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.7.res.5.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.5.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.7.res.6.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.7.res.6.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.0.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.12.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.13.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.13.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.13.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.13.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.16.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.17.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.17.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.17.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.17.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.4.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.5.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.5.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.5.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.5.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.8.weight[FLOAT, 640x640x21]\n",
            "  %encoder.layers.8.conv.9.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.9.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.9.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.conv.9.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.8.res.0.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.0.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.8.res.1.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.1.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.0.weight[FLOAT, 640x256x1]\n",
            "  %encoder.layers.8.res.2.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.2.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.8.res.3.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.3.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.0.weight[FLOAT, 640x384x1]\n",
            "  %encoder.layers.8.res.4.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.4.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.8.res.5.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.5.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.0.weight[FLOAT, 640x512x1]\n",
            "  %encoder.layers.8.res.6.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.6.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.0.weight[FLOAT, 640x640x1]\n",
            "  %encoder.layers.8.res.7.1.bias[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.1.running_mean[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.1.running_var[FLOAT, 640]\n",
            "  %encoder.layers.8.res.7.1.weight[FLOAT, 640]\n",
            "  %encoder.layers.9.conv.0.weight[FLOAT, 768x640x25]\n",
            "  %encoder.layers.9.conv.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.12.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.13.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.13.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.13.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.13.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.16.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.17.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.17.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.17.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.17.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.4.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.5.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.5.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.5.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.5.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.8.weight[FLOAT, 768x768x25]\n",
            "  %encoder.layers.9.conv.9.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.9.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.9.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.conv.9.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.9.res.0.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.0.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.9.res.1.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.1.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.0.weight[FLOAT, 768x256x1]\n",
            "  %encoder.layers.9.res.2.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.2.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.9.res.3.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.3.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.0.weight[FLOAT, 768x384x1]\n",
            "  %encoder.layers.9.res.4.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.4.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.9.res.5.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.5.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.0.weight[FLOAT, 768x512x1]\n",
            "  %encoder.layers.9.res.6.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.6.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.9.res.7.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.7.1.weight[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.0.weight[FLOAT, 768x640x1]\n",
            "  %encoder.layers.9.res.8.1.bias[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.1.running_mean[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.1.running_var[FLOAT, 768]\n",
            "  %encoder.layers.9.res.8.1.weight[FLOAT, 768]\n",
            ") {\n",
            "  %651 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [2]](%input__0, %encoder.layers.0.conv.0.weight)\n",
            "  %652 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%651, %encoder.layers.0.conv.1.weight, %encoder.layers.0.conv.1.bias, %encoder.layers.0.conv.1.running_mean, %encoder.layers.0.conv.1.running_var)\n",
            "  %653 = Relu(%652)\n",
            "  %654 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%653, %encoder.layers.1.conv.0.weight)\n",
            "  %655 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%654, %encoder.layers.1.conv.1.weight, %encoder.layers.1.conv.1.bias, %encoder.layers.1.conv.1.running_mean, %encoder.layers.1.conv.1.running_var)\n",
            "  %656 = Relu(%655)\n",
            "  %657 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%656, %encoder.layers.1.conv.4.weight)\n",
            "  %658 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%657, %encoder.layers.1.conv.5.weight, %encoder.layers.1.conv.5.bias, %encoder.layers.1.conv.5.running_mean, %encoder.layers.1.conv.5.running_var)\n",
            "  %659 = Relu(%658)\n",
            "  %660 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%659, %encoder.layers.1.conv.8.weight)\n",
            "  %661 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%660, %encoder.layers.1.conv.9.weight, %encoder.layers.1.conv.9.bias, %encoder.layers.1.conv.9.running_mean, %encoder.layers.1.conv.9.running_var)\n",
            "  %662 = Relu(%661)\n",
            "  %663 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%662, %encoder.layers.1.conv.12.weight)\n",
            "  %664 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%663, %encoder.layers.1.conv.13.weight, %encoder.layers.1.conv.13.bias, %encoder.layers.1.conv.13.running_mean, %encoder.layers.1.conv.13.running_var)\n",
            "  %665 = Relu(%664)\n",
            "  %666 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%665, %encoder.layers.1.conv.16.weight)\n",
            "  %667 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%666, %encoder.layers.1.conv.17.weight, %encoder.layers.1.conv.17.bias, %encoder.layers.1.conv.17.running_mean, %encoder.layers.1.conv.17.running_var)\n",
            "  %668 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.1.res.0.0.weight)\n",
            "  %669 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%668, %encoder.layers.1.res.0.1.weight, %encoder.layers.1.res.0.1.bias, %encoder.layers.1.res.0.1.running_mean, %encoder.layers.1.res.0.1.running_var)\n",
            "  %670 = Add(%667, %669)\n",
            "  %671 = Relu(%670)\n",
            "  %672 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%671, %encoder.layers.2.conv.0.weight)\n",
            "  %673 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%672, %encoder.layers.2.conv.1.weight, %encoder.layers.2.conv.1.bias, %encoder.layers.2.conv.1.running_mean, %encoder.layers.2.conv.1.running_var)\n",
            "  %674 = Relu(%673)\n",
            "  %675 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%674, %encoder.layers.2.conv.4.weight)\n",
            "  %676 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%675, %encoder.layers.2.conv.5.weight, %encoder.layers.2.conv.5.bias, %encoder.layers.2.conv.5.running_mean, %encoder.layers.2.conv.5.running_var)\n",
            "  %677 = Relu(%676)\n",
            "  %678 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%677, %encoder.layers.2.conv.8.weight)\n",
            "  %679 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%678, %encoder.layers.2.conv.9.weight, %encoder.layers.2.conv.9.bias, %encoder.layers.2.conv.9.running_mean, %encoder.layers.2.conv.9.running_var)\n",
            "  %680 = Relu(%679)\n",
            "  %681 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%680, %encoder.layers.2.conv.12.weight)\n",
            "  %682 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%681, %encoder.layers.2.conv.13.weight, %encoder.layers.2.conv.13.bias, %encoder.layers.2.conv.13.running_mean, %encoder.layers.2.conv.13.running_var)\n",
            "  %683 = Relu(%682)\n",
            "  %684 = Conv[dilations = [1], group = 1, kernel_shape = [11], pads = [5, 5], strides = [1]](%683, %encoder.layers.2.conv.16.weight)\n",
            "  %685 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%684, %encoder.layers.2.conv.17.weight, %encoder.layers.2.conv.17.bias, %encoder.layers.2.conv.17.running_mean, %encoder.layers.2.conv.17.running_var)\n",
            "  %686 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.2.res.0.0.weight)\n",
            "  %687 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%686, %encoder.layers.2.res.0.1.weight, %encoder.layers.2.res.0.1.bias, %encoder.layers.2.res.0.1.running_mean, %encoder.layers.2.res.0.1.running_var)\n",
            "  %688 = Add(%685, %687)\n",
            "  %689 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.2.res.1.0.weight)\n",
            "  %690 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%689, %encoder.layers.2.res.1.1.weight, %encoder.layers.2.res.1.1.bias, %encoder.layers.2.res.1.1.running_mean, %encoder.layers.2.res.1.1.running_var)\n",
            "  %691 = Add(%688, %690)\n",
            "  %692 = Relu(%691)\n",
            "  %693 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%692, %encoder.layers.3.conv.0.weight)\n",
            "  %694 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%693, %encoder.layers.3.conv.1.weight, %encoder.layers.3.conv.1.bias, %encoder.layers.3.conv.1.running_mean, %encoder.layers.3.conv.1.running_var)\n",
            "  %695 = Relu(%694)\n",
            "  %696 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%695, %encoder.layers.3.conv.4.weight)\n",
            "  %697 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%696, %encoder.layers.3.conv.5.weight, %encoder.layers.3.conv.5.bias, %encoder.layers.3.conv.5.running_mean, %encoder.layers.3.conv.5.running_var)\n",
            "  %698 = Relu(%697)\n",
            "  %699 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%698, %encoder.layers.3.conv.8.weight)\n",
            "  %700 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%699, %encoder.layers.3.conv.9.weight, %encoder.layers.3.conv.9.bias, %encoder.layers.3.conv.9.running_mean, %encoder.layers.3.conv.9.running_var)\n",
            "  %701 = Relu(%700)\n",
            "  %702 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%701, %encoder.layers.3.conv.12.weight)\n",
            "  %703 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%702, %encoder.layers.3.conv.13.weight, %encoder.layers.3.conv.13.bias, %encoder.layers.3.conv.13.running_mean, %encoder.layers.3.conv.13.running_var)\n",
            "  %704 = Relu(%703)\n",
            "  %705 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%704, %encoder.layers.3.conv.16.weight)\n",
            "  %706 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%705, %encoder.layers.3.conv.17.weight, %encoder.layers.3.conv.17.bias, %encoder.layers.3.conv.17.running_mean, %encoder.layers.3.conv.17.running_var)\n",
            "  %707 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.3.res.0.0.weight)\n",
            "  %708 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%707, %encoder.layers.3.res.0.1.weight, %encoder.layers.3.res.0.1.bias, %encoder.layers.3.res.0.1.running_mean, %encoder.layers.3.res.0.1.running_var)\n",
            "  %709 = Add(%706, %708)\n",
            "  %710 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.3.res.1.0.weight)\n",
            "  %711 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%710, %encoder.layers.3.res.1.1.weight, %encoder.layers.3.res.1.1.bias, %encoder.layers.3.res.1.1.running_mean, %encoder.layers.3.res.1.1.running_var)\n",
            "  %712 = Add(%709, %711)\n",
            "  %713 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.3.res.2.0.weight)\n",
            "  %714 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%713, %encoder.layers.3.res.2.1.weight, %encoder.layers.3.res.2.1.bias, %encoder.layers.3.res.2.1.running_mean, %encoder.layers.3.res.2.1.running_var)\n",
            "  %715 = Add(%712, %714)\n",
            "  %716 = Relu(%715)\n",
            "  %717 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%716, %encoder.layers.4.conv.0.weight)\n",
            "  %718 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%717, %encoder.layers.4.conv.1.weight, %encoder.layers.4.conv.1.bias, %encoder.layers.4.conv.1.running_mean, %encoder.layers.4.conv.1.running_var)\n",
            "  %719 = Relu(%718)\n",
            "  %720 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%719, %encoder.layers.4.conv.4.weight)\n",
            "  %721 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%720, %encoder.layers.4.conv.5.weight, %encoder.layers.4.conv.5.bias, %encoder.layers.4.conv.5.running_mean, %encoder.layers.4.conv.5.running_var)\n",
            "  %722 = Relu(%721)\n",
            "  %723 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%722, %encoder.layers.4.conv.8.weight)\n",
            "  %724 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%723, %encoder.layers.4.conv.9.weight, %encoder.layers.4.conv.9.bias, %encoder.layers.4.conv.9.running_mean, %encoder.layers.4.conv.9.running_var)\n",
            "  %725 = Relu(%724)\n",
            "  %726 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%725, %encoder.layers.4.conv.12.weight)\n",
            "  %727 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%726, %encoder.layers.4.conv.13.weight, %encoder.layers.4.conv.13.bias, %encoder.layers.4.conv.13.running_mean, %encoder.layers.4.conv.13.running_var)\n",
            "  %728 = Relu(%727)\n",
            "  %729 = Conv[dilations = [1], group = 1, kernel_shape = [13], pads = [6, 6], strides = [1]](%728, %encoder.layers.4.conv.16.weight)\n",
            "  %730 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%729, %encoder.layers.4.conv.17.weight, %encoder.layers.4.conv.17.bias, %encoder.layers.4.conv.17.running_mean, %encoder.layers.4.conv.17.running_var)\n",
            "  %731 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.4.res.0.0.weight)\n",
            "  %732 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%731, %encoder.layers.4.res.0.1.weight, %encoder.layers.4.res.0.1.bias, %encoder.layers.4.res.0.1.running_mean, %encoder.layers.4.res.0.1.running_var)\n",
            "  %733 = Add(%730, %732)\n",
            "  %734 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.4.res.1.0.weight)\n",
            "  %735 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%734, %encoder.layers.4.res.1.1.weight, %encoder.layers.4.res.1.1.bias, %encoder.layers.4.res.1.1.running_mean, %encoder.layers.4.res.1.1.running_var)\n",
            "  %736 = Add(%733, %735)\n",
            "  %737 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.4.res.2.0.weight)\n",
            "  %738 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%737, %encoder.layers.4.res.2.1.weight, %encoder.layers.4.res.2.1.bias, %encoder.layers.4.res.2.1.running_mean, %encoder.layers.4.res.2.1.running_var)\n",
            "  %739 = Add(%736, %738)\n",
            "  %740 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.4.res.3.0.weight)\n",
            "  %741 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%740, %encoder.layers.4.res.3.1.weight, %encoder.layers.4.res.3.1.bias, %encoder.layers.4.res.3.1.running_mean, %encoder.layers.4.res.3.1.running_var)\n",
            "  %742 = Add(%739, %741)\n",
            "  %743 = Relu(%742)\n",
            "  %744 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%743, %encoder.layers.5.conv.0.weight)\n",
            "  %745 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%744, %encoder.layers.5.conv.1.weight, %encoder.layers.5.conv.1.bias, %encoder.layers.5.conv.1.running_mean, %encoder.layers.5.conv.1.running_var)\n",
            "  %746 = Relu(%745)\n",
            "  %747 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%746, %encoder.layers.5.conv.4.weight)\n",
            "  %748 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%747, %encoder.layers.5.conv.5.weight, %encoder.layers.5.conv.5.bias, %encoder.layers.5.conv.5.running_mean, %encoder.layers.5.conv.5.running_var)\n",
            "  %749 = Relu(%748)\n",
            "  %750 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%749, %encoder.layers.5.conv.8.weight)\n",
            "  %751 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%750, %encoder.layers.5.conv.9.weight, %encoder.layers.5.conv.9.bias, %encoder.layers.5.conv.9.running_mean, %encoder.layers.5.conv.9.running_var)\n",
            "  %752 = Relu(%751)\n",
            "  %753 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%752, %encoder.layers.5.conv.12.weight)\n",
            "  %754 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%753, %encoder.layers.5.conv.13.weight, %encoder.layers.5.conv.13.bias, %encoder.layers.5.conv.13.running_mean, %encoder.layers.5.conv.13.running_var)\n",
            "  %755 = Relu(%754)\n",
            "  %756 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%755, %encoder.layers.5.conv.16.weight)\n",
            "  %757 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%756, %encoder.layers.5.conv.17.weight, %encoder.layers.5.conv.17.bias, %encoder.layers.5.conv.17.running_mean, %encoder.layers.5.conv.17.running_var)\n",
            "  %758 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.5.res.0.0.weight)\n",
            "  %759 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%758, %encoder.layers.5.res.0.1.weight, %encoder.layers.5.res.0.1.bias, %encoder.layers.5.res.0.1.running_mean, %encoder.layers.5.res.0.1.running_var)\n",
            "  %760 = Add(%757, %759)\n",
            "  %761 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.5.res.1.0.weight)\n",
            "  %762 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%761, %encoder.layers.5.res.1.1.weight, %encoder.layers.5.res.1.1.bias, %encoder.layers.5.res.1.1.running_mean, %encoder.layers.5.res.1.1.running_var)\n",
            "  %763 = Add(%760, %762)\n",
            "  %764 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.5.res.2.0.weight)\n",
            "  %765 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%764, %encoder.layers.5.res.2.1.weight, %encoder.layers.5.res.2.1.bias, %encoder.layers.5.res.2.1.running_mean, %encoder.layers.5.res.2.1.running_var)\n",
            "  %766 = Add(%763, %765)\n",
            "  %767 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.5.res.3.0.weight)\n",
            "  %768 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%767, %encoder.layers.5.res.3.1.weight, %encoder.layers.5.res.3.1.bias, %encoder.layers.5.res.3.1.running_mean, %encoder.layers.5.res.3.1.running_var)\n",
            "  %769 = Add(%766, %768)\n",
            "  %770 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.5.res.4.0.weight)\n",
            "  %771 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%770, %encoder.layers.5.res.4.1.weight, %encoder.layers.5.res.4.1.bias, %encoder.layers.5.res.4.1.running_mean, %encoder.layers.5.res.4.1.running_var)\n",
            "  %772 = Add(%769, %771)\n",
            "  %773 = Relu(%772)\n",
            "  %774 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%773, %encoder.layers.6.conv.0.weight)\n",
            "  %775 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%774, %encoder.layers.6.conv.1.weight, %encoder.layers.6.conv.1.bias, %encoder.layers.6.conv.1.running_mean, %encoder.layers.6.conv.1.running_var)\n",
            "  %776 = Relu(%775)\n",
            "  %777 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%776, %encoder.layers.6.conv.4.weight)\n",
            "  %778 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%777, %encoder.layers.6.conv.5.weight, %encoder.layers.6.conv.5.bias, %encoder.layers.6.conv.5.running_mean, %encoder.layers.6.conv.5.running_var)\n",
            "  %779 = Relu(%778)\n",
            "  %780 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%779, %encoder.layers.6.conv.8.weight)\n",
            "  %781 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%780, %encoder.layers.6.conv.9.weight, %encoder.layers.6.conv.9.bias, %encoder.layers.6.conv.9.running_mean, %encoder.layers.6.conv.9.running_var)\n",
            "  %782 = Relu(%781)\n",
            "  %783 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%782, %encoder.layers.6.conv.12.weight)\n",
            "  %784 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%783, %encoder.layers.6.conv.13.weight, %encoder.layers.6.conv.13.bias, %encoder.layers.6.conv.13.running_mean, %encoder.layers.6.conv.13.running_var)\n",
            "  %785 = Relu(%784)\n",
            "  %786 = Conv[dilations = [1], group = 1, kernel_shape = [17], pads = [8, 8], strides = [1]](%785, %encoder.layers.6.conv.16.weight)\n",
            "  %787 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%786, %encoder.layers.6.conv.17.weight, %encoder.layers.6.conv.17.bias, %encoder.layers.6.conv.17.running_mean, %encoder.layers.6.conv.17.running_var)\n",
            "  %788 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.6.res.0.0.weight)\n",
            "  %789 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%788, %encoder.layers.6.res.0.1.weight, %encoder.layers.6.res.0.1.bias, %encoder.layers.6.res.0.1.running_mean, %encoder.layers.6.res.0.1.running_var)\n",
            "  %790 = Add(%787, %789)\n",
            "  %791 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.6.res.1.0.weight)\n",
            "  %792 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%791, %encoder.layers.6.res.1.1.weight, %encoder.layers.6.res.1.1.bias, %encoder.layers.6.res.1.1.running_mean, %encoder.layers.6.res.1.1.running_var)\n",
            "  %793 = Add(%790, %792)\n",
            "  %794 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.6.res.2.0.weight)\n",
            "  %795 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%794, %encoder.layers.6.res.2.1.weight, %encoder.layers.6.res.2.1.bias, %encoder.layers.6.res.2.1.running_mean, %encoder.layers.6.res.2.1.running_var)\n",
            "  %796 = Add(%793, %795)\n",
            "  %797 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.6.res.3.0.weight)\n",
            "  %798 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%797, %encoder.layers.6.res.3.1.weight, %encoder.layers.6.res.3.1.bias, %encoder.layers.6.res.3.1.running_mean, %encoder.layers.6.res.3.1.running_var)\n",
            "  %799 = Add(%796, %798)\n",
            "  %800 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.6.res.4.0.weight)\n",
            "  %801 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%800, %encoder.layers.6.res.4.1.weight, %encoder.layers.6.res.4.1.bias, %encoder.layers.6.res.4.1.running_mean, %encoder.layers.6.res.4.1.running_var)\n",
            "  %802 = Add(%799, %801)\n",
            "  %803 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.6.res.5.0.weight)\n",
            "  %804 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%803, %encoder.layers.6.res.5.1.weight, %encoder.layers.6.res.5.1.bias, %encoder.layers.6.res.5.1.running_mean, %encoder.layers.6.res.5.1.running_var)\n",
            "  %805 = Add(%802, %804)\n",
            "  %806 = Relu(%805)\n",
            "  %807 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%806, %encoder.layers.7.conv.0.weight)\n",
            "  %808 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%807, %encoder.layers.7.conv.1.weight, %encoder.layers.7.conv.1.bias, %encoder.layers.7.conv.1.running_mean, %encoder.layers.7.conv.1.running_var)\n",
            "  %809 = Relu(%808)\n",
            "  %810 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%809, %encoder.layers.7.conv.4.weight)\n",
            "  %811 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%810, %encoder.layers.7.conv.5.weight, %encoder.layers.7.conv.5.bias, %encoder.layers.7.conv.5.running_mean, %encoder.layers.7.conv.5.running_var)\n",
            "  %812 = Relu(%811)\n",
            "  %813 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%812, %encoder.layers.7.conv.8.weight)\n",
            "  %814 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%813, %encoder.layers.7.conv.9.weight, %encoder.layers.7.conv.9.bias, %encoder.layers.7.conv.9.running_mean, %encoder.layers.7.conv.9.running_var)\n",
            "  %815 = Relu(%814)\n",
            "  %816 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%815, %encoder.layers.7.conv.12.weight)\n",
            "  %817 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%816, %encoder.layers.7.conv.13.weight, %encoder.layers.7.conv.13.bias, %encoder.layers.7.conv.13.running_mean, %encoder.layers.7.conv.13.running_var)\n",
            "  %818 = Relu(%817)\n",
            "  %819 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%818, %encoder.layers.7.conv.16.weight)\n",
            "  %820 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%819, %encoder.layers.7.conv.17.weight, %encoder.layers.7.conv.17.bias, %encoder.layers.7.conv.17.running_mean, %encoder.layers.7.conv.17.running_var)\n",
            "  %821 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.7.res.0.0.weight)\n",
            "  %822 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%821, %encoder.layers.7.res.0.1.weight, %encoder.layers.7.res.0.1.bias, %encoder.layers.7.res.0.1.running_mean, %encoder.layers.7.res.0.1.running_var)\n",
            "  %823 = Add(%820, %822)\n",
            "  %824 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.7.res.1.0.weight)\n",
            "  %825 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%824, %encoder.layers.7.res.1.1.weight, %encoder.layers.7.res.1.1.bias, %encoder.layers.7.res.1.1.running_mean, %encoder.layers.7.res.1.1.running_var)\n",
            "  %826 = Add(%823, %825)\n",
            "  %827 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.7.res.2.0.weight)\n",
            "  %828 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%827, %encoder.layers.7.res.2.1.weight, %encoder.layers.7.res.2.1.bias, %encoder.layers.7.res.2.1.running_mean, %encoder.layers.7.res.2.1.running_var)\n",
            "  %829 = Add(%826, %828)\n",
            "  %830 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.7.res.3.0.weight)\n",
            "  %831 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%830, %encoder.layers.7.res.3.1.weight, %encoder.layers.7.res.3.1.bias, %encoder.layers.7.res.3.1.running_mean, %encoder.layers.7.res.3.1.running_var)\n",
            "  %832 = Add(%829, %831)\n",
            "  %833 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.7.res.4.0.weight)\n",
            "  %834 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%833, %encoder.layers.7.res.4.1.weight, %encoder.layers.7.res.4.1.bias, %encoder.layers.7.res.4.1.running_mean, %encoder.layers.7.res.4.1.running_var)\n",
            "  %835 = Add(%832, %834)\n",
            "  %836 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.7.res.5.0.weight)\n",
            "  %837 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%836, %encoder.layers.7.res.5.1.weight, %encoder.layers.7.res.5.1.bias, %encoder.layers.7.res.5.1.running_mean, %encoder.layers.7.res.5.1.running_var)\n",
            "  %838 = Add(%835, %837)\n",
            "  %839 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.7.res.6.0.weight)\n",
            "  %840 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%839, %encoder.layers.7.res.6.1.weight, %encoder.layers.7.res.6.1.bias, %encoder.layers.7.res.6.1.running_mean, %encoder.layers.7.res.6.1.running_var)\n",
            "  %841 = Add(%838, %840)\n",
            "  %842 = Relu(%841)\n",
            "  %843 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%842, %encoder.layers.8.conv.0.weight)\n",
            "  %844 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%843, %encoder.layers.8.conv.1.weight, %encoder.layers.8.conv.1.bias, %encoder.layers.8.conv.1.running_mean, %encoder.layers.8.conv.1.running_var)\n",
            "  %845 = Relu(%844)\n",
            "  %846 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%845, %encoder.layers.8.conv.4.weight)\n",
            "  %847 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%846, %encoder.layers.8.conv.5.weight, %encoder.layers.8.conv.5.bias, %encoder.layers.8.conv.5.running_mean, %encoder.layers.8.conv.5.running_var)\n",
            "  %848 = Relu(%847)\n",
            "  %849 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%848, %encoder.layers.8.conv.8.weight)\n",
            "  %850 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%849, %encoder.layers.8.conv.9.weight, %encoder.layers.8.conv.9.bias, %encoder.layers.8.conv.9.running_mean, %encoder.layers.8.conv.9.running_var)\n",
            "  %851 = Relu(%850)\n",
            "  %852 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%851, %encoder.layers.8.conv.12.weight)\n",
            "  %853 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%852, %encoder.layers.8.conv.13.weight, %encoder.layers.8.conv.13.bias, %encoder.layers.8.conv.13.running_mean, %encoder.layers.8.conv.13.running_var)\n",
            "  %854 = Relu(%853)\n",
            "  %855 = Conv[dilations = [1], group = 1, kernel_shape = [21], pads = [10, 10], strides = [1]](%854, %encoder.layers.8.conv.16.weight)\n",
            "  %856 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%855, %encoder.layers.8.conv.17.weight, %encoder.layers.8.conv.17.bias, %encoder.layers.8.conv.17.running_mean, %encoder.layers.8.conv.17.running_var)\n",
            "  %857 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.8.res.0.0.weight)\n",
            "  %858 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%857, %encoder.layers.8.res.0.1.weight, %encoder.layers.8.res.0.1.bias, %encoder.layers.8.res.0.1.running_mean, %encoder.layers.8.res.0.1.running_var)\n",
            "  %859 = Add(%856, %858)\n",
            "  %860 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.8.res.1.0.weight)\n",
            "  %861 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%860, %encoder.layers.8.res.1.1.weight, %encoder.layers.8.res.1.1.bias, %encoder.layers.8.res.1.1.running_mean, %encoder.layers.8.res.1.1.running_var)\n",
            "  %862 = Add(%859, %861)\n",
            "  %863 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.8.res.2.0.weight)\n",
            "  %864 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%863, %encoder.layers.8.res.2.1.weight, %encoder.layers.8.res.2.1.bias, %encoder.layers.8.res.2.1.running_mean, %encoder.layers.8.res.2.1.running_var)\n",
            "  %865 = Add(%862, %864)\n",
            "  %866 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.8.res.3.0.weight)\n",
            "  %867 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%866, %encoder.layers.8.res.3.1.weight, %encoder.layers.8.res.3.1.bias, %encoder.layers.8.res.3.1.running_mean, %encoder.layers.8.res.3.1.running_var)\n",
            "  %868 = Add(%865, %867)\n",
            "  %869 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.8.res.4.0.weight)\n",
            "  %870 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%869, %encoder.layers.8.res.4.1.weight, %encoder.layers.8.res.4.1.bias, %encoder.layers.8.res.4.1.running_mean, %encoder.layers.8.res.4.1.running_var)\n",
            "  %871 = Add(%868, %870)\n",
            "  %872 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.8.res.5.0.weight)\n",
            "  %873 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%872, %encoder.layers.8.res.5.1.weight, %encoder.layers.8.res.5.1.bias, %encoder.layers.8.res.5.1.running_mean, %encoder.layers.8.res.5.1.running_var)\n",
            "  %874 = Add(%871, %873)\n",
            "  %875 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.8.res.6.0.weight)\n",
            "  %876 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%875, %encoder.layers.8.res.6.1.weight, %encoder.layers.8.res.6.1.bias, %encoder.layers.8.res.6.1.running_mean, %encoder.layers.8.res.6.1.running_var)\n",
            "  %877 = Add(%874, %876)\n",
            "  %878 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.8.res.7.0.weight)\n",
            "  %879 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%878, %encoder.layers.8.res.7.1.weight, %encoder.layers.8.res.7.1.bias, %encoder.layers.8.res.7.1.running_mean, %encoder.layers.8.res.7.1.running_var)\n",
            "  %880 = Add(%877, %879)\n",
            "  %881 = Relu(%880)\n",
            "  %882 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%881, %encoder.layers.9.conv.0.weight)\n",
            "  %883 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%882, %encoder.layers.9.conv.1.weight, %encoder.layers.9.conv.1.bias, %encoder.layers.9.conv.1.running_mean, %encoder.layers.9.conv.1.running_var)\n",
            "  %884 = Relu(%883)\n",
            "  %885 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%884, %encoder.layers.9.conv.4.weight)\n",
            "  %886 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%885, %encoder.layers.9.conv.5.weight, %encoder.layers.9.conv.5.bias, %encoder.layers.9.conv.5.running_mean, %encoder.layers.9.conv.5.running_var)\n",
            "  %887 = Relu(%886)\n",
            "  %888 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%887, %encoder.layers.9.conv.8.weight)\n",
            "  %889 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%888, %encoder.layers.9.conv.9.weight, %encoder.layers.9.conv.9.bias, %encoder.layers.9.conv.9.running_mean, %encoder.layers.9.conv.9.running_var)\n",
            "  %890 = Relu(%889)\n",
            "  %891 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%890, %encoder.layers.9.conv.12.weight)\n",
            "  %892 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%891, %encoder.layers.9.conv.13.weight, %encoder.layers.9.conv.13.bias, %encoder.layers.9.conv.13.running_mean, %encoder.layers.9.conv.13.running_var)\n",
            "  %893 = Relu(%892)\n",
            "  %894 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%893, %encoder.layers.9.conv.16.weight)\n",
            "  %895 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%894, %encoder.layers.9.conv.17.weight, %encoder.layers.9.conv.17.bias, %encoder.layers.9.conv.17.running_mean, %encoder.layers.9.conv.17.running_var)\n",
            "  %896 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.9.res.0.0.weight)\n",
            "  %897 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%896, %encoder.layers.9.res.0.1.weight, %encoder.layers.9.res.0.1.bias, %encoder.layers.9.res.0.1.running_mean, %encoder.layers.9.res.0.1.running_var)\n",
            "  %898 = Add(%895, %897)\n",
            "  %899 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.9.res.1.0.weight)\n",
            "  %900 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%899, %encoder.layers.9.res.1.1.weight, %encoder.layers.9.res.1.1.bias, %encoder.layers.9.res.1.1.running_mean, %encoder.layers.9.res.1.1.running_var)\n",
            "  %901 = Add(%898, %900)\n",
            "  %902 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.9.res.2.0.weight)\n",
            "  %903 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%902, %encoder.layers.9.res.2.1.weight, %encoder.layers.9.res.2.1.bias, %encoder.layers.9.res.2.1.running_mean, %encoder.layers.9.res.2.1.running_var)\n",
            "  %904 = Add(%901, %903)\n",
            "  %905 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.9.res.3.0.weight)\n",
            "  %906 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%905, %encoder.layers.9.res.3.1.weight, %encoder.layers.9.res.3.1.bias, %encoder.layers.9.res.3.1.running_mean, %encoder.layers.9.res.3.1.running_var)\n",
            "  %907 = Add(%904, %906)\n",
            "  %908 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.9.res.4.0.weight)\n",
            "  %909 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%908, %encoder.layers.9.res.4.1.weight, %encoder.layers.9.res.4.1.bias, %encoder.layers.9.res.4.1.running_mean, %encoder.layers.9.res.4.1.running_var)\n",
            "  %910 = Add(%907, %909)\n",
            "  %911 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.9.res.5.0.weight)\n",
            "  %912 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%911, %encoder.layers.9.res.5.1.weight, %encoder.layers.9.res.5.1.bias, %encoder.layers.9.res.5.1.running_mean, %encoder.layers.9.res.5.1.running_var)\n",
            "  %913 = Add(%910, %912)\n",
            "  %914 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.9.res.6.0.weight)\n",
            "  %915 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%914, %encoder.layers.9.res.6.1.weight, %encoder.layers.9.res.6.1.bias, %encoder.layers.9.res.6.1.running_mean, %encoder.layers.9.res.6.1.running_var)\n",
            "  %916 = Add(%913, %915)\n",
            "  %917 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.9.res.7.0.weight)\n",
            "  %918 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%917, %encoder.layers.9.res.7.1.weight, %encoder.layers.9.res.7.1.bias, %encoder.layers.9.res.7.1.running_mean, %encoder.layers.9.res.7.1.running_var)\n",
            "  %919 = Add(%916, %918)\n",
            "  %920 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%881, %encoder.layers.9.res.8.0.weight)\n",
            "  %921 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%920, %encoder.layers.9.res.8.1.weight, %encoder.layers.9.res.8.1.bias, %encoder.layers.9.res.8.1.running_mean, %encoder.layers.9.res.8.1.running_var)\n",
            "  %922 = Add(%919, %921)\n",
            "  %923 = Relu(%922)\n",
            "  %924 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%923, %encoder.layers.10.conv.0.weight)\n",
            "  %925 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%924, %encoder.layers.10.conv.1.weight, %encoder.layers.10.conv.1.bias, %encoder.layers.10.conv.1.running_mean, %encoder.layers.10.conv.1.running_var)\n",
            "  %926 = Relu(%925)\n",
            "  %927 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%926, %encoder.layers.10.conv.4.weight)\n",
            "  %928 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%927, %encoder.layers.10.conv.5.weight, %encoder.layers.10.conv.5.bias, %encoder.layers.10.conv.5.running_mean, %encoder.layers.10.conv.5.running_var)\n",
            "  %929 = Relu(%928)\n",
            "  %930 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%929, %encoder.layers.10.conv.8.weight)\n",
            "  %931 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%930, %encoder.layers.10.conv.9.weight, %encoder.layers.10.conv.9.bias, %encoder.layers.10.conv.9.running_mean, %encoder.layers.10.conv.9.running_var)\n",
            "  %932 = Relu(%931)\n",
            "  %933 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%932, %encoder.layers.10.conv.12.weight)\n",
            "  %934 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%933, %encoder.layers.10.conv.13.weight, %encoder.layers.10.conv.13.bias, %encoder.layers.10.conv.13.running_mean, %encoder.layers.10.conv.13.running_var)\n",
            "  %935 = Relu(%934)\n",
            "  %936 = Conv[dilations = [1], group = 1, kernel_shape = [25], pads = [12, 12], strides = [1]](%935, %encoder.layers.10.conv.16.weight)\n",
            "  %937 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%936, %encoder.layers.10.conv.17.weight, %encoder.layers.10.conv.17.bias, %encoder.layers.10.conv.17.running_mean, %encoder.layers.10.conv.17.running_var)\n",
            "  %938 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%653, %encoder.layers.10.res.0.0.weight)\n",
            "  %939 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%938, %encoder.layers.10.res.0.1.weight, %encoder.layers.10.res.0.1.bias, %encoder.layers.10.res.0.1.running_mean, %encoder.layers.10.res.0.1.running_var)\n",
            "  %940 = Add(%937, %939)\n",
            "  %941 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%671, %encoder.layers.10.res.1.0.weight)\n",
            "  %942 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%941, %encoder.layers.10.res.1.1.weight, %encoder.layers.10.res.1.1.bias, %encoder.layers.10.res.1.1.running_mean, %encoder.layers.10.res.1.1.running_var)\n",
            "  %943 = Add(%940, %942)\n",
            "  %944 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%692, %encoder.layers.10.res.2.0.weight)\n",
            "  %945 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%944, %encoder.layers.10.res.2.1.weight, %encoder.layers.10.res.2.1.bias, %encoder.layers.10.res.2.1.running_mean, %encoder.layers.10.res.2.1.running_var)\n",
            "  %946 = Add(%943, %945)\n",
            "  %947 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%716, %encoder.layers.10.res.3.0.weight)\n",
            "  %948 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%947, %encoder.layers.10.res.3.1.weight, %encoder.layers.10.res.3.1.bias, %encoder.layers.10.res.3.1.running_mean, %encoder.layers.10.res.3.1.running_var)\n",
            "  %949 = Add(%946, %948)\n",
            "  %950 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%743, %encoder.layers.10.res.4.0.weight)\n",
            "  %951 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%950, %encoder.layers.10.res.4.1.weight, %encoder.layers.10.res.4.1.bias, %encoder.layers.10.res.4.1.running_mean, %encoder.layers.10.res.4.1.running_var)\n",
            "  %952 = Add(%949, %951)\n",
            "  %953 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%773, %encoder.layers.10.res.5.0.weight)\n",
            "  %954 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%953, %encoder.layers.10.res.5.1.weight, %encoder.layers.10.res.5.1.bias, %encoder.layers.10.res.5.1.running_mean, %encoder.layers.10.res.5.1.running_var)\n",
            "  %955 = Add(%952, %954)\n",
            "  %956 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%806, %encoder.layers.10.res.6.0.weight)\n",
            "  %957 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%956, %encoder.layers.10.res.6.1.weight, %encoder.layers.10.res.6.1.bias, %encoder.layers.10.res.6.1.running_mean, %encoder.layers.10.res.6.1.running_var)\n",
            "  %958 = Add(%955, %957)\n",
            "  %959 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%842, %encoder.layers.10.res.7.0.weight)\n",
            "  %960 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%959, %encoder.layers.10.res.7.1.weight, %encoder.layers.10.res.7.1.bias, %encoder.layers.10.res.7.1.running_mean, %encoder.layers.10.res.7.1.running_var)\n",
            "  %961 = Add(%958, %960)\n",
            "  %962 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%881, %encoder.layers.10.res.8.0.weight)\n",
            "  %963 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%962, %encoder.layers.10.res.8.1.weight, %encoder.layers.10.res.8.1.bias, %encoder.layers.10.res.8.1.running_mean, %encoder.layers.10.res.8.1.running_var)\n",
            "  %964 = Add(%961, %963)\n",
            "  %965 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%923, %encoder.layers.10.res.9.0.weight)\n",
            "  %966 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%965, %encoder.layers.10.res.9.1.weight, %encoder.layers.10.res.9.1.bias, %encoder.layers.10.res.9.1.running_mean, %encoder.layers.10.res.9.1.running_var)\n",
            "  %967 = Add(%964, %966)\n",
            "  %968 = Relu(%967)\n",
            "  %969 = Conv[dilations = [2], group = 1, kernel_shape = [29], pads = [28, 28], strides = [1]](%968, %encoder.layers.11.conv.0.weight)\n",
            "  %970 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%969, %encoder.layers.11.conv.1.weight, %encoder.layers.11.conv.1.bias, %encoder.layers.11.conv.1.running_mean, %encoder.layers.11.conv.1.running_var)\n",
            "  %971 = Relu(%970)\n",
            "  %972 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%971, %encoder.layers.12.conv.0.weight)\n",
            "  %973 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.899999976158142](%972, %encoder.layers.12.conv.1.weight, %encoder.layers.12.conv.1.bias, %encoder.layers.12.conv.1.running_mean, %encoder.layers.12.conv.1.running_var)\n",
            "  %974 = Relu(%973)\n",
            "  %975 = Conv[dilations = [1], group = 1, kernel_shape = [1], pads = [0, 0], strides = [1]](%974, %decoder.layers.0.weight, %decoder.layers.0.bias)\n",
            "  %976 = Transpose[perm = [0, 2, 1]](%975)\n",
            "  %output__0 = LogSoftmax[axis = 2](%976)\n",
            "  return %output__0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6MG78-Y_wyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "178be98b-8e93-438f-e78e-988be5b913af"
      },
      "source": [
        "!pip install opencv-python==4.5.2.52\n",
        "import cv2 as cv\n",
        "# Should be > 4.5.x\n",
        "cv.__version__"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python==4.5.2.52 in /usr/local/lib/python3.7/dist-packages (4.5.2.52)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.2.52) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.5.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzvhT-IWF7BP"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "net = cv.dnn.readNetFromONNX('./jasper_input_1x64x256_float.onnx') # N,C,W\n",
        "net1 = cv.dnn.readNetFromONNX('./jasper_dynamic_input_float.onnx')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HuVgAyJmnv3"
      },
      "source": [
        "input_img = np.random.randn(320,64,32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "d5AU3ca3GExC",
        "outputId": "2d0733df-6cd8-4395-938a-e44cde899eeb"
      },
      "source": [
        "net1.setInput(input_img)\n",
        "out = net1.forward()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3c84732e2499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.5.2) /tmp/pip-req-build-oxjbfc17/opencv/modules/dnn/src/layers/permute_layer.cpp:138: error: (-215:Assertion failed) (int)_numAxes == inputs[0].size() in function 'getMemoryShapes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA1EXMAwJp87"
      },
      "source": [
        "import torch\n",
        "encoder = torch.jit.load('feature-extractor-ts-trace/1/model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdtrtGUyj3fl"
      },
      "source": [
        "encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P_MT2LVj4XB"
      },
      "source": [
        "decoder = torch.jit.load('decoder-ts-script/1/model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qijWbRCkIMy"
      },
      "source": [
        "decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv9fZJY2kI18"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}